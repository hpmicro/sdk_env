<!-- HTML header for doxygen 1.8.13-->
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=9"/>
<meta name="generator" content="Doxygen 1.12.0"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<link rel="icon" href="logo.ico">
<title>HPM SDK: NN Convolution Functions</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<link href="navtree.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="navtreedata.js"></script>
<script type="text/javascript" src="navtree.js"></script>
<script type="text/javascript" src="resize.js"></script>
<script type="text/javascript" src="cookie.js"></script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/searchdata.js"></script>
<script type="text/javascript" src="search/search.js"></script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
<link href="customdoxygen.css" rel="stylesheet" type="text/css"/>
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr style="height: 56px;">
  <td id="projectlogo"><a href="https://www.hpmicro.com/"
     target="_blank"><img alt="Logo" src="logo.png"/></a></td>
  <td id="projectalign" style="padding-left: 1em;">
   <div id="projectname">HPM SDK
   </div>
   <div id="projectbrief">HPMicro Software Development Kit</div>
  </td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.12.0 -->
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
var searchBox = new SearchBox("searchBox", "search/",'.html');
/* @license-end */
</script>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
$(function() { codefold.init(0); });
/* @license-end */
</script>
<script type="text/javascript" src="menudata.js"></script>
<script type="text/javascript" src="menu.js"></script>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
$(function() {
  initMenu('',true,false,'search.php','Search',true);
  $(function() { init_search(); });
});
/* @license-end */
</script>
<div id="main-nav"></div>
</div><!-- top -->
<div id="side-nav" class="ui-resizable side-nav-resizable">
  <div id="nav-tree">
    <div id="nav-tree-contents">
      <div id="nav-sync" class="sync"></div>
    </div>
  </div>
  <div id="splitbar" style="-moz-user-select:none;" 
       class="ui-resizable-handle">
  </div>
</div>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
$(function(){initNavTree('group__nnconvolution.html',''); initResizable(true); });
/* @license-end */
</script>
<div id="doc-content">
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<div id="MSearchResults">
<div class="SRPage">
<div id="SRIndex">
<div id="SRResults"></div>
<div class="SRStatus" id="Loading">Loading...</div>
<div class="SRStatus" id="Searching">Searching...</div>
<div class="SRStatus" id="NoMatches">No Matches</div>
</div>
</div>
</div>
</div>

<div class="header">
  <div class="summary">
<a href="#func-members">Functions</a>  </div>
  <div class="headertitle"><div class="title">NN Convolution Functions<div class="ingroups"><a class="el" href="group__hpmmath.html">HPMicro Math Functions</a> &raquo; <a class="el" href="group__sort.html">DSP Sort Functions</a></div></div></div>
</div><!--header-->
<div class="contents">

<p>The convolution functions transform the input matrix into a column vector with im2col, and then use matrix-matrix multiplication to get the convolution result.  
<a href="#details">More...</a></p>
<table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a id="func-members" name="func-members"></a>
Functions</h2></td></tr>
<tr class="memitem:gaf6fad182b1496ef1d5651b6628701293" id="r_gaf6fad182b1496ef1d5651b6628701293"><td class="memItemLeft" align="right" valign="top">static int32_t&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#gaf6fad182b1496ef1d5651b6628701293">hpm_nn_conv_1x1_HWC_s8_s8_s8_sft_bias_fast_any</a> (const q7_t *in_tensor, const uint16_t in_tensor_dim_x, const uint16_t in_tensor_dim_y, const uint16_t in_tensor_ch, const q7_t *ker_weight, const uint16_t out_tensor_ch, const uint16_t ker_dim_x, const uint16_t ker_dim_y, const uint16_t pad_x, const uint16_t pad_y, const uint16_t stride_x, const uint16_t stride_y, const q7_t *<a class="el" href="group__nnfullyconnect.html#ga602e28fc157c370e73e4df5712f9df84">bias</a>, const uint16_t <a class="el" href="group__nnfullyconnect.html#gad09cca4af5af99ea8c169222a235b87f">bias_lshift</a>, const uint16_t <a class="el" href="group__nnfullyconnect.html#ga8dd64794329e763d76515d7434831c97">out_rshift</a>, q7_t *out_tensor, const uint16_t out_tensor_dim_x, const uint16_t out_tensor_dim_y, q15_t *<a class="el" href="group__nnfullyconnect.html#ga4972f5e62722e743bc2e14d86e130148">in_tmp_buf</a>, q7_t *tmp_buf)</td></tr>
<tr class="memdesc:gaf6fad182b1496ef1d5651b6628701293"><td class="mdescLeft">&#160;</td><td class="mdescRight">This function performs 1x1 kernels convolution for signed 8-bit integer inputs/outputs in any x and y dimensions with shift-based quantization on the outputs.  <br /></td></tr>
<tr class="separator:gaf6fad182b1496ef1d5651b6628701293"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ga48801812baf4ac44d8f420656e0d344e" id="r_ga48801812baf4ac44d8f420656e0d344e"><td class="memItemLeft" align="right" valign="top">static int32_t&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#ga48801812baf4ac44d8f420656e0d344e">hpm_nn_conv_HWC_s8_s8_s8_RGB_sft_bias</a> (const q7_t *in_tensor, const uint16_t in_tensor_dim, const q7_t *ker_weight, const uint16_t out_tensor_ch, const uint16_t ker_dim, const uint16_t pad, const uint16_t stride, const q7_t *<a class="el" href="group__nnfullyconnect.html#ga602e28fc157c370e73e4df5712f9df84">bias</a>, const uint16_t <a class="el" href="group__nnfullyconnect.html#gad09cca4af5af99ea8c169222a235b87f">bias_lshift</a>, const uint16_t <a class="el" href="group__nnfullyconnect.html#ga8dd64794329e763d76515d7434831c97">out_rshift</a>, q7_t *out_tensor, const uint16_t out_tensor_dim, q15_t *<a class="el" href="group__nnfullyconnect.html#ga4972f5e62722e743bc2e14d86e130148">in_tmp_buf</a>, q7_t *tmp_buf)</td></tr>
<tr class="memdesc:ga48801812baf4ac44d8f420656e0d344e"><td class="mdescLeft">&#160;</td><td class="mdescRight">This function performs signed 8-bit integer convolution for RGB images with shift-based quantization on the outputs.  <br /></td></tr>
<tr class="separator:ga48801812baf4ac44d8f420656e0d344e"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:gacb280da3e5ee9dae757454a6f9fde55a" id="r_gacb280da3e5ee9dae757454a6f9fde55a"><td class="memItemLeft" align="right" valign="top">static int32_t&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#gacb280da3e5ee9dae757454a6f9fde55a">hpm_nn_conv_HWC_s8_s8_s8_RGB_sft_bias_fast</a> (const q7_t *in_tensor, const uint16_t in_tensor_dim, const q7_t *ker_weight, const uint16_t out_tensor_ch, const uint16_t ker_dim, const uint16_t pad, const uint16_t stride, const q7_t *<a class="el" href="group__nnfullyconnect.html#ga602e28fc157c370e73e4df5712f9df84">bias</a>, const uint16_t <a class="el" href="group__nnfullyconnect.html#gad09cca4af5af99ea8c169222a235b87f">bias_lshift</a>, const uint16_t <a class="el" href="group__nnfullyconnect.html#ga8dd64794329e763d76515d7434831c97">out_rshift</a>, q7_t *out_tensor, const uint16_t out_tensor_dim, q15_t *<a class="el" href="group__nnfullyconnect.html#ga4972f5e62722e743bc2e14d86e130148">in_tmp_buf</a>, q15_t *wt_tmp_buf)</td></tr>
<tr class="memdesc:gacb280da3e5ee9dae757454a6f9fde55a"><td class="mdescLeft">&#160;</td><td class="mdescRight">This function performs fast signed 8-bit integer convolution for RGB images with shift-based quantization on the outputs.  <br /></td></tr>
<tr class="separator:gacb280da3e5ee9dae757454a6f9fde55a"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ga4289d8b8bf7de39fe2ec6716aeb1fb21" id="r_ga4289d8b8bf7de39fe2ec6716aeb1fb21"><td class="memItemLeft" align="right" valign="top">static int32_t&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#ga4289d8b8bf7de39fe2ec6716aeb1fb21">hpm_nn_conv_HWC_s8_s8_s8_sft_bias</a> (const q7_t *in_tensor, const uint16_t in_tensor_dim, const uint16_t in_tensor_ch, const q7_t *ker_weight, const uint16_t out_tensor_ch, const uint16_t ker_dim, const uint16_t pad, const uint16_t stride, const q7_t *<a class="el" href="group__nnfullyconnect.html#ga602e28fc157c370e73e4df5712f9df84">bias</a>, const uint16_t <a class="el" href="group__nnfullyconnect.html#gad09cca4af5af99ea8c169222a235b87f">bias_lshift</a>, const uint16_t <a class="el" href="group__nnfullyconnect.html#ga8dd64794329e763d76515d7434831c97">out_rshift</a>, q7_t *out_tensor, const uint16_t out_tensor_dim, q15_t *<a class="el" href="group__nnfullyconnect.html#ga4972f5e62722e743bc2e14d86e130148">in_tmp_buf</a>, q7_t *tmp_buf)</td></tr>
<tr class="memdesc:ga4289d8b8bf7de39fe2ec6716aeb1fb21"><td class="mdescLeft">&#160;</td><td class="mdescRight">This function performs signed 8-bit integer convolution with shift-based quantization on the outputs.  <br /></td></tr>
<tr class="separator:ga4289d8b8bf7de39fe2ec6716aeb1fb21"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:gaa3bea4019638b22edc46a625f5cf7cce" id="r_gaa3bea4019638b22edc46a625f5cf7cce"><td class="memItemLeft" align="right" valign="top">static void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#gaa3bea4019638b22edc46a625f5cf7cce">hpm_nn_conv_HWC_s8_s8_s8_sft_bias_any</a> (const q7_t *in_tensor, const uint16_t in_tensor_dim_x, const uint16_t in_tensor_dim_y, const uint16_t in_tensor_ch, const q7_t *ker_weight, const uint16_t out_tensor_ch, const uint16_t ker_dim_x, const uint16_t ker_dim_y, const uint16_t pad_x, const uint16_t pad_y, const uint16_t stride_x, const uint16_t stride_y, const q7_t *<a class="el" href="group__nnfullyconnect.html#ga602e28fc157c370e73e4df5712f9df84">bias</a>, const uint16_t <a class="el" href="group__nnfullyconnect.html#gad09cca4af5af99ea8c169222a235b87f">bias_lshift</a>, const uint16_t <a class="el" href="group__nnfullyconnect.html#ga8dd64794329e763d76515d7434831c97">out_rshift</a>, q7_t *out_tensor, const uint16_t out_tensor_dim_x, const uint16_t out_tensor_dim_y, q15_t *<a class="el" href="group__nnfullyconnect.html#ga4972f5e62722e743bc2e14d86e130148">in_tmp_buf</a>, q7_t *tmp_buf)</td></tr>
<tr class="memdesc:gaa3bea4019638b22edc46a625f5cf7cce"><td class="mdescLeft">&#160;</td><td class="mdescRight">This function performs signed 8-bit integer convolution in any x and y dimensions with shift-based quantization on the outputs.  <br /></td></tr>
<tr class="separator:gaa3bea4019638b22edc46a625f5cf7cce"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:gad9c7a0bfeedea12c13702a7b85f6045b" id="r_gad9c7a0bfeedea12c13702a7b85f6045b"><td class="memItemLeft" align="right" valign="top">static int32_t&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#gad9c7a0bfeedea12c13702a7b85f6045b">hpm_nn_conv_HWC_s8_s8_s8_sft_bias_fast</a> (const q7_t *in_tensor, const uint16_t in_tensor_dim, const uint16_t in_tensor_ch, const q7_t *ker_weight, const uint16_t out_tensor_ch, const uint16_t ker_dim, const uint16_t pad, const uint16_t stride, const q7_t *<a class="el" href="group__nnfullyconnect.html#ga602e28fc157c370e73e4df5712f9df84">bias</a>, const uint16_t <a class="el" href="group__nnfullyconnect.html#gad09cca4af5af99ea8c169222a235b87f">bias_lshift</a>, const uint16_t <a class="el" href="group__nnfullyconnect.html#ga8dd64794329e763d76515d7434831c97">out_rshift</a>, q7_t *out_tensor, const uint16_t out_tensor_dim, q15_t *<a class="el" href="group__nnfullyconnect.html#ga4972f5e62722e743bc2e14d86e130148">in_tmp_buf</a>, q7_t *tmp_buf)</td></tr>
<tr class="memdesc:gad9c7a0bfeedea12c13702a7b85f6045b"><td class="mdescLeft">&#160;</td><td class="mdescRight">This function performs fast signed 8-bit integer convolution with shift-based quantization on the outputs.  <br /></td></tr>
<tr class="separator:gad9c7a0bfeedea12c13702a7b85f6045b"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ga6ebc094b7ca8a8eb46c249c165dc0990" id="r_ga6ebc094b7ca8a8eb46c249c165dc0990"><td class="memItemLeft" align="right" valign="top">static int32_t&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#ga6ebc094b7ca8a8eb46c249c165dc0990">hpm_nn_conv_HWC_s8_s8_s8_sft_bias_fast_any</a> (const q7_t *in_tensor, const uint16_t in_tensor_dim_x, const uint16_t in_tensor_dim_y, const uint16_t in_tensor_ch, const q7_t *ker_weight, const uint16_t out_tensor_ch, const uint16_t ker_dim_x, const uint16_t ker_dim_y, const uint16_t pad_x, const uint16_t pad_y, const uint16_t stride_x, const uint16_t stride_y, const q7_t *<a class="el" href="group__nnfullyconnect.html#ga602e28fc157c370e73e4df5712f9df84">bias</a>, const uint16_t <a class="el" href="group__nnfullyconnect.html#gad09cca4af5af99ea8c169222a235b87f">bias_lshift</a>, const uint16_t <a class="el" href="group__nnfullyconnect.html#ga8dd64794329e763d76515d7434831c97">out_rshift</a>, q7_t *out_tensor, const uint16_t out_tensor_dim_x, const uint16_t out_tensor_dim_y, q15_t *<a class="el" href="group__nnfullyconnect.html#ga4972f5e62722e743bc2e14d86e130148">in_tmp_buf</a>, q7_t *tmp_buf)</td></tr>
<tr class="memdesc:ga6ebc094b7ca8a8eb46c249c165dc0990"><td class="mdescLeft">&#160;</td><td class="mdescRight">This function performs fast signed 8-bit integer convolution in any x and y dimensions with shift-based quantization on the outputs.  <br /></td></tr>
<tr class="separator:ga6ebc094b7ca8a8eb46c249c165dc0990"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:gae45d9ea581aa690f6bc604878b7ff56a" id="r_gae45d9ea581aa690f6bc604878b7ff56a"><td class="memItemLeft" align="right" valign="top">static int32_t&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#gae45d9ea581aa690f6bc604878b7ff56a">hpm_nn_conv_HWC_s16_s16_s16_sft_bias</a> (const q15_t *in_tensor, const uint16_t in_tensor_dim, const uint16_t in_tensor_ch, const q15_t *ker_weight, const uint16_t out_tensor_ch, const uint16_t ker_dim, const uint16_t pad, const uint16_t stride, const q15_t *<a class="el" href="group__nnfullyconnect.html#ga602e28fc157c370e73e4df5712f9df84">bias</a>, const uint16_t <a class="el" href="group__nnfullyconnect.html#gad09cca4af5af99ea8c169222a235b87f">bias_lshift</a>, const uint16_t <a class="el" href="group__nnfullyconnect.html#ga8dd64794329e763d76515d7434831c97">out_rshift</a>, q15_t *out_tensor, const uint16_t out_tensor_dim, q15_t *<a class="el" href="group__nnfullyconnect.html#ga4972f5e62722e743bc2e14d86e130148">in_tmp_buf</a>, q7_t *tmp_buf)</td></tr>
<tr class="memdesc:gae45d9ea581aa690f6bc604878b7ff56a"><td class="mdescLeft">&#160;</td><td class="mdescRight">This function performs signed 16-bit integer convolution with shift-based quantization on the outputs.  <br /></td></tr>
<tr class="separator:gae45d9ea581aa690f6bc604878b7ff56a"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ga2ad7e5bbd56df8f95bd183850900ff56" id="r_ga2ad7e5bbd56df8f95bd183850900ff56"><td class="memItemLeft" align="right" valign="top">static int32_t&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#ga2ad7e5bbd56df8f95bd183850900ff56">hpm_nn_conv_HWC_s16_s16_s16_sft_bias_fast</a> (const q15_t *in_tensor, const uint16_t in_tensor_dim, const uint16_t in_tensor_ch, const q15_t *ker_weight, const uint16_t out_tensor_ch, const uint16_t ker_dim, const uint16_t pad, const uint16_t stride, const q15_t *<a class="el" href="group__nnfullyconnect.html#ga602e28fc157c370e73e4df5712f9df84">bias</a>, const uint16_t <a class="el" href="group__nnfullyconnect.html#gad09cca4af5af99ea8c169222a235b87f">bias_lshift</a>, const uint16_t <a class="el" href="group__nnfullyconnect.html#ga8dd64794329e763d76515d7434831c97">out_rshift</a>, q15_t *out_tensor, const uint16_t out_tensor_dim, q15_t *<a class="el" href="group__nnfullyconnect.html#ga4972f5e62722e743bc2e14d86e130148">in_tmp_buf</a>, q7_t *tmp_buf)</td></tr>
<tr class="memdesc:ga2ad7e5bbd56df8f95bd183850900ff56"><td class="mdescLeft">&#160;</td><td class="mdescRight">This function performs fast signed 16-bit integer convolution with shift-based quantization on the outputs.  <br /></td></tr>
<tr class="separator:ga2ad7e5bbd56df8f95bd183850900ff56"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:gab92665e531cb2e24620d923c487f5697" id="r_gab92665e531cb2e24620d923c487f5697"><td class="memItemLeft" align="right" valign="top">static int32_t&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#gab92665e531cb2e24620d923c487f5697">hpm_nn_conv_HWC_s16_s16_s16_sft_bias_fast_any</a> (const q15_t *in_tensor, const uint16_t in_tensor_dim_x, const uint16_t in_tensor_dim_y, const uint16_t in_tensor_ch, const q15_t *ker_weight, const uint16_t out_tensor_ch, const uint16_t ker_dim_x, const uint16_t ker_dim_y, const uint16_t pad_x, const uint16_t pad_y, const uint16_t stride_x, const uint16_t stride_y, const q15_t *<a class="el" href="group__nnfullyconnect.html#ga602e28fc157c370e73e4df5712f9df84">bias</a>, const uint16_t <a class="el" href="group__nnfullyconnect.html#gad09cca4af5af99ea8c169222a235b87f">bias_lshift</a>, const uint16_t <a class="el" href="group__nnfullyconnect.html#ga8dd64794329e763d76515d7434831c97">out_rshift</a>, q15_t *out_tensor, const uint16_t out_tensor_dim_x, const uint16_t out_tensor_dim_y, q15_t *<a class="el" href="group__nnfullyconnect.html#ga4972f5e62722e743bc2e14d86e130148">in_tmp_buf</a>, q7_t *tmp_buf)</td></tr>
<tr class="memdesc:gab92665e531cb2e24620d923c487f5697"><td class="mdescLeft">&#160;</td><td class="mdescRight">This function performs fast signed 16-bit integer convolution in any x and y dimensions with shift-based quantization on the outputs.  <br /></td></tr>
<tr class="separator:gab92665e531cb2e24620d923c487f5697"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ga14a5303eb12476d8342725b778f3d60f" id="r_ga14a5303eb12476d8342725b778f3d60f"><td class="memItemLeft" align="right" valign="top">static int32_t&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#ga14a5303eb12476d8342725b778f3d60f">hpm_nn_conv_dw_HWC_s8_s8_s8_sft_bias</a> (const q7_t *in_tensor, const uint16_t in_tensor_dim, const uint16_t in_tensor_ch, const q7_t *ker_weight, const uint16_t out_tensor_ch, const uint16_t ker_dim, const uint16_t pad, const uint16_t stride, const q7_t *<a class="el" href="group__nnfullyconnect.html#ga602e28fc157c370e73e4df5712f9df84">bias</a>, const uint16_t <a class="el" href="group__nnfullyconnect.html#gad09cca4af5af99ea8c169222a235b87f">bias_lshift</a>, const uint16_t <a class="el" href="group__nnfullyconnect.html#ga8dd64794329e763d76515d7434831c97">out_rshift</a>, q7_t *out_tensor, const uint16_t out_tensor_dim, q15_t *<a class="el" href="group__nnfullyconnect.html#ga4972f5e62722e743bc2e14d86e130148">in_tmp_buf</a>, q7_t *tmp_buf)</td></tr>
<tr class="memdesc:ga14a5303eb12476d8342725b778f3d60f"><td class="mdescLeft">&#160;</td><td class="mdescRight">This function performs signed 8-bit integer depthwise convolution with shift-based quantization on the outputs.  <br /></td></tr>
<tr class="separator:ga14a5303eb12476d8342725b778f3d60f"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:gacbd18e7251df9494ddf4619156237efd" id="r_gacbd18e7251df9494ddf4619156237efd"><td class="memItemLeft" align="right" valign="top">static int32_t&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#gacbd18e7251df9494ddf4619156237efd">hpm_nn_conv_dw_HWC_s8_s8_s8_sft_bias_any</a> (const q7_t *in_tensor, const uint16_t in_tensor_dim_x, const uint16_t in_tensor_dim_y, const uint16_t in_tensor_ch, const q7_t *ker_weight, const uint16_t out_tensor_ch, const uint16_t ker_dim_x, const uint16_t ker_dim_y, const uint16_t pad_x, const uint16_t pad_y, const uint16_t stride_x, const uint16_t stride_y, const q7_t *<a class="el" href="group__nnfullyconnect.html#ga602e28fc157c370e73e4df5712f9df84">bias</a>, const uint16_t <a class="el" href="group__nnfullyconnect.html#gad09cca4af5af99ea8c169222a235b87f">bias_lshift</a>, const uint16_t <a class="el" href="group__nnfullyconnect.html#ga8dd64794329e763d76515d7434831c97">out_rshift</a>, q7_t *out_tensor, const uint16_t out_tensor_dim_x, const uint16_t out_tensor_dim_y, q15_t *<a class="el" href="group__nnfullyconnect.html#ga4972f5e62722e743bc2e14d86e130148">in_tmp_buf</a>, q7_t *tmp_buf)</td></tr>
<tr class="memdesc:gacbd18e7251df9494ddf4619156237efd"><td class="mdescLeft">&#160;</td><td class="mdescRight">This function performs signed 8-bit integer depthwise convolution in any x and y dimensions with shift-based quantization on the outputs.  <br /></td></tr>
<tr class="separator:gacbd18e7251df9494ddf4619156237efd"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ga291d3433cfdeac37ddedd621e0cea855" id="r_ga291d3433cfdeac37ddedd621e0cea855"><td class="memItemLeft" align="right" valign="top">static int32_t&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#ga291d3433cfdeac37ddedd621e0cea855">hpm_nn_conv_1x1_HWC_s8_s8_s8_sym_bias_fast_any</a> (const q7_t *in_tensor, const uint16_t in_tensor_dim_x, const uint16_t in_tensor_dim_y, const uint16_t in_tensor_ch, const q7_t *ker_weight, const uint16_t out_tensor_ch, const uint16_t ker_dim_x, const uint16_t ker_dim_y, const uint16_t pad_x, const uint16_t pad_y, const uint16_t stride_x, const uint16_t stride_y, const q31_t *<a class="el" href="group__nnfullyconnect.html#ga602e28fc157c370e73e4df5712f9df84">bias</a>, const uint16_t pre_rshift, const uint16_t out_scale, const uint16_t post_rshift, q7_t *out_tensor, const uint16_t out_tensor_dim_x, const uint16_t out_tensor_dim_y, q15_t *<a class="el" href="group__nnfullyconnect.html#ga4972f5e62722e743bc2e14d86e130148">in_tmp_buf</a>)</td></tr>
<tr class="memdesc:ga291d3433cfdeac37ddedd621e0cea855"><td class="mdescLeft">&#160;</td><td class="mdescRight">This function performs 1x1 kernels convolution for signed 8-bit integer inputs/outputs in any x and y dimensions with bias inputs and symmetric quantization on the outputs..  <br /></td></tr>
<tr class="separator:ga291d3433cfdeac37ddedd621e0cea855"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:gab36c58937982cb251a299463e48ff357" id="r_gab36c58937982cb251a299463e48ff357"><td class="memItemLeft" align="right" valign="top">static int32_t&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#gab36c58937982cb251a299463e48ff357">hpm_nn_conv_1x1_HWC_s8_s16_s8_sym_bias_fast_any</a> (const q7_t *in_tensor, const uint16_t in_tensor_dim_x, const uint16_t in_tensor_dim_y, const uint16_t in_tensor_ch, const q7_t *ker_weight, const uint16_t out_tensor_ch, const uint16_t ker_dim_x, const uint16_t ker_dim_y, const uint16_t pad_x, const uint16_t pad_y, const uint16_t stride_x, const uint16_t stride_y, const q31_t *<a class="el" href="group__nnfullyconnect.html#ga602e28fc157c370e73e4df5712f9df84">bias</a>, const uint16_t pre_rshift, const uint16_t out_scale, const uint16_t post_rshift, q15_t *out_tensor, const uint16_t out_tensor_dim_x, const uint16_t out_tensor_dim_y, q15_t *<a class="el" href="group__nnfullyconnect.html#ga4972f5e62722e743bc2e14d86e130148">in_tmp_buf</a>)</td></tr>
<tr class="memdesc:gab36c58937982cb251a299463e48ff357"><td class="mdescLeft">&#160;</td><td class="mdescRight">This function performs 1x1 kernels convolution for signed 8-bit integer inputs and signed 16-bit integer outputs in any x and y dimensions with bias inputs and symmetric quantization on the outputs.  <br /></td></tr>
<tr class="separator:gab36c58937982cb251a299463e48ff357"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:gad97f5d188a38e067ca8afe1d26a3f9e6" id="r_gad97f5d188a38e067ca8afe1d26a3f9e6"><td class="memItemLeft" align="right" valign="top">static int32_t&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#gad97f5d188a38e067ca8afe1d26a3f9e6">hpm_nn_conv_1x1_HWC_u8_u8_s8_sym_bias_fast_any</a> (const u8_t *in_tensor, const uint16_t in_tensor_dim_x, const uint16_t in_tensor_dim_y, const uint16_t in_tensor_ch, const q7_t *ker_weight, const uint16_t out_tensor_ch, const uint16_t ker_dim_x, const uint16_t ker_dim_y, const uint16_t pad_x, const uint16_t pad_y, const uint16_t stride_x, const uint16_t stride_y, const q31_t *<a class="el" href="group__nnfullyconnect.html#ga602e28fc157c370e73e4df5712f9df84">bias</a>, const uint16_t pre_rshift, const uint16_t out_scale, const uint16_t post_rshift, u8_t *out_tensor, const uint16_t out_tensor_dim_x, const uint16_t out_tensor_dim_y, q15_t *<a class="el" href="group__nnfullyconnect.html#ga4972f5e62722e743bc2e14d86e130148">in_tmp_buf</a>)</td></tr>
<tr class="memdesc:gad97f5d188a38e067ca8afe1d26a3f9e6"><td class="mdescLeft">&#160;</td><td class="mdescRight">This function performs 1x1 kernels convolution for unsigned 8-bit integer inputs/outputs in any x and y dimensions with bias inputs and symmetric quantization on the outputs.  <br /></td></tr>
<tr class="separator:gad97f5d188a38e067ca8afe1d26a3f9e6"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ga1ee3747f0f50187370bb25d91b412447" id="r_ga1ee3747f0f50187370bb25d91b412447"><td class="memItemLeft" align="right" valign="top">static int32_t&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#ga1ee3747f0f50187370bb25d91b412447">hpm_nn_conv_1x1_HWC_u8_s8_s8_sym_bias_fast_any</a> (const u8_t *in_tensor, const uint16_t in_tensor_dim_x, const uint16_t in_tensor_dim_y, const uint16_t in_tensor_ch, const q7_t *ker_weight, const uint16_t out_tensor_ch, const uint16_t ker_dim_x, const uint16_t ker_dim_y, const uint16_t pad_x, const uint16_t pad_y, const uint16_t stride_x, const uint16_t stride_y, const q31_t *<a class="el" href="group__nnfullyconnect.html#ga602e28fc157c370e73e4df5712f9df84">bias</a>, const uint16_t pre_rshift, const uint16_t out_scale, const uint16_t post_rshift, q7_t *out_tensor, const uint16_t out_tensor_dim_x, const uint16_t out_tensor_dim_y, q15_t *<a class="el" href="group__nnfullyconnect.html#ga4972f5e62722e743bc2e14d86e130148">in_tmp_buf</a>)</td></tr>
<tr class="memdesc:ga1ee3747f0f50187370bb25d91b412447"><td class="mdescLeft">&#160;</td><td class="mdescRight">This function performs 1x1 kernels convolution for unsigned 8-bit integer inputs and signed 8-bit integer outputs in any x and y dimensions with bias inputs and symmetric quantization on the outputs.  <br /></td></tr>
<tr class="separator:ga1ee3747f0f50187370bb25d91b412447"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:gac7a64479b1a28db67739740f7797c0ad" id="r_gac7a64479b1a28db67739740f7797c0ad"><td class="memItemLeft" align="right" valign="top">static int32_t&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#gac7a64479b1a28db67739740f7797c0ad">hpm_nn_conv_1x1_HWC_u8_s16_s8_sym_bias_fast_any</a> (const u8_t *in_tensor, const uint16_t in_tensor_dim_x, const uint16_t in_tensor_dim_y, const uint16_t in_tensor_ch, const q7_t *ker_weight, const uint16_t out_tensor_ch, const uint16_t ker_dim_x, const uint16_t ker_dim_y, const uint16_t pad_x, const uint16_t pad_y, const uint16_t stride_x, const uint16_t stride_y, const q31_t *<a class="el" href="group__nnfullyconnect.html#ga602e28fc157c370e73e4df5712f9df84">bias</a>, const uint16_t pre_rshift, const uint16_t out_scale, const uint16_t post_rshift, q15_t *out_tensor, const uint16_t out_tensor_dim_x, const uint16_t out_tensor_dim_y, q15_t *<a class="el" href="group__nnfullyconnect.html#ga4972f5e62722e743bc2e14d86e130148">in_tmp_buf</a>)</td></tr>
<tr class="memdesc:gac7a64479b1a28db67739740f7797c0ad"><td class="mdescLeft">&#160;</td><td class="mdescRight">This function performs 1x1 kernels convolution for unsigned 8-bit integer inputs and signed 16-bit integer outputs in any x and y dimensions with bias inputs and symmetric quantization on the outputs.  <br /></td></tr>
<tr class="separator:gac7a64479b1a28db67739740f7797c0ad"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ga1353634c6dd78e51d72ad649f1851741" id="r_ga1353634c6dd78e51d72ad649f1851741"><td class="memItemLeft" align="right" valign="top">static int32_t&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#ga1353634c6dd78e51d72ad649f1851741">hpm_nn_conv_1x1_HWC_s8_s8_s8_sym_fast_any</a> (const q7_t *in_tensor, const uint16_t in_tensor_dim_x, const uint16_t in_tensor_dim_y, const uint16_t in_tensor_ch, const q7_t *ker_weight, const uint16_t out_tensor_ch, const uint16_t ker_dim_x, const uint16_t ker_dim_y, const uint16_t pad_x, const uint16_t pad_y, const uint16_t stride_x, const uint16_t stride_y, const uint16_t pre_rshift, const uint16_t out_scale, const uint16_t post_rshift, q7_t *out_tensor, const uint16_t out_tensor_dim_x, const uint16_t out_tensor_dim_y, q15_t *<a class="el" href="group__nnfullyconnect.html#ga4972f5e62722e743bc2e14d86e130148">in_tmp_buf</a>)</td></tr>
<tr class="memdesc:ga1353634c6dd78e51d72ad649f1851741"><td class="mdescLeft">&#160;</td><td class="mdescRight">This function performs 1x1 kernels convolution for signed 8-bit integer inputs/outputs in any x and y dimensions with symmetric quantization on the outputs.  <br /></td></tr>
<tr class="separator:ga1353634c6dd78e51d72ad649f1851741"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ga40b28637cd642db0f36e19b0c5008433" id="r_ga40b28637cd642db0f36e19b0c5008433"><td class="memItemLeft" align="right" valign="top">static int32_t&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#ga40b28637cd642db0f36e19b0c5008433">hpm_nn_conv_1x1_HWC_s8_s16_s8_sym_fast_any</a> (const q7_t *in_tensor, const uint16_t in_tensor_dim_x, const uint16_t in_tensor_dim_y, const uint16_t in_tensor_ch, const q7_t *ker_weight, const uint16_t out_tensor_ch, const uint16_t ker_dim_x, const uint16_t ker_dim_y, const uint16_t pad_x, const uint16_t pad_y, const uint16_t stride_x, const uint16_t stride_y, const uint16_t pre_rshift, const uint16_t out_scale, const uint16_t post_rshift, q15_t *out_tensor, const uint16_t out_tensor_dim_x, const uint16_t out_tensor_dim_y, q15_t *<a class="el" href="group__nnfullyconnect.html#ga4972f5e62722e743bc2e14d86e130148">in_tmp_buf</a>)</td></tr>
<tr class="memdesc:ga40b28637cd642db0f36e19b0c5008433"><td class="mdescLeft">&#160;</td><td class="mdescRight">This function performs 1x1 kernels convolution for signed 8-bit integer inputs and signed 16-bit integer outputs in any x and y dimensions with symmetric quantization on the outputs.  <br /></td></tr>
<tr class="separator:ga40b28637cd642db0f36e19b0c5008433"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ga1a24af57ab9a2be65f085e36c0c80520" id="r_ga1a24af57ab9a2be65f085e36c0c80520"><td class="memItemLeft" align="right" valign="top">static int32_t&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#ga1a24af57ab9a2be65f085e36c0c80520">hpm_nn_conv_1x1_HWC_u8_u8_s8_sym_fast_any</a> (const u8_t *in_tensor, const uint16_t in_tensor_dim_x, const uint16_t in_tensor_dim_y, const uint16_t in_tensor_ch, const q7_t *ker_weight, const uint16_t out_tensor_ch, const uint16_t ker_dim_x, const uint16_t ker_dim_y, const uint16_t pad_x, const uint16_t pad_y, const uint16_t stride_x, const uint16_t stride_y, const uint16_t pre_rshift, const uint16_t out_scale, const uint16_t post_rshift, u8_t *out_tensor, const uint16_t out_tensor_dim_x, const uint16_t out_tensor_dim_y, q15_t *<a class="el" href="group__nnfullyconnect.html#ga4972f5e62722e743bc2e14d86e130148">in_tmp_buf</a>)</td></tr>
<tr class="memdesc:ga1a24af57ab9a2be65f085e36c0c80520"><td class="mdescLeft">&#160;</td><td class="mdescRight">This function performs 1x1 kernels convolution for unsigned 8-bit integer inputs/outputs in any x and y dimensions with symmetric quantization on the outputs.  <br /></td></tr>
<tr class="separator:ga1a24af57ab9a2be65f085e36c0c80520"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ga13dceb3700caa3c22c53bd7f6017a40d" id="r_ga13dceb3700caa3c22c53bd7f6017a40d"><td class="memItemLeft" align="right" valign="top">static int32_t&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#ga13dceb3700caa3c22c53bd7f6017a40d">hpm_nn_conv_1x1_HWC_u8_s8_s8_sym_fast_any</a> (const u8_t *in_tensor, const uint16_t in_tensor_dim_x, const uint16_t in_tensor_dim_y, const uint16_t in_tensor_ch, const q7_t *ker_weight, const uint16_t out_tensor_ch, const uint16_t ker_dim_x, const uint16_t ker_dim_y, const uint16_t pad_x, const uint16_t pad_y, const uint16_t stride_x, const uint16_t stride_y, const uint16_t pre_rshift, const uint16_t out_scale, const uint16_t post_rshift, q7_t *out_tensor, const uint16_t out_tensor_dim_x, const uint16_t out_tensor_dim_y, q15_t *<a class="el" href="group__nnfullyconnect.html#ga4972f5e62722e743bc2e14d86e130148">in_tmp_buf</a>)</td></tr>
<tr class="memdesc:ga13dceb3700caa3c22c53bd7f6017a40d"><td class="mdescLeft">&#160;</td><td class="mdescRight">This function performs 1x1 kernels convolution for unsigned 8-bit integer inputs and signed 8-bit integer outputs in any x and y dimensions with symmetric quantization on the outputs.  <br /></td></tr>
<tr class="separator:ga13dceb3700caa3c22c53bd7f6017a40d"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ga2e95b6dd2dc0ebe0fb31b4ce4e97b5c0" id="r_ga2e95b6dd2dc0ebe0fb31b4ce4e97b5c0"><td class="memItemLeft" align="right" valign="top">static int32_t&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#ga2e95b6dd2dc0ebe0fb31b4ce4e97b5c0">hpm_nn_conv_1x1_HWC_u8_s16_s8_sym_fast_any</a> (const u8_t *in_tensor, const uint16_t in_tensor_dim_x, const uint16_t in_tensor_dim_y, const uint16_t in_tensor_ch, const q7_t *ker_weight, const uint16_t out_tensor_ch, const uint16_t ker_dim_x, const uint16_t ker_dim_y, const uint16_t pad_x, const uint16_t pad_y, const uint16_t stride_x, const uint16_t stride_y, const uint16_t pre_rshift, const uint16_t out_scale, const uint16_t post_rshift, q15_t *out_tensor, const uint16_t out_tensor_dim_x, const uint16_t out_tensor_dim_y, q15_t *<a class="el" href="group__nnfullyconnect.html#ga4972f5e62722e743bc2e14d86e130148">in_tmp_buf</a>)</td></tr>
<tr class="memdesc:ga2e95b6dd2dc0ebe0fb31b4ce4e97b5c0"><td class="mdescLeft">&#160;</td><td class="mdescRight">This function performs 1x1 kernels convolution for unsigned 8-bit integer inputs and signed 16-bit integer outputs in any x and y dimensions with symmetric quantization on the outputs.  <br /></td></tr>
<tr class="separator:ga2e95b6dd2dc0ebe0fb31b4ce4e97b5c0"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:gaeed17db639b9ce3a896bc2bfeaaeb8ed" id="r_gaeed17db639b9ce3a896bc2bfeaaeb8ed"><td class="memItemLeft" align="right" valign="top">static int32_t&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#gaeed17db639b9ce3a896bc2bfeaaeb8ed">hpm_nn_conv_HWC_s8_s8_s8_RGB_sym_bias_fast</a> (const q7_t *in_tensor, const uint16_t in_tensor_dim, const q7_t *ker_weight, const uint16_t out_tensor_ch, const uint16_t ker_dim, const uint16_t pad, const uint16_t stride, const q31_t *<a class="el" href="group__nnfullyconnect.html#ga602e28fc157c370e73e4df5712f9df84">bias</a>, const uint16_t pre_rshift, const uint16_t out_scale, const uint16_t post_rshift, q7_t *out_tensor, const uint16_t out_tensor_dim, q15_t *<a class="el" href="group__nnfullyconnect.html#ga4972f5e62722e743bc2e14d86e130148">in_tmp_buf</a>, q15_t *wt_tmp_buf)</td></tr>
<tr class="memdesc:gaeed17db639b9ce3a896bc2bfeaaeb8ed"><td class="mdescLeft">&#160;</td><td class="mdescRight">This function performs fast convolution on RGB images for signed 8-bit integer inputs/outputs with bias inputs and symmetric quantization on the outputs.  <br /></td></tr>
<tr class="separator:gaeed17db639b9ce3a896bc2bfeaaeb8ed"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:gadbb401015033df936d4547841e0c6778" id="r_gadbb401015033df936d4547841e0c6778"><td class="memItemLeft" align="right" valign="top">static int32_t&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#gadbb401015033df936d4547841e0c6778">hpm_nn_conv_HWC_s8_s16_s8_RGB_sym_bias_fast</a> (const q7_t *in_tensor, const uint16_t in_tensor_dim, const q7_t *ker_weight, const uint16_t out_tensor_ch, const uint16_t ker_dim, const uint16_t pad, const uint16_t stride, const q31_t *<a class="el" href="group__nnfullyconnect.html#ga602e28fc157c370e73e4df5712f9df84">bias</a>, const uint16_t pre_rshift, const uint16_t out_scale, const uint16_t post_rshift, q15_t *out_tensor, const uint16_t out_tensor_dim, q15_t *<a class="el" href="group__nnfullyconnect.html#ga4972f5e62722e743bc2e14d86e130148">in_tmp_buf</a>, q15_t *wt_tmp_buf)</td></tr>
<tr class="memdesc:gadbb401015033df936d4547841e0c6778"><td class="mdescLeft">&#160;</td><td class="mdescRight">This function performs fast convolution on RGB images for signed 8-bit integer inputs and signed 16-bit integer outputs with bias inputs and symmetric quantization on the outputs.  <br /></td></tr>
<tr class="separator:gadbb401015033df936d4547841e0c6778"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:gae84e818d001cf7ea2c4331924f36e35e" id="r_gae84e818d001cf7ea2c4331924f36e35e"><td class="memItemLeft" align="right" valign="top">static int32_t&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#gae84e818d001cf7ea2c4331924f36e35e">hpm_nn_conv_HWC_u8_u8_s8_RGB_sym_bias_fast</a> (const u8_t *in_tensor, const uint16_t in_tensor_dim, const q7_t *ker_weight, const uint16_t out_tensor_ch, const uint16_t ker_dim, const uint16_t pad, const uint16_t stride, const q31_t *<a class="el" href="group__nnfullyconnect.html#ga602e28fc157c370e73e4df5712f9df84">bias</a>, const uint16_t pre_rshift, const uint16_t out_scale, const uint16_t post_rshift, u8_t *out_tensor, const uint16_t out_tensor_dim, q15_t *<a class="el" href="group__nnfullyconnect.html#ga4972f5e62722e743bc2e14d86e130148">in_tmp_buf</a>, q15_t *wt_tmp_buf)</td></tr>
<tr class="memdesc:gae84e818d001cf7ea2c4331924f36e35e"><td class="mdescLeft">&#160;</td><td class="mdescRight">This function performs fast convolution on RGB images for unsigned 8-bit integer inputs/outputs with symmetric quantization on the outputs.  <br /></td></tr>
<tr class="separator:gae84e818d001cf7ea2c4331924f36e35e"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ga02b99a74afdae934fc45f491a59d2214" id="r_ga02b99a74afdae934fc45f491a59d2214"><td class="memItemLeft" align="right" valign="top">static int32_t&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#ga02b99a74afdae934fc45f491a59d2214">hpm_nn_conv_HWC_u8_s8_s8_RGB_sym_bias_fast</a> (const u8_t *in_tensor, const uint16_t in_tensor_dim, const q7_t *ker_weight, const uint16_t out_tensor_ch, const uint16_t ker_dim, const uint16_t pad, const uint16_t stride, const q31_t *<a class="el" href="group__nnfullyconnect.html#ga602e28fc157c370e73e4df5712f9df84">bias</a>, const uint16_t pre_rshift, const uint16_t out_scale, const uint16_t post_rshift, q7_t *out_tensor, const uint16_t out_tensor_dim, q15_t *<a class="el" href="group__nnfullyconnect.html#ga4972f5e62722e743bc2e14d86e130148">in_tmp_buf</a>, q15_t *wt_tmp_buf)</td></tr>
<tr class="memdesc:ga02b99a74afdae934fc45f491a59d2214"><td class="mdescLeft">&#160;</td><td class="mdescRight">This function performs fast convolution on RGB images for signed 8-bit integer inputs/outputs with bias inputs and symmetric quantization on the outputs.  <br /></td></tr>
<tr class="separator:ga02b99a74afdae934fc45f491a59d2214"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ga3fbca4e04cca9289834c84a10a913a88" id="r_ga3fbca4e04cca9289834c84a10a913a88"><td class="memItemLeft" align="right" valign="top">static int32_t&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#ga3fbca4e04cca9289834c84a10a913a88">hpm_nn_conv_HWC_u8_s16_s8_RGB_sym_bias_fast</a> (const u8_t *in_tensor, const uint16_t in_tensor_dim, const q7_t *ker_weight, const uint16_t out_tensor_ch, const uint16_t ker_dim, const uint16_t pad, const uint16_t stride, const q31_t *<a class="el" href="group__nnfullyconnect.html#ga602e28fc157c370e73e4df5712f9df84">bias</a>, const uint16_t pre_rshift, const uint16_t out_scale, const uint16_t post_rshift, q15_t *out_tensor, const uint16_t out_tensor_dim, q15_t *<a class="el" href="group__nnfullyconnect.html#ga4972f5e62722e743bc2e14d86e130148">in_tmp_buf</a>, q15_t *wt_tmp_buf)</td></tr>
<tr class="memdesc:ga3fbca4e04cca9289834c84a10a913a88"><td class="mdescLeft">&#160;</td><td class="mdescRight">This function performs fast convolution on RGB images for unsigned 8-bit integer inputs and signed 16-bit integer outputs with bias inputs and symmetric quantization on the outputs.  <br /></td></tr>
<tr class="separator:ga3fbca4e04cca9289834c84a10a913a88"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:gac66363c7f5934113644361412bcf3afc" id="r_gac66363c7f5934113644361412bcf3afc"><td class="memItemLeft" align="right" valign="top">static int32_t&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#gac66363c7f5934113644361412bcf3afc">hpm_nn_conv_HWC_s8_s8_s8_RGB_sym_fast</a> (const q7_t *in_tensor, const uint16_t in_tensor_dim, const q7_t *ker_weight, const uint16_t out_tensor_ch, const uint16_t ker_dim, const uint16_t pad, const uint16_t stride, const uint16_t pre_rshift, const uint16_t out_scale, const uint16_t post_rshift, q7_t *out_tensor, const uint16_t out_tensor_dim, q15_t *<a class="el" href="group__nnfullyconnect.html#ga4972f5e62722e743bc2e14d86e130148">in_tmp_buf</a>, q15_t *wt_tmp_buf)</td></tr>
<tr class="memdesc:gac66363c7f5934113644361412bcf3afc"><td class="mdescLeft">&#160;</td><td class="mdescRight">This function performs fast convolution on RGB images for signed 8-bit integer inputs/outputs with symmetric quantization on the outputs.  <br /></td></tr>
<tr class="separator:gac66363c7f5934113644361412bcf3afc"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ga760c3e28022de0cc9781549ec67b472a" id="r_ga760c3e28022de0cc9781549ec67b472a"><td class="memItemLeft" align="right" valign="top">static int32_t&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#ga760c3e28022de0cc9781549ec67b472a">hpm_nn_conv_HWC_s8_s16_s8_RGB_sym_fast</a> (const q7_t *in_tensor, const uint16_t in_tensor_dim, const q7_t *ker_weight, const uint16_t out_tensor_ch, const uint16_t ker_dim, const uint16_t pad, const uint16_t stride, const uint16_t pre_rshift, const uint16_t out_scale, const uint16_t post_rshift, q15_t *out_tensor, const uint16_t out_tensor_dim, q15_t *<a class="el" href="group__nnfullyconnect.html#ga4972f5e62722e743bc2e14d86e130148">in_tmp_buf</a>, q15_t *wt_tmp_buf)</td></tr>
<tr class="memdesc:ga760c3e28022de0cc9781549ec67b472a"><td class="mdescLeft">&#160;</td><td class="mdescRight">This function performs fast convolution on RGB images for signed 8-bit integer inputs and signed 16-bit integer outputs with symmetric quantization on the outputs.  <br /></td></tr>
<tr class="separator:ga760c3e28022de0cc9781549ec67b472a"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ga546898208090a68e33f99ced79470f5f" id="r_ga546898208090a68e33f99ced79470f5f"><td class="memItemLeft" align="right" valign="top">static int32_t&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#ga546898208090a68e33f99ced79470f5f">hpm_nn_conv_HWC_u8_u8_s8_RGB_sym_fast</a> (const u8_t *in_tensor, const uint16_t in_tensor_dim, const q7_t *ker_weight, const uint16_t out_tensor_ch, const uint16_t ker_dim, const uint16_t pad, const uint16_t stride, const uint16_t pre_rshift, const uint16_t out_scale, const uint16_t post_rshift, u8_t *out_tensor, const uint16_t out_tensor_dim, q15_t *<a class="el" href="group__nnfullyconnect.html#ga4972f5e62722e743bc2e14d86e130148">in_tmp_buf</a>, q15_t *wt_tmp_buf)</td></tr>
<tr class="memdesc:ga546898208090a68e33f99ced79470f5f"><td class="mdescLeft">&#160;</td><td class="mdescRight">This function performs fast convolution on RGB images for unsigned 8-bit integer inputs/outputs with symmetric quantization on the outputs.  <br /></td></tr>
<tr class="separator:ga546898208090a68e33f99ced79470f5f"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ga2f5d213d0023ff26d9ce168bfefa2a40" id="r_ga2f5d213d0023ff26d9ce168bfefa2a40"><td class="memItemLeft" align="right" valign="top">static int32_t&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#ga2f5d213d0023ff26d9ce168bfefa2a40">hpm_nn_conv_HWC_u8_s8_s8_RGB_sym_fast</a> (const u8_t *in_tensor, const uint16_t in_tensor_dim, const q7_t *ker_weight, const uint16_t out_tensor_ch, const uint16_t ker_dim, const uint16_t pad, const uint16_t stride, const uint16_t pre_rshift, const uint16_t out_scale, const uint16_t post_rshift, q7_t *out_tensor, const uint16_t out_tensor_dim, q15_t *<a class="el" href="group__nnfullyconnect.html#ga4972f5e62722e743bc2e14d86e130148">in_tmp_buf</a>, q15_t *wt_tmp_buf)</td></tr>
<tr class="memdesc:ga2f5d213d0023ff26d9ce168bfefa2a40"><td class="mdescLeft">&#160;</td><td class="mdescRight">This function performs fast convolution on RGB images for unsigned 8-bit integer inputs and signed 8-bit integer outputs with symmetric quantization on the outputs.  <br /></td></tr>
<tr class="separator:ga2f5d213d0023ff26d9ce168bfefa2a40"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ga30719ccfc86c77e8b4fde37011f8d543" id="r_ga30719ccfc86c77e8b4fde37011f8d543"><td class="memItemLeft" align="right" valign="top">static int32_t&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#ga30719ccfc86c77e8b4fde37011f8d543">hpm_nn_conv_HWC_u8_s16_s8_RGB_sym_fast</a> (const u8_t *in_tensor, const uint16_t in_tensor_dim, const q7_t *ker_weight, const uint16_t out_tensor_ch, const uint16_t ker_dim, const uint16_t pad, const uint16_t stride, const uint16_t pre_rshift, const uint16_t out_scale, const uint16_t post_rshift, q15_t *out_tensor, const uint16_t out_tensor_dim, q15_t *<a class="el" href="group__nnfullyconnect.html#ga4972f5e62722e743bc2e14d86e130148">in_tmp_buf</a>, q15_t *wt_tmp_buf)</td></tr>
<tr class="memdesc:ga30719ccfc86c77e8b4fde37011f8d543"><td class="mdescLeft">&#160;</td><td class="mdescRight">This function performs fast convolution on RGB images for unsigned 8-bit integer inputs and signed 16-bit integer outputs with symmetric quantization on the outputs.  <br /></td></tr>
<tr class="separator:ga30719ccfc86c77e8b4fde37011f8d543"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ga0bc1ef1d72db702cc49be0016a4180f8" id="r_ga0bc1ef1d72db702cc49be0016a4180f8"><td class="memItemLeft" align="right" valign="top">static int32_t&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#ga0bc1ef1d72db702cc49be0016a4180f8">hpm_nn_conv_HWC_s8_s8_s8_sym_bias_fast</a> (const q7_t *in_tensor, const uint16_t in_tensor_dim, const uint16_t in_tensor_ch, const q7_t *ker_weight, const uint16_t out_tensor_ch, const uint16_t ker_dim, const uint16_t pad, const uint16_t stride, const q31_t *<a class="el" href="group__nnfullyconnect.html#ga602e28fc157c370e73e4df5712f9df84">bias</a>, const uint16_t pre_rshift, const uint16_t out_scale, const uint16_t post_rshift, q7_t *out_tensor, const uint16_t out_tensor_dim, q15_t *<a class="el" href="group__nnfullyconnect.html#ga4972f5e62722e743bc2e14d86e130148">in_tmp_buf</a>)</td></tr>
<tr class="memdesc:ga0bc1ef1d72db702cc49be0016a4180f8"><td class="mdescLeft">&#160;</td><td class="mdescRight">This function performs fast convolution for signed 8-bit integer inputs/outputs with bias inputs and symmetric quantization on the outputs.  <br /></td></tr>
<tr class="separator:ga0bc1ef1d72db702cc49be0016a4180f8"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:gaa32181a4fa9730dd1aaff34473aad105" id="r_gaa32181a4fa9730dd1aaff34473aad105"><td class="memItemLeft" align="right" valign="top">static int32_t&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#gaa32181a4fa9730dd1aaff34473aad105">hpm_nn_conv_HWC_s8_s16_s8_sym_bias_fast</a> (const q7_t *in_tensor, const uint16_t in_tensor_dim, const uint16_t in_tensor_ch, const q7_t *ker_weight, const uint16_t out_tensor_ch, const uint16_t ker_dim, const uint16_t pad, const uint16_t stride, const q31_t *<a class="el" href="group__nnfullyconnect.html#ga602e28fc157c370e73e4df5712f9df84">bias</a>, const uint16_t pre_rshift, const uint16_t out_scale, const uint16_t post_rshift, q15_t *out_tensor, const uint16_t out_tensor_dim, q15_t *<a class="el" href="group__nnfullyconnect.html#ga4972f5e62722e743bc2e14d86e130148">in_tmp_buf</a>)</td></tr>
<tr class="memdesc:gaa32181a4fa9730dd1aaff34473aad105"><td class="mdescLeft">&#160;</td><td class="mdescRight">This function performs fast convolution for signed 8-bit integer inputs and signed 16-bit integer outputs with bias inputs and symmetric quantization on the outputs.  <br /></td></tr>
<tr class="separator:gaa32181a4fa9730dd1aaff34473aad105"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:gab00822cf6d1b355344c6385a2555dab4" id="r_gab00822cf6d1b355344c6385a2555dab4"><td class="memItemLeft" align="right" valign="top">static int32_t&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#gab00822cf6d1b355344c6385a2555dab4">hpm_nn_conv_HWC_u8_u8_s8_sym_bias_fast</a> (const u8_t *in_tensor, const uint16_t in_tensor_dim, const uint16_t in_tensor_ch, const q7_t *ker_weight, const uint16_t out_tensor_ch, const uint16_t ker_dim, const uint16_t pad, const uint16_t stride, const q31_t *<a class="el" href="group__nnfullyconnect.html#ga602e28fc157c370e73e4df5712f9df84">bias</a>, const uint16_t pre_rshift, const uint16_t out_scale, const uint16_t post_rshift, u8_t *out_tensor, const uint16_t out_tensor_dim, q15_t *<a class="el" href="group__nnfullyconnect.html#ga4972f5e62722e743bc2e14d86e130148">in_tmp_buf</a>)</td></tr>
<tr class="memdesc:gab00822cf6d1b355344c6385a2555dab4"><td class="mdescLeft">&#160;</td><td class="mdescRight">This function performs fast convolution for unsigned 8-bit integer inputs/outputs with bias inputs and symmetric quantization on the outputs.  <br /></td></tr>
<tr class="separator:gab00822cf6d1b355344c6385a2555dab4"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ga7cd15bdefc9684fc8c6dc5740bd973e6" id="r_ga7cd15bdefc9684fc8c6dc5740bd973e6"><td class="memItemLeft" align="right" valign="top">static int32_t&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#ga7cd15bdefc9684fc8c6dc5740bd973e6">hpm_nn_conv_HWC_u8_s8_s8_sym_bias_fast</a> (const u8_t *in_tensor, const uint16_t in_tensor_dim, const uint16_t in_tensor_ch, const q7_t *ker_weight, const uint16_t out_tensor_ch, const uint16_t ker_dim, const uint16_t pad, const uint16_t stride, const q31_t *<a class="el" href="group__nnfullyconnect.html#ga602e28fc157c370e73e4df5712f9df84">bias</a>, const uint16_t pre_rshift, const uint16_t out_scale, const uint16_t post_rshift, q7_t *out_tensor, const uint16_t out_tensor_dim, q15_t *<a class="el" href="group__nnfullyconnect.html#ga4972f5e62722e743bc2e14d86e130148">in_tmp_buf</a>)</td></tr>
<tr class="memdesc:ga7cd15bdefc9684fc8c6dc5740bd973e6"><td class="mdescLeft">&#160;</td><td class="mdescRight">This function performs fast convolution for unsigned 8-bit integer inputs and signed 8-bit integer outputs with bias inputs and symmetric quantization on the outputs.  <br /></td></tr>
<tr class="separator:ga7cd15bdefc9684fc8c6dc5740bd973e6"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ga14a05c18351cdbb2158cf1978e508f8c" id="r_ga14a05c18351cdbb2158cf1978e508f8c"><td class="memItemLeft" align="right" valign="top">static int32_t&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#ga14a05c18351cdbb2158cf1978e508f8c">hpm_nn_conv_HWC_u8_s16_s8_sym_bias_fast</a> (const u8_t *in_tensor, const uint16_t in_tensor_dim, const uint16_t in_tensor_ch, const q7_t *ker_weight, const uint16_t out_tensor_ch, const uint16_t ker_dim, const uint16_t pad, const uint16_t stride, const q31_t *<a class="el" href="group__nnfullyconnect.html#ga602e28fc157c370e73e4df5712f9df84">bias</a>, const uint16_t pre_rshift, const uint16_t out_scale, const uint16_t post_rshift, q15_t *out_tensor, const uint16_t out_tensor_dim, q15_t *<a class="el" href="group__nnfullyconnect.html#ga4972f5e62722e743bc2e14d86e130148">in_tmp_buf</a>)</td></tr>
<tr class="memdesc:ga14a05c18351cdbb2158cf1978e508f8c"><td class="mdescLeft">&#160;</td><td class="mdescRight">This function performs fast convolution for unsigned 8-bit integer inputs and signed 16-bit integer outputs with bias inputs and symmetric quantization on the outputs.  <br /></td></tr>
<tr class="separator:ga14a05c18351cdbb2158cf1978e508f8c"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:gaf85f4310b5b177044f48ea61614aaf10" id="r_gaf85f4310b5b177044f48ea61614aaf10"><td class="memItemLeft" align="right" valign="top">static int32_t&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#gaf85f4310b5b177044f48ea61614aaf10">hpm_nn_conv_HWC_s8_s8_s8_sym_fast</a> (const q7_t *in_tensor, const uint16_t in_tensor_dim, const uint16_t in_tensor_ch, const q7_t *ker_weight, const uint16_t out_tensor_ch, const uint16_t ker_dim, const uint16_t pad, const uint16_t stride, const uint16_t pre_rshift, const uint16_t out_scale, const uint16_t post_rshift, q7_t *out_tensor, const uint16_t out_tensor_dim, q15_t *<a class="el" href="group__nnfullyconnect.html#ga4972f5e62722e743bc2e14d86e130148">in_tmp_buf</a>)</td></tr>
<tr class="memdesc:gaf85f4310b5b177044f48ea61614aaf10"><td class="mdescLeft">&#160;</td><td class="mdescRight">This function performs fast convolution for signed 8-bit integer inputs/outputs with symmetric quantization on the outputs.  <br /></td></tr>
<tr class="separator:gaf85f4310b5b177044f48ea61614aaf10"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:gaba554ffd11e415541ebab72f6161915d" id="r_gaba554ffd11e415541ebab72f6161915d"><td class="memItemLeft" align="right" valign="top">static int32_t&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#gaba554ffd11e415541ebab72f6161915d">hpm_nn_conv_HWC_s8_s16_s8_sym_fast</a> (const q7_t *in_tensor, const uint16_t in_tensor_dim, const uint16_t in_tensor_ch, const q7_t *ker_weight, const uint16_t out_tensor_ch, const uint16_t ker_dim, const uint16_t pad, const uint16_t stride, const uint16_t pre_rshift, const uint16_t out_scale, const uint16_t post_rshift, q15_t *out_tensor, const uint16_t out_tensor_dim, q15_t *<a class="el" href="group__nnfullyconnect.html#ga4972f5e62722e743bc2e14d86e130148">in_tmp_buf</a>)</td></tr>
<tr class="memdesc:gaba554ffd11e415541ebab72f6161915d"><td class="mdescLeft">&#160;</td><td class="mdescRight">This function performs fast convolution for signed 8-bit integer inputs and signed 16-bit integer outputs with symmetric quantization on the outputs.  <br /></td></tr>
<tr class="separator:gaba554ffd11e415541ebab72f6161915d"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ga44f3d234a8ffe93b8cbc31e19ed49cc3" id="r_ga44f3d234a8ffe93b8cbc31e19ed49cc3"><td class="memItemLeft" align="right" valign="top">static int32_t&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#ga44f3d234a8ffe93b8cbc31e19ed49cc3">hpm_nn_conv_HWC_u8_u8_s8_sym_fast</a> (const u8_t *in_tensor, const uint16_t in_tensor_dim, const uint16_t in_tensor_ch, const q7_t *ker_weight, const uint16_t out_tensor_ch, const uint16_t ker_dim, const uint16_t pad, const uint16_t stride, const uint16_t pre_rshift, const uint16_t out_scale, const uint16_t post_rshift, u8_t *out_tensor, const uint16_t out_tensor_dim, q15_t *<a class="el" href="group__nnfullyconnect.html#ga4972f5e62722e743bc2e14d86e130148">in_tmp_buf</a>)</td></tr>
<tr class="memdesc:ga44f3d234a8ffe93b8cbc31e19ed49cc3"><td class="mdescLeft">&#160;</td><td class="mdescRight">This function performs fast convolution for unsigned 8-bit integer inputs/outputs with symmetric quantization on the outputs.  <br /></td></tr>
<tr class="separator:ga44f3d234a8ffe93b8cbc31e19ed49cc3"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ga681fd01c3db04f540acb48e080682acc" id="r_ga681fd01c3db04f540acb48e080682acc"><td class="memItemLeft" align="right" valign="top">static int32_t&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#ga681fd01c3db04f540acb48e080682acc">hpm_nn_conv_HWC_u8_s8_s8_sym_fast</a> (const u8_t *in_tensor, const uint16_t in_tensor_dim, const uint16_t in_tensor_ch, const q7_t *ker_weight, const uint16_t out_tensor_ch, const uint16_t ker_dim, const uint16_t pad, const uint16_t stride, const uint16_t pre_rshift, const uint16_t out_scale, const uint16_t post_rshift, q7_t *out_tensor, const uint16_t out_tensor_dim, q15_t *<a class="el" href="group__nnfullyconnect.html#ga4972f5e62722e743bc2e14d86e130148">in_tmp_buf</a>)</td></tr>
<tr class="memdesc:ga681fd01c3db04f540acb48e080682acc"><td class="mdescLeft">&#160;</td><td class="mdescRight">This function performs fast convolution for unsigned 8-bit integer inputs and signed 8-bit integer outputs with symmetric quantization on the outputs.  <br /></td></tr>
<tr class="separator:ga681fd01c3db04f540acb48e080682acc"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ga6ca86332aeecf3be577bfb87f554d178" id="r_ga6ca86332aeecf3be577bfb87f554d178"><td class="memItemLeft" align="right" valign="top">static int32_t&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#ga6ca86332aeecf3be577bfb87f554d178">hpm_nn_conv_HWC_u8_s16_s8_sym_fast</a> (const u8_t *in_tensor, const uint16_t in_tensor_dim, const uint16_t in_tensor_ch, const q7_t *ker_weight, const uint16_t out_tensor_ch, const uint16_t ker_dim, const uint16_t pad, const uint16_t stride, const uint16_t pre_rshift, const uint16_t out_scale, const uint16_t post_rshift, q15_t *out_tensor, const uint16_t out_tensor_dim, q15_t *<a class="el" href="group__nnfullyconnect.html#ga4972f5e62722e743bc2e14d86e130148">in_tmp_buf</a>)</td></tr>
<tr class="memdesc:ga6ca86332aeecf3be577bfb87f554d178"><td class="mdescLeft">&#160;</td><td class="mdescRight">This function performs fast convolution for unsigned 8-bit integer inputs and signed 16-bit integer outputs with symmetric quantization on the outputs.  <br /></td></tr>
<tr class="separator:ga6ca86332aeecf3be577bfb87f554d178"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:gaa733b3587ec4a987004946f46fdf4d8e" id="r_gaa733b3587ec4a987004946f46fdf4d8e"><td class="memItemLeft" align="right" valign="top">static int32_t&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#gaa733b3587ec4a987004946f46fdf4d8e">hpm_nn_conv_HWC_s8_s8_s8_sym_bias_fast_any</a> (const q7_t *in_tensor, const uint16_t in_tensor_dim_x, const uint16_t in_tensor_dim_y, const uint16_t in_tensor_ch, const q7_t *ker_weight, const uint16_t out_tensor_ch, const uint16_t ker_dim_x, const uint16_t ker_dim_y, const uint16_t pad_x, const uint16_t pad_y, const uint16_t stride_x, const uint16_t stride_y, const q31_t *<a class="el" href="group__nnfullyconnect.html#ga602e28fc157c370e73e4df5712f9df84">bias</a>, const uint16_t pre_rshift, const uint16_t out_scale, const uint16_t post_rshift, q7_t *out_tensor, const uint16_t out_tensor_dim_x, const uint16_t out_tensor_dim_y, q15_t *<a class="el" href="group__nnfullyconnect.html#ga4972f5e62722e743bc2e14d86e130148">in_tmp_buf</a>)</td></tr>
<tr class="memdesc:gaa733b3587ec4a987004946f46fdf4d8e"><td class="mdescLeft">&#160;</td><td class="mdescRight">This function performs fast convolution for signed 8-bit integer inputs/outputs in any x and y dimensions with bias inputs and symmetric quantization on the outputs.  <br /></td></tr>
<tr class="separator:gaa733b3587ec4a987004946f46fdf4d8e"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:gafa3b832483993fd1609f2744a7a1c6d5" id="r_gafa3b832483993fd1609f2744a7a1c6d5"><td class="memItemLeft" align="right" valign="top">static int32_t&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#gafa3b832483993fd1609f2744a7a1c6d5">hpm_nn_conv_HWC_s8_s16_s8_sym_bias_fast_any</a> (const q7_t *in_tensor, const uint16_t in_tensor_dim_x, const uint16_t in_tensor_dim_y, const uint16_t in_tensor_ch, const q7_t *ker_weight, const uint16_t out_tensor_ch, const uint16_t ker_dim_x, const uint16_t ker_dim_y, const uint16_t pad_x, const uint16_t pad_y, const uint16_t stride_x, const uint16_t stride_y, const q31_t *<a class="el" href="group__nnfullyconnect.html#ga602e28fc157c370e73e4df5712f9df84">bias</a>, const uint16_t pre_rshift, const uint16_t out_scale, const uint16_t post_rshift, q15_t *out_tensor, const uint16_t out_tensor_dim_x, const uint16_t out_tensor_dim_y, q15_t *<a class="el" href="group__nnfullyconnect.html#ga4972f5e62722e743bc2e14d86e130148">in_tmp_buf</a>)</td></tr>
<tr class="memdesc:gafa3b832483993fd1609f2744a7a1c6d5"><td class="mdescLeft">&#160;</td><td class="mdescRight">This function performs fast convolution for signed 8-bit integer inputs and signed 16-bit integer outputs in any x and y dimensions with bias inputs and symmetric quantization on the outputs.  <br /></td></tr>
<tr class="separator:gafa3b832483993fd1609f2744a7a1c6d5"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:gaa245691db40029df9384b7e50b79fde4" id="r_gaa245691db40029df9384b7e50b79fde4"><td class="memItemLeft" align="right" valign="top">static int32_t&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#gaa245691db40029df9384b7e50b79fde4">hpm_nn_conv_HWC_u8_u8_s8_sym_bias_fast_any</a> (const u8_t *in_tensor, const uint16_t in_tensor_dim_x, const uint16_t in_tensor_dim_y, const uint16_t in_tensor_ch, const q7_t *ker_weight, const uint16_t out_tensor_ch, const uint16_t ker_dim_x, const uint16_t ker_dim_y, const uint16_t pad_x, const uint16_t pad_y, const uint16_t stride_x, const uint16_t stride_y, const q31_t *<a class="el" href="group__nnfullyconnect.html#ga602e28fc157c370e73e4df5712f9df84">bias</a>, const uint16_t pre_rshift, const uint16_t out_scale, const uint16_t post_rshift, u8_t *out_tensor, const uint16_t out_tensor_dim_x, const uint16_t out_tensor_dim_y, q15_t *<a class="el" href="group__nnfullyconnect.html#ga4972f5e62722e743bc2e14d86e130148">in_tmp_buf</a>)</td></tr>
<tr class="memdesc:gaa245691db40029df9384b7e50b79fde4"><td class="mdescLeft">&#160;</td><td class="mdescRight">This function performs fast convolution for unsigned 8-bit integer inputs/outputs in any x and y dimensions with bias inputs and symmetric quantization on the outputs.  <br /></td></tr>
<tr class="separator:gaa245691db40029df9384b7e50b79fde4"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:gae65c6f8353b1d3eb0ad4f6bbdb89c4cc" id="r_gae65c6f8353b1d3eb0ad4f6bbdb89c4cc"><td class="memItemLeft" align="right" valign="top">static int32_t&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#gae65c6f8353b1d3eb0ad4f6bbdb89c4cc">hpm_nn_conv_HWC_u8_s8_s8_sym_bias_fast_any</a> (const u8_t *in_tensor, const uint16_t in_tensor_dim_x, const uint16_t in_tensor_dim_y, const uint16_t in_tensor_ch, const q7_t *ker_weight, const uint16_t out_tensor_ch, const uint16_t ker_dim_x, const uint16_t ker_dim_y, const uint16_t pad_x, const uint16_t pad_y, const uint16_t stride_x, const uint16_t stride_y, const q31_t *<a class="el" href="group__nnfullyconnect.html#ga602e28fc157c370e73e4df5712f9df84">bias</a>, const uint16_t pre_rshift, const uint16_t out_scale, const uint16_t post_rshift, q7_t *out_tensor, const uint16_t out_tensor_dim_x, const uint16_t out_tensor_dim_y, q15_t *<a class="el" href="group__nnfullyconnect.html#ga4972f5e62722e743bc2e14d86e130148">in_tmp_buf</a>)</td></tr>
<tr class="memdesc:gae65c6f8353b1d3eb0ad4f6bbdb89c4cc"><td class="mdescLeft">&#160;</td><td class="mdescRight">This function performs fast convolution for unsigned 8-bit integer inputs and signed 8-bit integer outputs in any x and y dimensions with bias inputs and symmetric quantization on the outputs.  <br /></td></tr>
<tr class="separator:gae65c6f8353b1d3eb0ad4f6bbdb89c4cc"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ga1ba10db375981d7dfba5902aea8de0ff" id="r_ga1ba10db375981d7dfba5902aea8de0ff"><td class="memItemLeft" align="right" valign="top">static int32_t&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#ga1ba10db375981d7dfba5902aea8de0ff">hpm_nn_conv_HWC_u8_s16_s8_sym_bias_fast_any</a> (const u8_t *in_tensor, const uint16_t in_tensor_dim_x, const uint16_t in_tensor_dim_y, const uint16_t in_tensor_ch, const q7_t *ker_weight, const uint16_t out_tensor_ch, const uint16_t ker_dim_x, const uint16_t ker_dim_y, const uint16_t pad_x, const uint16_t pad_y, const uint16_t stride_x, const uint16_t stride_y, const q31_t *<a class="el" href="group__nnfullyconnect.html#ga602e28fc157c370e73e4df5712f9df84">bias</a>, const uint16_t pre_rshift, const uint16_t out_scale, const uint16_t post_rshift, q15_t *out_tensor, const uint16_t out_tensor_dim_x, const uint16_t out_tensor_dim_y, q15_t *<a class="el" href="group__nnfullyconnect.html#ga4972f5e62722e743bc2e14d86e130148">in_tmp_buf</a>)</td></tr>
<tr class="memdesc:ga1ba10db375981d7dfba5902aea8de0ff"><td class="mdescLeft">&#160;</td><td class="mdescRight">This function performs fast convolution for unsigned 8-bit integer inputs and signed 16-bit integer outputs in any x and y dimensions with bias inputs and symmetric quantization on the outputs.  <br /></td></tr>
<tr class="separator:ga1ba10db375981d7dfba5902aea8de0ff"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:gaf210756844a35322033afcc20325eae5" id="r_gaf210756844a35322033afcc20325eae5"><td class="memItemLeft" align="right" valign="top">static int32_t&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#gaf210756844a35322033afcc20325eae5">hpm_nn_conv_HWC_s8_s8_s8_sym_fast_any</a> (const q7_t *in_tensor, const uint16_t in_tensor_dim_x, const uint16_t in_tensor_dim_y, const uint16_t in_tensor_ch, const q7_t *ker_weight, const uint16_t out_tensor_ch, const uint16_t ker_dim_x, const uint16_t ker_dim_y, const uint16_t pad_x, const uint16_t pad_y, const uint16_t stride_x, const uint16_t stride_y, const uint16_t pre_rshift, const uint16_t out_scale, const uint16_t post_rshift, q7_t *out_tensor, const uint16_t out_tensor_dim_x, const uint16_t out_tensor_dim_y, q15_t *<a class="el" href="group__nnfullyconnect.html#ga4972f5e62722e743bc2e14d86e130148">in_tmp_buf</a>)</td></tr>
<tr class="memdesc:gaf210756844a35322033afcc20325eae5"><td class="mdescLeft">&#160;</td><td class="mdescRight">This function performs fast convolution for signed 8-bit integer inputs/outputs in any x and y dimensions with symmetric quantization on the outputs.  <br /></td></tr>
<tr class="separator:gaf210756844a35322033afcc20325eae5"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:gaea70ea34cd3a6e45bc89ada5e110e698" id="r_gaea70ea34cd3a6e45bc89ada5e110e698"><td class="memItemLeft" align="right" valign="top">static int32_t&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#gaea70ea34cd3a6e45bc89ada5e110e698">hpm_nn_conv_HWC_s8_s16_s8_sym_fast_any</a> (const q7_t *in_tensor, const uint16_t in_tensor_dim_x, const uint16_t in_tensor_dim_y, const uint16_t in_tensor_ch, const q7_t *ker_weight, const uint16_t out_tensor_ch, const uint16_t ker_dim_x, const uint16_t ker_dim_y, const uint16_t pad_x, const uint16_t pad_y, const uint16_t stride_x, const uint16_t stride_y, const uint16_t pre_rshift, const uint16_t out_scale, const uint16_t post_rshift, q15_t *out_tensor, const uint16_t out_tensor_dim_x, const uint16_t out_tensor_dim_y, q15_t *<a class="el" href="group__nnfullyconnect.html#ga4972f5e62722e743bc2e14d86e130148">in_tmp_buf</a>)</td></tr>
<tr class="memdesc:gaea70ea34cd3a6e45bc89ada5e110e698"><td class="mdescLeft">&#160;</td><td class="mdescRight">This function performs fast convolution for signed 8-bit integer inputs and signed 16-bit integer outputs in any x and y dimensions with symmetric quantization on the outputs.  <br /></td></tr>
<tr class="separator:gaea70ea34cd3a6e45bc89ada5e110e698"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:gad00d5ffdfffd45ad20e15c41da36a31b" id="r_gad00d5ffdfffd45ad20e15c41da36a31b"><td class="memItemLeft" align="right" valign="top">static int32_t&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#gad00d5ffdfffd45ad20e15c41da36a31b">hpm_nn_conv_HWC_u8_u8_s8_sym_fast_any</a> (const u8_t *in_tensor, const uint16_t in_tensor_dim_x, const uint16_t in_tensor_dim_y, const uint16_t in_tensor_ch, const q7_t *ker_weight, const uint16_t out_tensor_ch, const uint16_t ker_dim_x, const uint16_t ker_dim_y, const uint16_t pad_x, const uint16_t pad_y, const uint16_t stride_x, const uint16_t stride_y, const uint16_t pre_rshift, const uint16_t out_scale, const uint16_t post_rshift, u8_t *out_tensor, const uint16_t out_tensor_dim_x, const uint16_t out_tensor_dim_y, q15_t *<a class="el" href="group__nnfullyconnect.html#ga4972f5e62722e743bc2e14d86e130148">in_tmp_buf</a>)</td></tr>
<tr class="memdesc:gad00d5ffdfffd45ad20e15c41da36a31b"><td class="mdescLeft">&#160;</td><td class="mdescRight">This function performs fast convolution for unsigned 8-bit integer inputs/outputs in any x and y dimensions with symmetric quantization on the outputs.  <br /></td></tr>
<tr class="separator:gad00d5ffdfffd45ad20e15c41da36a31b"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:gad463faadd1a58de1fabc5f05a396f025" id="r_gad463faadd1a58de1fabc5f05a396f025"><td class="memItemLeft" align="right" valign="top">static int32_t&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#gad463faadd1a58de1fabc5f05a396f025">hpm_nn_conv_HWC_u8_s8_s8_sym_fast_any</a> (const u8_t *in_tensor, const uint16_t in_tensor_dim_x, const uint16_t in_tensor_dim_y, const uint16_t in_tensor_ch, const q7_t *ker_weight, const uint16_t out_tensor_ch, const uint16_t ker_dim_x, const uint16_t ker_dim_y, const uint16_t pad_x, const uint16_t pad_y, const uint16_t stride_x, const uint16_t stride_y, const uint16_t pre_rshift, const uint16_t out_scale, const uint16_t post_rshift, q7_t *out_tensor, const uint16_t out_tensor_dim_x, const uint16_t out_tensor_dim_y, q15_t *<a class="el" href="group__nnfullyconnect.html#ga4972f5e62722e743bc2e14d86e130148">in_tmp_buf</a>)</td></tr>
<tr class="memdesc:gad463faadd1a58de1fabc5f05a396f025"><td class="mdescLeft">&#160;</td><td class="mdescRight">This function performs fast convolution for unsigned 8-bit integer inputs and signed 8-bit integer outputs in any x and y dimensions with symmetric quantization on the outputs.  <br /></td></tr>
<tr class="separator:gad463faadd1a58de1fabc5f05a396f025"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ga7bb79b1cd25ff4e15ddfff5ac9336d3f" id="r_ga7bb79b1cd25ff4e15ddfff5ac9336d3f"><td class="memItemLeft" align="right" valign="top">static int32_t&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#ga7bb79b1cd25ff4e15ddfff5ac9336d3f">hpm_nn_conv_HWC_u8_s16_s8_sym_fast_any</a> (const u8_t *in_tensor, const uint16_t in_tensor_dim_x, const uint16_t in_tensor_dim_y, const uint16_t in_tensor_ch, const q7_t *ker_weight, const uint16_t out_tensor_ch, const uint16_t ker_dim_x, const uint16_t ker_dim_y, const uint16_t pad_x, const uint16_t pad_y, const uint16_t stride_x, const uint16_t stride_y, const uint16_t pre_rshift, const uint16_t out_scale, const uint16_t post_rshift, q15_t *out_tensor, const uint16_t out_tensor_dim_x, const uint16_t out_tensor_dim_y, q15_t *<a class="el" href="group__nnfullyconnect.html#ga4972f5e62722e743bc2e14d86e130148">in_tmp_buf</a>)</td></tr>
<tr class="memdesc:ga7bb79b1cd25ff4e15ddfff5ac9336d3f"><td class="mdescLeft">&#160;</td><td class="mdescRight">This function performs fast convolution for unsigned 8-bit integer inputs and signed 16-bit integer outputs in any x and y dimensions with symmetric quantization on the outputs.  <br /></td></tr>
<tr class="separator:ga7bb79b1cd25ff4e15ddfff5ac9336d3f"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:gaa2232c5f84cbe4d40d4201756d87c308" id="r_gaa2232c5f84cbe4d40d4201756d87c308"><td class="memItemLeft" align="right" valign="top">static int32_t&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#gaa2232c5f84cbe4d40d4201756d87c308">hpm_nn_conv_dw_HWC_s8_s8_s8_sym_bias</a> (const q7_t *in_tensor, const uint16_t in_tensor_dim, const uint16_t in_tensor_ch, const q7_t *ker_weight, const uint16_t out_tensor_ch, const uint16_t ker_dim, const uint16_t pad, const uint16_t stride, const q31_t *<a class="el" href="group__nnfullyconnect.html#ga602e28fc157c370e73e4df5712f9df84">bias</a>, const uint16_t pre_rshift, const uint16_t out_scale, const uint16_t post_rshift, q7_t *out_tensor, const uint16_t out_tensor_dim, q15_t *<a class="el" href="group__nnfullyconnect.html#ga4972f5e62722e743bc2e14d86e130148">in_tmp_buf</a>)</td></tr>
<tr class="memdesc:gaa2232c5f84cbe4d40d4201756d87c308"><td class="mdescLeft">&#160;</td><td class="mdescRight">This function performs depthwise convolution for signed 8-bit integer inputs/outputs with bias inputs and symmetric quantization on the outputs.  <br /></td></tr>
<tr class="separator:gaa2232c5f84cbe4d40d4201756d87c308"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ga3c6fcf87e6f94a46600aab9b8154e747" id="r_ga3c6fcf87e6f94a46600aab9b8154e747"><td class="memItemLeft" align="right" valign="top">static int32_t&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#ga3c6fcf87e6f94a46600aab9b8154e747">hpm_nn_conv_dw_HWC_s8_s16_s8_sym_bias</a> (const q7_t *in_tensor, const uint16_t in_tensor_dim, const uint16_t in_tensor_ch, const q7_t *ker_weight, const uint16_t out_tensor_ch, const uint16_t ker_dim, const uint16_t pad, const uint16_t stride, const q31_t *<a class="el" href="group__nnfullyconnect.html#ga602e28fc157c370e73e4df5712f9df84">bias</a>, const uint16_t pre_rshift, const uint16_t out_scale, const uint16_t post_rshift, q15_t *out_tensor, const uint16_t out_tensor_dim, q15_t *<a class="el" href="group__nnfullyconnect.html#ga4972f5e62722e743bc2e14d86e130148">in_tmp_buf</a>)</td></tr>
<tr class="memdesc:ga3c6fcf87e6f94a46600aab9b8154e747"><td class="mdescLeft">&#160;</td><td class="mdescRight">This function performs depthwise convolution for signed 8-bit integer inputs and signed 16-bit integer outputs with bias inputs and symmetric quantization on the outputs.  <br /></td></tr>
<tr class="separator:ga3c6fcf87e6f94a46600aab9b8154e747"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ga88f4d9ab1a22cc7d551664bf37c11f4a" id="r_ga88f4d9ab1a22cc7d551664bf37c11f4a"><td class="memItemLeft" align="right" valign="top">static int32_t&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#ga88f4d9ab1a22cc7d551664bf37c11f4a">hpm_nn_conv_dw_HWC_u8_u8_s8_sym_bias</a> (const u8_t *in_tensor, const uint16_t in_tensor_dim, const uint16_t in_tensor_ch, const q7_t *ker_weight, const uint16_t out_tensor_ch, const uint16_t ker_dim, const uint16_t pad, const uint16_t stride, const q31_t *<a class="el" href="group__nnfullyconnect.html#ga602e28fc157c370e73e4df5712f9df84">bias</a>, const uint16_t pre_rshift, const uint16_t out_scale, const uint16_t post_rshift, u8_t *out_tensor, const uint16_t out_tensor_dim, q15_t *<a class="el" href="group__nnfullyconnect.html#ga4972f5e62722e743bc2e14d86e130148">in_tmp_buf</a>)</td></tr>
<tr class="memdesc:ga88f4d9ab1a22cc7d551664bf37c11f4a"><td class="mdescLeft">&#160;</td><td class="mdescRight">This function performs depthwise convolution for unsigned 8-bit integer inputs/outputs with bias inputs and symmetric quantization on the outputs.  <br /></td></tr>
<tr class="separator:ga88f4d9ab1a22cc7d551664bf37c11f4a"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ga3c07fe5b1305f89f094eb44de887288e" id="r_ga3c07fe5b1305f89f094eb44de887288e"><td class="memItemLeft" align="right" valign="top">static int32_t&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#ga3c07fe5b1305f89f094eb44de887288e">hpm_nn_conv_dw_HWC_u8_s8_s8_sym_bias</a> (const u8_t *in_tensor, const uint16_t in_tensor_dim, const uint16_t in_tensor_ch, const q7_t *ker_weight, const uint16_t out_tensor_ch, const uint16_t ker_dim, const uint16_t pad, const uint16_t stride, const q31_t *<a class="el" href="group__nnfullyconnect.html#ga602e28fc157c370e73e4df5712f9df84">bias</a>, const uint16_t pre_rshift, const uint16_t out_scale, const uint16_t post_rshift, q7_t *out_tensor, const uint16_t out_tensor_dim, q15_t *<a class="el" href="group__nnfullyconnect.html#ga4972f5e62722e743bc2e14d86e130148">in_tmp_buf</a>)</td></tr>
<tr class="memdesc:ga3c07fe5b1305f89f094eb44de887288e"><td class="mdescLeft">&#160;</td><td class="mdescRight">This function performs depthwise convolution for unsigned 8-bit integer inputs and signed 8-bit integer outputs with bias inputs and symmetric quantization on the outputs.  <br /></td></tr>
<tr class="separator:ga3c07fe5b1305f89f094eb44de887288e"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:gae3cdb24a3bc9374cc98a97d1cf66d713" id="r_gae3cdb24a3bc9374cc98a97d1cf66d713"><td class="memItemLeft" align="right" valign="top">static int32_t&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#gae3cdb24a3bc9374cc98a97d1cf66d713">hpm_nn_conv_dw_HWC_u8_s16_s8_sym_bias</a> (const u8_t *in_tensor, const uint16_t in_tensor_dim, const uint16_t in_tensor_ch, const q7_t *ker_weight, const uint16_t out_tensor_ch, const uint16_t ker_dim, const uint16_t pad, const uint16_t stride, const q31_t *<a class="el" href="group__nnfullyconnect.html#ga602e28fc157c370e73e4df5712f9df84">bias</a>, const uint16_t pre_rshift, const uint16_t out_scale, const uint16_t post_rshift, q15_t *out_tensor, const uint16_t out_tensor_dim, q15_t *<a class="el" href="group__nnfullyconnect.html#ga4972f5e62722e743bc2e14d86e130148">in_tmp_buf</a>)</td></tr>
<tr class="memdesc:gae3cdb24a3bc9374cc98a97d1cf66d713"><td class="mdescLeft">&#160;</td><td class="mdescRight">This function performs depthwise convolution for unsigned 8-bit integer inputs and signed 16-bit integer outputs with bias inputs and symmetric quantization on the outputs.  <br /></td></tr>
<tr class="separator:gae3cdb24a3bc9374cc98a97d1cf66d713"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:gaddf5ec832e3e3306da2089d5bb742aee" id="r_gaddf5ec832e3e3306da2089d5bb742aee"><td class="memItemLeft" align="right" valign="top">static int32_t&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#gaddf5ec832e3e3306da2089d5bb742aee">hpm_nn_conv_dw_HWC_s8_s8_s8_sym</a> (const q7_t *in_tensor, const uint16_t in_tensor_dim, const uint16_t in_tensor_ch, const q7_t *ker_weight, const uint16_t out_tensor_ch, const uint16_t ker_dim, const uint16_t pad, const uint16_t stride, const uint16_t pre_rshift, const uint16_t out_scale, const uint16_t post_rshift, q7_t *out_tensor, const uint16_t out_tensor_dim, q15_t *<a class="el" href="group__nnfullyconnect.html#ga4972f5e62722e743bc2e14d86e130148">in_tmp_buf</a>)</td></tr>
<tr class="memdesc:gaddf5ec832e3e3306da2089d5bb742aee"><td class="mdescLeft">&#160;</td><td class="mdescRight">This function performs depthwise convolution for signed 8-bit integer inputs/outputs with symmetric quantization on the outputs.  <br /></td></tr>
<tr class="separator:gaddf5ec832e3e3306da2089d5bb742aee"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:gacb88aa3904d0374b532ac0dfae36d0ae" id="r_gacb88aa3904d0374b532ac0dfae36d0ae"><td class="memItemLeft" align="right" valign="top">static int32_t&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#gacb88aa3904d0374b532ac0dfae36d0ae">hpm_nn_conv_dw_HWC_s8_s16_s8_sym</a> (const q7_t *in_tensor, const uint16_t in_tensor_dim, const uint16_t in_tensor_ch, const q7_t *ker_weight, const uint16_t out_tensor_ch, const uint16_t ker_dim, const uint16_t pad, const uint16_t stride, const uint16_t pre_rshift, const uint16_t out_scale, const uint16_t post_rshift, q15_t *out_tensor, const uint16_t out_tensor_dim, q15_t *<a class="el" href="group__nnfullyconnect.html#ga4972f5e62722e743bc2e14d86e130148">in_tmp_buf</a>)</td></tr>
<tr class="memdesc:gacb88aa3904d0374b532ac0dfae36d0ae"><td class="mdescLeft">&#160;</td><td class="mdescRight">This function performs depthwise convolution for signed 8-bit integer inputs and signed 16-bit integer outputs with symmetric quantization on the outputs.  <br /></td></tr>
<tr class="separator:gacb88aa3904d0374b532ac0dfae36d0ae"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ga11e8db5b74e51807c0f6c264ceb88a3f" id="r_ga11e8db5b74e51807c0f6c264ceb88a3f"><td class="memItemLeft" align="right" valign="top">static int32_t&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#ga11e8db5b74e51807c0f6c264ceb88a3f">hpm_nn_conv_dw_HWC_u8_u8_s8_sym</a> (const u8_t *in_tensor, const uint16_t in_tensor_dim, const uint16_t in_tensor_ch, const q7_t *ker_weight, const uint16_t out_tensor_ch, const uint16_t ker_dim, const uint16_t pad, const uint16_t stride, const uint16_t pre_rshift, const uint16_t out_scale, const uint16_t post_rshift, u8_t *out_tensor, const uint16_t out_tensor_dim, q15_t *<a class="el" href="group__nnfullyconnect.html#ga4972f5e62722e743bc2e14d86e130148">in_tmp_buf</a>)</td></tr>
<tr class="memdesc:ga11e8db5b74e51807c0f6c264ceb88a3f"><td class="mdescLeft">&#160;</td><td class="mdescRight">This function performs depthwise convolution for unsigned 8-bit integer inputs/outputs with symmetric quantization on the outputs.  <br /></td></tr>
<tr class="separator:ga11e8db5b74e51807c0f6c264ceb88a3f"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ga8021fde290f091b9348e56ae24fdf912" id="r_ga8021fde290f091b9348e56ae24fdf912"><td class="memItemLeft" align="right" valign="top">static int32_t&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#ga8021fde290f091b9348e56ae24fdf912">hpm_nn_conv_dw_HWC_u8_s8_s8_sym</a> (const u8_t *in_tensor, const uint16_t in_tensor_dim, const uint16_t in_tensor_ch, const q7_t *ker_weight, const uint16_t out_tensor_ch, const uint16_t ker_dim, const uint16_t pad, const uint16_t stride, const uint16_t pre_rshift, const uint16_t out_scale, const uint16_t post_rshift, q7_t *out_tensor, const uint16_t out_tensor_dim, q15_t *<a class="el" href="group__nnfullyconnect.html#ga4972f5e62722e743bc2e14d86e130148">in_tmp_buf</a>)</td></tr>
<tr class="memdesc:ga8021fde290f091b9348e56ae24fdf912"><td class="mdescLeft">&#160;</td><td class="mdescRight">This function performs depthwise convolution for unsigned 8-bit integer inputs and signed 8-bit integer outputs, and with symmetric quantization on the outputs.  <br /></td></tr>
<tr class="separator:ga8021fde290f091b9348e56ae24fdf912"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ga19633dab07a1ccb79712b58dbf7e9a51" id="r_ga19633dab07a1ccb79712b58dbf7e9a51"><td class="memItemLeft" align="right" valign="top">static int32_t&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#ga19633dab07a1ccb79712b58dbf7e9a51">hpm_nn_conv_dw_HWC_u8_s16_s8_sym</a> (const u8_t *in_tensor, const uint16_t in_tensor_dim, const uint16_t in_tensor_ch, const q7_t *ker_weight, const uint16_t out_tensor_ch, const uint16_t ker_dim, const uint16_t pad, const uint16_t stride, const uint16_t pre_rshift, const uint16_t out_scale, const uint16_t post_rshift, q15_t *out_tensor, const uint16_t out_tensor_dim, q15_t *<a class="el" href="group__nnfullyconnect.html#ga4972f5e62722e743bc2e14d86e130148">in_tmp_buf</a>)</td></tr>
<tr class="memdesc:ga19633dab07a1ccb79712b58dbf7e9a51"><td class="mdescLeft">&#160;</td><td class="mdescRight">This function performs depthwise convolution for unsigned 8-bit integer inputs and signed 16-bit integer outputs with symmetric quantization on the outputs.  <br /></td></tr>
<tr class="separator:ga19633dab07a1ccb79712b58dbf7e9a51"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ga425531141b804498f1b04ab9203c35c3" id="r_ga425531141b804498f1b04ab9203c35c3"><td class="memItemLeft" align="right" valign="top">static int32_t&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#ga425531141b804498f1b04ab9203c35c3">hpm_nn_conv_dw_HWC_s8_s8_s8_sym_bias_any</a> (const q7_t *in_tensor, const uint16_t in_tensor_dim_x, const uint16_t in_tensor_dim_y, const uint16_t in_tensor_ch, const q7_t *ker_weight, const uint16_t out_tensor_ch, const uint16_t ker_dim_x, const uint16_t ker_dim_y, const uint16_t pad_x, const uint16_t pad_y, const uint16_t stride_x, const uint16_t stride_y, const q31_t *<a class="el" href="group__nnfullyconnect.html#ga602e28fc157c370e73e4df5712f9df84">bias</a>, const uint16_t pre_rshift, const uint16_t out_scale, const uint16_t post_rshift, q7_t *out_tensor, const uint16_t out_tensor_dim_x, const uint16_t out_tensor_dim_y, q15_t *<a class="el" href="group__nnfullyconnect.html#ga4972f5e62722e743bc2e14d86e130148">in_tmp_buf</a>)</td></tr>
<tr class="memdesc:ga425531141b804498f1b04ab9203c35c3"><td class="mdescLeft">&#160;</td><td class="mdescRight">This function performs depthwise convolution for signed 8-bit integer inputs/outputs in any x and y dimensions with bias inputs and symmetric quantization on the outputs.  <br /></td></tr>
<tr class="separator:ga425531141b804498f1b04ab9203c35c3"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ga0a8c643e8c77051213ccf469486ddccb" id="r_ga0a8c643e8c77051213ccf469486ddccb"><td class="memItemLeft" align="right" valign="top">static int32_t&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#ga0a8c643e8c77051213ccf469486ddccb">hpm_nn_conv_dw_HWC_s8_s16_s8_sym_bias_any</a> (const q7_t *in_tensor, const uint16_t in_tensor_dim_x, const uint16_t in_tensor_dim_y, const uint16_t in_tensor_ch, const q7_t *ker_weight, const uint16_t out_tensor_ch, const uint16_t ker_dim_x, const uint16_t ker_dim_y, const uint16_t pad_x, const uint16_t pad_y, const uint16_t stride_x, const uint16_t stride_y, const q31_t *<a class="el" href="group__nnfullyconnect.html#ga602e28fc157c370e73e4df5712f9df84">bias</a>, const uint16_t pre_rshift, const uint16_t out_scale, const uint16_t post_rshift, q15_t *out_tensor, const uint16_t out_tensor_dim_x, const uint16_t out_tensor_dim_y, q15_t *<a class="el" href="group__nnfullyconnect.html#ga4972f5e62722e743bc2e14d86e130148">in_tmp_buf</a>)</td></tr>
<tr class="memdesc:ga0a8c643e8c77051213ccf469486ddccb"><td class="mdescLeft">&#160;</td><td class="mdescRight">This function performs depthwise convolution for signed 8-bit integer inputs and signed 16-bit integer outputs in any x and y dimensions with bias inputs and symmetric quantization on the outputs.  <br /></td></tr>
<tr class="separator:ga0a8c643e8c77051213ccf469486ddccb"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ga048ff15cdd4652c25b9b250f8356f335" id="r_ga048ff15cdd4652c25b9b250f8356f335"><td class="memItemLeft" align="right" valign="top">static int32_t&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#ga048ff15cdd4652c25b9b250f8356f335">hpm_nn_conv_dw_HWC_u8_u8_s8_sym_bias_any</a> (const u8_t *in_tensor, const uint16_t in_tensor_dim_x, const uint16_t in_tensor_dim_y, const uint16_t in_tensor_ch, const q7_t *ker_weight, const uint16_t out_tensor_ch, const uint16_t ker_dim_x, const uint16_t ker_dim_y, const uint16_t pad_x, const uint16_t pad_y, const uint16_t stride_x, const uint16_t stride_y, const q31_t *<a class="el" href="group__nnfullyconnect.html#ga602e28fc157c370e73e4df5712f9df84">bias</a>, const uint16_t pre_rshift, const uint16_t out_scale, const uint16_t post_rshift, u8_t *out_tensor, const uint16_t out_tensor_dim_x, const uint16_t out_tensor_dim_y, q15_t *<a class="el" href="group__nnfullyconnect.html#ga4972f5e62722e743bc2e14d86e130148">in_tmp_buf</a>)</td></tr>
<tr class="memdesc:ga048ff15cdd4652c25b9b250f8356f335"><td class="mdescLeft">&#160;</td><td class="mdescRight">This function performs depthwise convolution for unsigned 8-bit integer inputs/outputs in any x and y dimensions with bias inputs and symmetric quantization on the outputs.  <br /></td></tr>
<tr class="separator:ga048ff15cdd4652c25b9b250f8356f335"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:gab6af36649c64102a6e1c80e623bed9f3" id="r_gab6af36649c64102a6e1c80e623bed9f3"><td class="memItemLeft" align="right" valign="top">static int32_t&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#gab6af36649c64102a6e1c80e623bed9f3">hpm_nn_conv_dw_HWC_u8_s8_s8_sym_bias_any</a> (const u8_t *in_tensor, const uint16_t in_tensor_dim_x, const uint16_t in_tensor_dim_y, const uint16_t in_tensor_ch, const q7_t *ker_weight, const uint16_t out_tensor_ch, const uint16_t ker_dim_x, const uint16_t ker_dim_y, const uint16_t pad_x, const uint16_t pad_y, const uint16_t stride_x, const uint16_t stride_y, const q31_t *<a class="el" href="group__nnfullyconnect.html#ga602e28fc157c370e73e4df5712f9df84">bias</a>, const uint16_t pre_rshift, const uint16_t out_scale, const uint16_t post_rshift, q7_t *out_tensor, const uint16_t out_tensor_dim_x, const uint16_t out_tensor_dim_y, q15_t *<a class="el" href="group__nnfullyconnect.html#ga4972f5e62722e743bc2e14d86e130148">in_tmp_buf</a>)</td></tr>
<tr class="memdesc:gab6af36649c64102a6e1c80e623bed9f3"><td class="mdescLeft">&#160;</td><td class="mdescRight">This function performs depthwise convolution for unsigned 8-bit integer inputs and signed 8-bit integer outputs in any x and y dimensions with bias inputs and symmetric quantization on the outputs.  <br /></td></tr>
<tr class="separator:gab6af36649c64102a6e1c80e623bed9f3"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ga24277b452593c20ae17ff2086fb8253a" id="r_ga24277b452593c20ae17ff2086fb8253a"><td class="memItemLeft" align="right" valign="top">static int32_t&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#ga24277b452593c20ae17ff2086fb8253a">hpm_nn_conv_dw_HWC_u8_s16_s8_sym_bias_any</a> (const u8_t *in_tensor, const uint16_t in_tensor_dim_x, const uint16_t in_tensor_dim_y, const uint16_t in_tensor_ch, const q7_t *ker_weight, const uint16_t out_tensor_ch, const uint16_t ker_dim_x, const uint16_t ker_dim_y, const uint16_t pad_x, const uint16_t pad_y, const uint16_t stride_x, const uint16_t stride_y, const q31_t *<a class="el" href="group__nnfullyconnect.html#ga602e28fc157c370e73e4df5712f9df84">bias</a>, const uint16_t pre_rshift, const uint16_t out_scale, const uint16_t post_rshift, q15_t *out_tensor, const uint16_t out_tensor_dim_x, const uint16_t out_tensor_dim_y, q15_t *<a class="el" href="group__nnfullyconnect.html#ga4972f5e62722e743bc2e14d86e130148">in_tmp_buf</a>)</td></tr>
<tr class="memdesc:ga24277b452593c20ae17ff2086fb8253a"><td class="mdescLeft">&#160;</td><td class="mdescRight">This function performs depthwise convolution for unsigned 8-bit integer inputs and signed 16-bit integer outputs in any x and y dimensions with bias inputs and symmetric quantization on the outputs.  <br /></td></tr>
<tr class="separator:ga24277b452593c20ae17ff2086fb8253a"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:gae8250ca3c328de6b4ea93e4f62bcf541" id="r_gae8250ca3c328de6b4ea93e4f62bcf541"><td class="memItemLeft" align="right" valign="top">static int32_t&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#gae8250ca3c328de6b4ea93e4f62bcf541">hpm_nn_conv_dw_HWC_s8_s8_s8_sym_any</a> (const q7_t *in_tensor, const uint16_t in_tensor_dim_x, const uint16_t in_tensor_dim_y, const uint16_t in_tensor_ch, const q7_t *ker_weight, const uint16_t out_tensor_ch, const uint16_t ker_dim_x, const uint16_t ker_dim_y, const uint16_t pad_x, const uint16_t pad_y, const uint16_t stride_x, const uint16_t stride_y, const uint16_t pre_rshift, const uint16_t out_scale, const uint16_t post_rshift, q7_t *out_tensor, const uint16_t out_tensor_dim_x, const uint16_t out_tensor_dim_y, q15_t *<a class="el" href="group__nnfullyconnect.html#ga4972f5e62722e743bc2e14d86e130148">in_tmp_buf</a>)</td></tr>
<tr class="memdesc:gae8250ca3c328de6b4ea93e4f62bcf541"><td class="mdescLeft">&#160;</td><td class="mdescRight">This function performs depthwise convolution for signed 8-bit integer inputs/outputs in any x and y dimensions with bias inputs and symmetric quantization on the outputs.  <br /></td></tr>
<tr class="separator:gae8250ca3c328de6b4ea93e4f62bcf541"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ga6bf168c41fda67552bd4b5f5c200a268" id="r_ga6bf168c41fda67552bd4b5f5c200a268"><td class="memItemLeft" align="right" valign="top">static int32_t&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#ga6bf168c41fda67552bd4b5f5c200a268">hpm_nn_conv_dw_HWC_s8_s16_s8_sym_any</a> (const q7_t *in_tensor, const uint16_t in_tensor_dim_x, const uint16_t in_tensor_dim_y, const uint16_t in_tensor_ch, const q7_t *ker_weight, const uint16_t out_tensor_ch, const uint16_t ker_dim_x, const uint16_t ker_dim_y, const uint16_t pad_x, const uint16_t pad_y, const uint16_t stride_x, const uint16_t stride_y, const uint16_t pre_rshift, const uint16_t out_scale, const uint16_t post_rshift, q15_t *out_tensor, const uint16_t out_tensor_dim_x, const uint16_t out_tensor_dim_y, q15_t *<a class="el" href="group__nnfullyconnect.html#ga4972f5e62722e743bc2e14d86e130148">in_tmp_buf</a>)</td></tr>
<tr class="memdesc:ga6bf168c41fda67552bd4b5f5c200a268"><td class="mdescLeft">&#160;</td><td class="mdescRight">This function performs depthwise convolution for signed 8-bit integer inputs and signed 16-bit integer outputs in any x and y dimensions with symmetric quantization on the outputs.  <br /></td></tr>
<tr class="separator:ga6bf168c41fda67552bd4b5f5c200a268"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:gab5cb8f3dc2985f57b742036399164798" id="r_gab5cb8f3dc2985f57b742036399164798"><td class="memItemLeft" align="right" valign="top">static int32_t&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#gab5cb8f3dc2985f57b742036399164798">hpm_nn_conv_dw_HWC_u8_u8_s8_sym_any</a> (const u8_t *in_tensor, const uint16_t in_tensor_dim_x, const uint16_t in_tensor_dim_y, const uint16_t in_tensor_ch, const q7_t *ker_weight, const uint16_t out_tensor_ch, const uint16_t ker_dim_x, const uint16_t ker_dim_y, const uint16_t pad_x, const uint16_t pad_y, const uint16_t stride_x, const uint16_t stride_y, const uint16_t pre_rshift, const uint16_t out_scale, const uint16_t post_rshift, u8_t *out_tensor, const uint16_t out_tensor_dim_x, const uint16_t out_tensor_dim_y, q15_t *<a class="el" href="group__nnfullyconnect.html#ga4972f5e62722e743bc2e14d86e130148">in_tmp_buf</a>)</td></tr>
<tr class="memdesc:gab5cb8f3dc2985f57b742036399164798"><td class="mdescLeft">&#160;</td><td class="mdescRight">This function performs depthwise convolution for unsigned 8-bit integer inputs/outputs in any x and y dimensions with symmetric quantization on the outputs.  <br /></td></tr>
<tr class="separator:gab5cb8f3dc2985f57b742036399164798"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:gac080214be9e1938ba324ca42c0aade2c" id="r_gac080214be9e1938ba324ca42c0aade2c"><td class="memItemLeft" align="right" valign="top">static int32_t&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#gac080214be9e1938ba324ca42c0aade2c">hpm_nn_conv_dw_HWC_u8_s8_s8_sym_any</a> (const u8_t *in_tensor, const uint16_t in_tensor_dim_x, const uint16_t in_tensor_dim_y, const uint16_t in_tensor_ch, const q7_t *ker_weight, const uint16_t out_tensor_ch, const uint16_t ker_dim_x, const uint16_t ker_dim_y, const uint16_t pad_x, const uint16_t pad_y, const uint16_t stride_x, const uint16_t stride_y, const uint16_t pre_rshift, const uint16_t out_scale, const uint16_t post_rshift, q7_t *out_tensor, const uint16_t out_tensor_dim_x, const uint16_t out_tensor_dim_y, q15_t *<a class="el" href="group__nnfullyconnect.html#ga4972f5e62722e743bc2e14d86e130148">in_tmp_buf</a>)</td></tr>
<tr class="memdesc:gac080214be9e1938ba324ca42c0aade2c"><td class="mdescLeft">&#160;</td><td class="mdescRight">This function performs depthwise convolution for unsigned 8-bit integer inputs and signed 8-bit integer outputs in any x and y dimensions with symmetric quantization on the outputs.  <br /></td></tr>
<tr class="separator:gac080214be9e1938ba324ca42c0aade2c"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:gae9744bde30c4e26b17ef6dc89acb16d7" id="r_gae9744bde30c4e26b17ef6dc89acb16d7"><td class="memItemLeft" align="right" valign="top">static int32_t&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#gae9744bde30c4e26b17ef6dc89acb16d7">hpm_nn_conv_dw_HWC_u8_s16_s8_sym_any</a> (const u8_t *in_tensor, const uint16_t in_tensor_dim_x, const uint16_t in_tensor_dim_y, const uint16_t in_tensor_ch, const q7_t *ker_weight, const uint16_t out_tensor_ch, const uint16_t ker_dim_x, const uint16_t ker_dim_y, const uint16_t pad_x, const uint16_t pad_y, const uint16_t stride_x, const uint16_t stride_y, const uint16_t pre_rshift, const uint16_t out_scale, const uint16_t post_rshift, q15_t *out_tensor, const uint16_t out_tensor_dim_x, const uint16_t out_tensor_dim_y, q15_t *<a class="el" href="group__nnfullyconnect.html#ga4972f5e62722e743bc2e14d86e130148">in_tmp_buf</a>)</td></tr>
<tr class="memdesc:gae9744bde30c4e26b17ef6dc89acb16d7"><td class="mdescLeft">&#160;</td><td class="mdescRight">This function performs depthwise convolution for unsigned 8-bit integer inputs and signed 16-bit integer outputs in any x and y dimensions with symmetric quantization on the outputs.  <br /></td></tr>
<tr class="separator:gae9744bde30c4e26b17ef6dc89acb16d7"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ga2420b518e254e3fd4abe27f16a2a7901" id="r_ga2420b518e254e3fd4abe27f16a2a7901"><td class="memItemLeft" align="right" valign="top">static int32_t&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#ga2420b518e254e3fd4abe27f16a2a7901">hpm_nn_conv_1x1_HWC_s8_s8_s8_asym_bias_fast_any</a> (const q7_t *in_tensor, const uint16_t in_tensor_dim_x, const uint16_t in_tensor_dim_y, const uint16_t in_tensor_ch, const uint16_t in_tensor_group, const q7_t *ker_weight, const uint16_t out_tensor_ch, const uint16_t pad_x, const uint16_t pad_y, const uint16_t stride_x, const uint16_t stride_y, const int32_t *<a class="el" href="group__nnfullyconnect.html#ga602e28fc157c370e73e4df5712f9df84">bias</a>, q7_t *out_tensor, const int32_t *out_shift, const int32_t *out_scale, const int32_t out_offset, const int32_t in_offset, const int32_t act_min, const int32_t act_max, const uint16_t out_tensor_dim_x, const uint16_t out_tensor_dim_y, q15_t *tmp_buf)</td></tr>
<tr class="memdesc:ga2420b518e254e3fd4abe27f16a2a7901"><td class="mdescLeft">&#160;</td><td class="mdescRight">This function performs 1x1 kernels convolution for signed 8-bit interger inputs/outputs in any x and y dimensions with asymmetric quantization on the outputs.  <br /></td></tr>
<tr class="separator:ga2420b518e254e3fd4abe27f16a2a7901"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:gaa7a9c1eab5556db05cfa3d05dfa4c71c" id="r_gaa7a9c1eab5556db05cfa3d05dfa4c71c"><td class="memItemLeft" align="right" valign="top">static int32_t&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#gaa7a9c1eab5556db05cfa3d05dfa4c71c">hpm_nn_conv_1x1_HWC_s8_s8_s8_asym_bias_fast_any_get_buffer_size</a> (const uint16_t in_tensor_ch)</td></tr>
<tr class="memdesc:gaa7a9c1eab5556db05cfa3d05dfa4c71c"><td class="mdescLeft">&#160;</td><td class="mdescRight">This function is used to get the needed size, in bytes, by the input temporary buffer of riscv_nn_conv_1x1_HWC_s8_s8_s8_asym_bias_fast_any.  <br /></td></tr>
<tr class="separator:gaa7a9c1eab5556db05cfa3d05dfa4c71c"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:gae1c62cb7f29063bf12498148562fdca7" id="r_gae1c62cb7f29063bf12498148562fdca7"><td class="memItemLeft" align="right" valign="top">static int&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#gae1c62cb7f29063bf12498148562fdca7">hpm_nn_conv_1xn_HWC_s8_s8_s8_asym_bias_any</a> (const q7_t *in_tensor, const uint16_t in_tensor_dim_x, const uint16_t in_tensor_ch, const uint16_t in_tensor_group, const q7_t *ker_weight, const uint16_t out_tensor_ch, const uint16_t ker_dim_x, const uint16_t pad_x, const uint16_t stride_x, const int32_t *<a class="el" href="group__nnfullyconnect.html#ga602e28fc157c370e73e4df5712f9df84">bias</a>, q7_t *out_tensor, const int32_t *out_shift, const int32_t *out_scale, const int32_t out_offset, const int32_t in_offset, const int32_t act_min, const int32_t act_max, const uint16_t out_tensor_dim_x, q15_t *<a class="el" href="group__nnfullyconnect.html#ga4972f5e62722e743bc2e14d86e130148">in_tmp_buf</a>)</td></tr>
<tr class="memdesc:gae1c62cb7f29063bf12498148562fdca7"><td class="mdescLeft">&#160;</td><td class="mdescRight">This function performs 1xn kernels convolution for signed 8-bit integer inputs/outputs in any x and y dimensions with asymmetric quantization on the outputs.  <br /></td></tr>
<tr class="separator:gae1c62cb7f29063bf12498148562fdca7"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ga1e0aac3f254eb048c027362e2fa40c0a" id="r_ga1e0aac3f254eb048c027362e2fa40c0a"><td class="memItemLeft" align="right" valign="top">static int32_t&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#ga1e0aac3f254eb048c027362e2fa40c0a">hpm_nn_conv_1xn_HWC_s8_s8_s8_asym_bias_any_get_buffer_size</a> (const uint16_t in_tensor_ch, const uint16_t ker_dim_x, const uint16_t ker_dim_y)</td></tr>
<tr class="memdesc:ga1e0aac3f254eb048c027362e2fa40c0a"><td class="mdescLeft">&#160;</td><td class="mdescRight">This function is used to get the needed size, in bytes, by the input temporary buffer of riscv_nn_conv_1xn_HWC_s8_s8_s8_asym_bias_any.  <br /></td></tr>
<tr class="separator:ga1e0aac3f254eb048c027362e2fa40c0a"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:gafcbbcd4692c657df2ab93d7529fc0adb" id="r_gafcbbcd4692c657df2ab93d7529fc0adb"><td class="memItemLeft" align="right" valign="top">static int32_t&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#gafcbbcd4692c657df2ab93d7529fc0adb">hpm_nn_conv_HWC_s8_s8_s8_asym_bias_any</a> (const q7_t *in_tensor, const uint16_t in_tensor_dim_x, const uint16_t in_tensor_dim_y, const uint16_t in_tensor_ch, const uint16_t in_tensor_group, const q7_t *ker_weight, const uint16_t out_tensor_ch, const uint16_t ker_dim_x, const uint16_t ker_dim_y, const uint16_t pad_x, const uint16_t pad_y, const uint16_t stride_x, const uint16_t stride_y, const int32_t *<a class="el" href="group__nnfullyconnect.html#ga602e28fc157c370e73e4df5712f9df84">bias</a>, q7_t *out_tensor, const int32_t *out_shift, const int32_t *out_scale, const int32_t out_offset, const int32_t in_offset, const int32_t act_min, const int32_t act_max, const uint16_t out_tensor_dim_x, const uint16_t out_tensor_dim_y, q15_t *<a class="el" href="group__nnfullyconnect.html#ga4972f5e62722e743bc2e14d86e130148">in_tmp_buf</a>)</td></tr>
<tr class="memdesc:gafcbbcd4692c657df2ab93d7529fc0adb"><td class="mdescLeft">&#160;</td><td class="mdescRight">This function performs convolution for signed 8-bit integer inputs/outputs in any x and y dimensions with asymmetric quantization on the outputs.  <br /></td></tr>
<tr class="separator:gafcbbcd4692c657df2ab93d7529fc0adb"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ga89509f5499197a1f65bc7e29ff471f2a" id="r_ga89509f5499197a1f65bc7e29ff471f2a"><td class="memItemLeft" align="right" valign="top">static int32_t&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#ga89509f5499197a1f65bc7e29ff471f2a">hpm_nn_conv_HWC_s8_s8_s8_asym_bias_any_get_buffer_size</a> (const uint16_t in_tensor_ch, const uint16_t ker_dim_x, const uint16_t ker_dim_y)</td></tr>
<tr class="memdesc:ga89509f5499197a1f65bc7e29ff471f2a"><td class="mdescLeft">&#160;</td><td class="mdescRight">This function is used to get the needed size, in bytes, by the input temporary buffer of riscv_nn_conv_HWC_s8_s8_s8_asym_bias_any.  <br /></td></tr>
<tr class="separator:ga89509f5499197a1f65bc7e29ff471f2a"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ga9cfa87c1ba0068ad397a429d1ac1aab2" id="r_ga9cfa87c1ba0068ad397a429d1ac1aab2"><td class="memItemLeft" align="right" valign="top">static int32_t&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#ga9cfa87c1ba0068ad397a429d1ac1aab2">hpm_nn_conv_dw_HWC_3x3_s8_s8_s8_asym_bias_any</a> (const int8_t *in_tensor, const int32_t in_tensor_dim_x, const int32_t in_tensor_dim_y, const int32_t in_tensor_ch, const int8_t *ker_weight, const int32_t out_tensor_ch, const int32_t pad_x, const int32_t pad_y, const int32_t stride_x, const int32_t stride_y, const int32_t *<a class="el" href="group__nnfullyconnect.html#ga602e28fc157c370e73e4df5712f9df84">bias</a>, int8_t *out_tensor, const int32_t *out_shift, const int32_t *out_scale, const int32_t out_tensor_dim_x, const int32_t out_tensor_dim_y, const int32_t out_offset, const int32_t in_offset, const int32_t act_min, const int32_t act_max, const int32_t dilation_x, const int32_t dilation_y, int16_t *tmp_buf)</td></tr>
<tr class="memdesc:ga9cfa87c1ba0068ad397a429d1ac1aab2"><td class="mdescLeft">&#160;</td><td class="mdescRight">This function performs depthwise 3x3 kernels convolution for signed 8-bit integer inputs/outputs in any x and y dimensions with asymmetric quantization on the outputs.  <br /></td></tr>
<tr class="separator:ga9cfa87c1ba0068ad397a429d1ac1aab2"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ga455407b84cfc71528b0dd8680c64a8b3" id="r_ga455407b84cfc71528b0dd8680c64a8b3"><td class="memItemLeft" align="right" valign="top">static int32_t&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#ga455407b84cfc71528b0dd8680c64a8b3">hpm_nn_conv_dw_HWC_s8_s8_s8_asym_bias_any</a> (const q7_t *in_tensor, const uint16_t in_tensor_dim_x, const uint16_t in_tensor_dim_y, const uint16_t in_tensor_ch, const q7_t *ker_weight, const uint16_t out_tensor_ch, const uint16_t ch_mult, const uint16_t ker_dim_x, const uint16_t ker_dim_y, const uint16_t pad_x, const uint16_t pad_y, const uint16_t stride_x, const uint16_t stride_y, const int32_t *<a class="el" href="group__nnfullyconnect.html#ga602e28fc157c370e73e4df5712f9df84">bias</a>, q7_t *out_tensor, const int32_t *out_shift, const int32_t *out_scale, const uint16_t out_tensor_dim_x, const uint16_t out_tensor_dim_y, const int32_t out_offset, const int32_t in_offset, const int32_t act_min, const int32_t act_max, const uint16_t dilation_x, const uint16_t dilation_y, q15_t *tmp_buf)</td></tr>
<tr class="memdesc:ga455407b84cfc71528b0dd8680c64a8b3"><td class="mdescLeft">&#160;</td><td class="mdescRight">This function performs depthwise convolution for signed 8-bit interger inputs/outputs in any x and y dimensions with asymmetric quantization on the outputs.  <br /></td></tr>
<tr class="separator:ga455407b84cfc71528b0dd8680c64a8b3"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:gad954df9be69373bdc385362c70b140dc" id="r_gad954df9be69373bdc385362c70b140dc"><td class="memItemLeft" align="right" valign="top">static int32_t&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#gad954df9be69373bdc385362c70b140dc">hpm_nn_conv_dw_HWC_s8_s8_s8_asym_bias_fast_any</a> (const q7_t *in_tensor, const uint16_t in_tensor_dim_x, const uint16_t in_tensor_dim_y, const uint16_t in_tensor_ch, const q7_t *ker_weight, const uint16_t out_tensor_ch, const uint16_t ker_dim_x, const uint16_t ker_dim_y, const uint16_t pad_x, const uint16_t pad_y, const uint16_t stride_x, const uint16_t stride_y, const int32_t *<a class="el" href="group__nnfullyconnect.html#ga602e28fc157c370e73e4df5712f9df84">bias</a>, q7_t *out_tensor, const int32_t *out_shift, const int32_t *out_scale, const uint16_t out_tensor_dim_x, const uint16_t out_tensor_dim_y, const int32_t out_offset, const int32_t in_offset, const int32_t act_min, const int32_t act_max, const uint16_t dilation_x, const uint16_t dilation_y, q15_t *<a class="el" href="group__nnfullyconnect.html#ga4972f5e62722e743bc2e14d86e130148">in_tmp_buf</a>)</td></tr>
<tr class="memdesc:gad954df9be69373bdc385362c70b140dc"><td class="mdescLeft">&#160;</td><td class="mdescRight">This function performs fast depthwise convolution for signed 8-bit integer inputs/outputs in any x and y dimensions with asymmetric quantization on the outputs.  <br /></td></tr>
<tr class="separator:gad954df9be69373bdc385362c70b140dc"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:gad9339201eff1c27fd41039bfc4a4756c" id="r_gad9339201eff1c27fd41039bfc4a4756c"><td class="memItemLeft" align="right" valign="top">static int32_t&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#gad9339201eff1c27fd41039bfc4a4756c">hpm_nn_conv_dw_HWC_s8_s8_s8_asym_bias_fast_any_get_buffer_size</a> (const uint16_t in_tensor_ch, const uint16_t ker_dim_x, const uint16_t ker_dim_y)</td></tr>
<tr class="memdesc:gad9339201eff1c27fd41039bfc4a4756c"><td class="mdescLeft">&#160;</td><td class="mdescRight">This function is used to get the needed size, in bytes, by the input temporary buffer of riscv_nn_conv_dw_HWC_s8_s8_s8_asym_bias_fast_any.  <br /></td></tr>
<tr class="separator:gad9339201eff1c27fd41039bfc4a4756c"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ga0b9ce54b2ac422932e71b67b66d657c1" id="r_ga0b9ce54b2ac422932e71b67b66d657c1"><td class="memItemLeft" align="right" valign="top">static int32_t&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#ga0b9ce54b2ac422932e71b67b66d657c1">hpm_nn_conv_dw_HWC_u8_u8_u8_asym_bias_any</a> (const uint8_t *in_tensor, const uint16_t in_tensor_dim_x, const uint16_t in_tensor_dim_y, const uint16_t in_tensor_ch, const uint8_t *ker_weight, const uint16_t ker_dim_x, const uint16_t ker_dim_y, const int16_t ch_mult, const int16_t pad_x, const int16_t pad_y, const int16_t stride_x, const int16_t stride_y, const int16_t dilation_x, const int16_t dilation_y, const int32_t *<a class="el" href="group__nnfullyconnect.html#ga602e28fc157c370e73e4df5712f9df84">bias</a>, const int32_t in_offset, const int32_t ker_offset, const int32_t out_offset, uint8_t *out_tensor, const uint16_t out_tensor_dim_x, const uint16_t out_tensor_dim_y, const int32_t act_min, const int32_t act_max, const int32_t out_shift, const int32_t out_scale)</td></tr>
<tr class="memdesc:ga0b9ce54b2ac422932e71b67b66d657c1"><td class="mdescLeft">&#160;</td><td class="mdescRight">This function performs depthwise convolution for unsigned 8-bit integer inputs/outputs in any x and y dimensions with asymmetric quantization on the outputs.  <br /></td></tr>
<tr class="separator:ga0b9ce54b2ac422932e71b67b66d657c1"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table>
<a name="details" id="details"></a><h2 class="groupheader">Detailed Description</h2>
<p>The convolution functions transform the input matrix into a column vector with im2col, and then use matrix-matrix multiplication to get the convolution result. </p>
<h2 class="groupheader">Function Documentation</h2>
<a id="gab36c58937982cb251a299463e48ff357" name="gab36c58937982cb251a299463e48ff357"></a>
<h2 class="memtitle"><span class="permalink"><a href="#gab36c58937982cb251a299463e48ff357">&#9670;&#160;</a></span>hpm_nn_conv_1x1_HWC_s8_s16_s8_sym_bias_fast_any()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">static int32_t hpm_nn_conv_1x1_HWC_s8_s16_s8_sym_bias_fast_any </td>
          <td>(</td>
          <td class="paramtype">const q7_t *</td>          <td class="paramname"><span class="paramname"><em>in_tensor</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>in_tensor_dim_x</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>in_tensor_dim_y</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>in_tensor_ch</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const q7_t *</td>          <td class="paramname"><span class="paramname"><em>ker_weight</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>out_tensor_ch</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>ker_dim_x</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>ker_dim_y</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>pad_x</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>pad_y</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>stride_x</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>stride_y</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const q31_t *</td>          <td class="paramname"><span class="paramname"><em>bias</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>pre_rshift</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>out_scale</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>post_rshift</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">q15_t *</td>          <td class="paramname"><span class="paramname"><em>out_tensor</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>out_tensor_dim_x</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>out_tensor_dim_y</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">q15_t *</td>          <td class="paramname"><span class="paramname"><em>in_tmp_buf</em></span>&#160;)</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span><span class="mlabel">static</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p><code>#include &lt;<a class="el" href="hpm__math_8h.html">middleware/hpm_math/hpm_math.h</a>&gt;</code></p>

<p>This function performs 1x1 kernels convolution for signed 8-bit integer inputs and signed 16-bit integer outputs in any x and y dimensions with bias inputs and symmetric quantization on the outputs. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor</td><td>pointer of the input tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor_dim_x</td><td>x dimension of the input tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor_dim_y</td><td>y dimension of the input tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor_ch</td><td>number of input tensor channels </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">ker_weight</td><td>pointer of kernel weights </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_tensor_ch</td><td>number of output tensor channels </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">ker_dim_x</td><td>x dimension of the filter kernel </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">ker_dim_y</td><td>y dimension of the filter kernel </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">pad_x</td><td>padding size in the x dimension </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">pad_y</td><td>padding size in the y dimension </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">stride_x</td><td>convolution stride in the x dimension </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">stride_y</td><td>convolution stride in the y dimension </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">bias</td><td>pointer of the bias vector </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">pre_rshift</td><td>right shift amount for the output </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_scale</td><td>value of scaling for the output </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">post_rshift</td><td>right shift amount for the output </td></tr>
    <tr><td class="paramdir">[out]</td><td class="paramname">out_tensor</td><td>pointer of the output tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_tensor_dim_x</td><td>x dimension of the output tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_tensor_dim_y</td><td>y dimension of the output tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tmp_buf</td><td>temporary buffer for the input tensor. It is required when -mext-dsp or -mext-vector is enabled and its size must be equal to "2 * in_tensor_ch *
                                     ker_dim_x * ker_dim_y". </td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>This function returns 0 on success; otherwise, it returns -1 if its inputs do not meet the constraints (see the Note below for details).</dd></dl>
<dl class="section note"><dt>Note</dt><dd><ul>
<li>The input constraints of this function are:<ul>
<li>in_tensor_ch is a multiple of 4</li>
<li>out_tensor_ch is a multiple of 2</li>
<li>ker_dim_x is 1</li>
<li>ker_dim_y is 1</li>
<li>pad_x is 0</li>
<li>pad_y is 0</li>
<li>stride_x is 1</li>
<li>stride_y is 1</li>
</ul>
</li>
<li>The outputs will be 2-stage shifted before being stored, i.e., out = ((out &gt;&gt; pre_rshift) *out_scale) &gt;&gt; post_rshift. </li>
</ul>
</dd></dl>

</div>
</div>
<a id="ga40b28637cd642db0f36e19b0c5008433" name="ga40b28637cd642db0f36e19b0c5008433"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ga40b28637cd642db0f36e19b0c5008433">&#9670;&#160;</a></span>hpm_nn_conv_1x1_HWC_s8_s16_s8_sym_fast_any()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">static int32_t hpm_nn_conv_1x1_HWC_s8_s16_s8_sym_fast_any </td>
          <td>(</td>
          <td class="paramtype">const q7_t *</td>          <td class="paramname"><span class="paramname"><em>in_tensor</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>in_tensor_dim_x</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>in_tensor_dim_y</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>in_tensor_ch</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const q7_t *</td>          <td class="paramname"><span class="paramname"><em>ker_weight</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>out_tensor_ch</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>ker_dim_x</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>ker_dim_y</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>pad_x</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>pad_y</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>stride_x</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>stride_y</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>pre_rshift</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>out_scale</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>post_rshift</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">q15_t *</td>          <td class="paramname"><span class="paramname"><em>out_tensor</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>out_tensor_dim_x</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>out_tensor_dim_y</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">q15_t *</td>          <td class="paramname"><span class="paramname"><em>in_tmp_buf</em></span>&#160;)</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span><span class="mlabel">static</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p><code>#include &lt;<a class="el" href="hpm__math_8h.html">middleware/hpm_math/hpm_math.h</a>&gt;</code></p>

<p>This function performs 1x1 kernels convolution for signed 8-bit integer inputs and signed 16-bit integer outputs in any x and y dimensions with symmetric quantization on the outputs. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor</td><td>pointer of the input tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor_dim_x</td><td>x dimension of the input tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor_dim_y</td><td>y dimension of the input tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor_ch</td><td>number of input tensor channels </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">ker_weight</td><td>pointer of kernel weights </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_tensor_ch</td><td>number of output tensor channels </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">ker_dim_x</td><td>x dimension of the filter kernel </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">ker_dim_y</td><td>y dimension of the filter kernel </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">pad_x</td><td>padding size in the x dimension </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">pad_y</td><td>padding size in the y dimension </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">stride_x</td><td>convolution stride in the x dimension </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">stride_y</td><td>convolution stride in the y dimension </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">pre_rshift</td><td>right shift amount for the output </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_scale</td><td>value of scaling for the output </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">post_rshift</td><td>right shift amount for the output </td></tr>
    <tr><td class="paramdir">[out]</td><td class="paramname">out_tensor</td><td>pointer of the output tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_tensor_dim_x</td><td>x dimension of the output tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_tensor_dim_y</td><td>y dimension of the output tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tmp_buf</td><td>temporary buffer for the input tensor. It is required when -mext-dsp or -mext-vector is enabled and its size must be equal to 2 * in_tensor_ch * ker_dim_x * ker_dim_y. </td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>This function returns 0 on success; otherwise, it returns -1 if its inputs do not meet the constraints (see the Note below for details).</dd></dl>
<dl class="section note"><dt>Note</dt><dd><ul>
<li>The input constraints of this function are:<ul>
<li>in_tensor_ch is a multiple of 4</li>
<li>out_tensor_ch is a multiple of 2</li>
<li>ker_dim_x is 1</li>
<li>ker_dim_y is 1</li>
<li>pad_x is 0</li>
<li>pad_y is 0</li>
<li>stride_x is 1</li>
<li>stride_y is 1</li>
</ul>
</li>
<li>The outputs will be 2-stage shifted before being stored, i.e., out = ((out &gt;&gt; pre_rshift) *out_scale) &gt;&gt; post_rshift. </li>
</ul>
</dd></dl>

</div>
</div>
<a id="ga2420b518e254e3fd4abe27f16a2a7901" name="ga2420b518e254e3fd4abe27f16a2a7901"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ga2420b518e254e3fd4abe27f16a2a7901">&#9670;&#160;</a></span>hpm_nn_conv_1x1_HWC_s8_s8_s8_asym_bias_fast_any()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">static int32_t hpm_nn_conv_1x1_HWC_s8_s8_s8_asym_bias_fast_any </td>
          <td>(</td>
          <td class="paramtype">const q7_t *</td>          <td class="paramname"><span class="paramname"><em>in_tensor</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>in_tensor_dim_x</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>in_tensor_dim_y</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>in_tensor_ch</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>in_tensor_group</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const q7_t *</td>          <td class="paramname"><span class="paramname"><em>ker_weight</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>out_tensor_ch</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>pad_x</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>pad_y</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>stride_x</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>stride_y</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const int32_t *</td>          <td class="paramname"><span class="paramname"><em>bias</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">q7_t *</td>          <td class="paramname"><span class="paramname"><em>out_tensor</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const int32_t *</td>          <td class="paramname"><span class="paramname"><em>out_shift</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const int32_t *</td>          <td class="paramname"><span class="paramname"><em>out_scale</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const int32_t</td>          <td class="paramname"><span class="paramname"><em>out_offset</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const int32_t</td>          <td class="paramname"><span class="paramname"><em>in_offset</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const int32_t</td>          <td class="paramname"><span class="paramname"><em>act_min</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const int32_t</td>          <td class="paramname"><span class="paramname"><em>act_max</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>out_tensor_dim_x</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>out_tensor_dim_y</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">q15_t *</td>          <td class="paramname"><span class="paramname"><em>tmp_buf</em></span>&#160;)</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span><span class="mlabel">static</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p><code>#include &lt;<a class="el" href="hpm__math_8h.html">middleware/hpm_math/hpm_math.h</a>&gt;</code></p>

<p>This function performs 1x1 kernels convolution for signed 8-bit interger inputs/outputs in any x and y dimensions with asymmetric quantization on the outputs. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor</td><td>pointer of the input tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor_dim_x</td><td>x dimension of the input tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor_dim_y</td><td>y dimension of the input tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor_ch</td><td>number of input tensor channels </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor_group</td><td>number of input tensor groups </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">ker_weight</td><td>pointer of kernel weights </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_tensor_ch</td><td>number of output tensor channels </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">pad_x</td><td>padding size in the x dimension </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">pad_y</td><td>padding size in the y dimension </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">stride_x</td><td>convolution stride in the x dimension </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">stride_y</td><td>convolution stride in the y dimension </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">bias</td><td>pointer of the bias vector </td></tr>
    <tr><td class="paramdir">[out]</td><td class="paramname">out_tensor</td><td>pointer of the output tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_shift</td><td>pointer of the shift vector for output tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_scale</td><td>pointer of the scaling vector for output tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_offset</td><td>value of offset for the output tensor. It should be in the range of -128 to 127. </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_offset</td><td>value of offset for the input tensor It should be in the range of -127 to 128. </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">act_min</td><td>minimum value to clip out the ouput tensor. It should be in the range of -128 to 127. </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">act_max</td><td>maximum value to clip out the ouput tensor. It should be in the range of -128 to 127. </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_tensor_dim_x</td><td>x dimension of the output tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_tensor_dim_y</td><td>y dimension of the output tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">tmp_buf</td><td>dummy </td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>This function returns 0 on success; otherwise, it returns -1 if its inputs do not meet the constraints (see the Note below for details).</dd></dl>
<dl class="section note"><dt>Note</dt><dd><ul>
<li>The input constraints of this function are:<ul>
<li>in_tensor_ch is a multiple of 4</li>
<li>pad_x is 0</li>
<li>pad_y is 0</li>
<li>stride_x is 1</li>
<li>stride_y is 1 </li>
</ul>
</li>
</ul>
</dd></dl>

</div>
</div>
<a id="gaa7a9c1eab5556db05cfa3d05dfa4c71c" name="gaa7a9c1eab5556db05cfa3d05dfa4c71c"></a>
<h2 class="memtitle"><span class="permalink"><a href="#gaa7a9c1eab5556db05cfa3d05dfa4c71c">&#9670;&#160;</a></span>hpm_nn_conv_1x1_HWC_s8_s8_s8_asym_bias_fast_any_get_buffer_size()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">static int32_t hpm_nn_conv_1x1_HWC_s8_s8_s8_asym_bias_fast_any_get_buffer_size </td>
          <td>(</td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>in_tensor_ch</em></span></td><td>)</td>
          <td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span><span class="mlabel">static</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p><code>#include &lt;<a class="el" href="hpm__math_8h.html">middleware/hpm_math/hpm_math.h</a>&gt;</code></p>

<p>This function is used to get the needed size, in bytes, by the input temporary buffer of riscv_nn_conv_1x1_HWC_s8_s8_s8_asym_bias_fast_any. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor_ch</td><td>number of input tensor channels </td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>This function returns the needed size by the temporary buffer. </dd></dl>

</div>
</div>
<a id="gaf6fad182b1496ef1d5651b6628701293" name="gaf6fad182b1496ef1d5651b6628701293"></a>
<h2 class="memtitle"><span class="permalink"><a href="#gaf6fad182b1496ef1d5651b6628701293">&#9670;&#160;</a></span>hpm_nn_conv_1x1_HWC_s8_s8_s8_sft_bias_fast_any()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">static int32_t hpm_nn_conv_1x1_HWC_s8_s8_s8_sft_bias_fast_any </td>
          <td>(</td>
          <td class="paramtype">const q7_t *</td>          <td class="paramname"><span class="paramname"><em>in_tensor</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>in_tensor_dim_x</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>in_tensor_dim_y</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>in_tensor_ch</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const q7_t *</td>          <td class="paramname"><span class="paramname"><em>ker_weight</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>out_tensor_ch</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>ker_dim_x</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>ker_dim_y</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>pad_x</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>pad_y</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>stride_x</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>stride_y</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const q7_t *</td>          <td class="paramname"><span class="paramname"><em>bias</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>bias_lshift</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>out_rshift</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">q7_t *</td>          <td class="paramname"><span class="paramname"><em>out_tensor</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>out_tensor_dim_x</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>out_tensor_dim_y</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">q15_t *</td>          <td class="paramname"><span class="paramname"><em>in_tmp_buf</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">q7_t *</td>          <td class="paramname"><span class="paramname"><em>tmp_buf</em></span>&#160;)</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span><span class="mlabel">static</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p><code>#include &lt;<a class="el" href="hpm__math_8h.html">middleware/hpm_math/hpm_math.h</a>&gt;</code></p>

<p>This function performs 1x1 kernels convolution for signed 8-bit integer inputs/outputs in any x and y dimensions with shift-based quantization on the outputs. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor</td><td>pointer of the input tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor_dim_x</td><td>x dimension of the input tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor_dim_y</td><td>y dimension of the input tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor_ch</td><td>number of input tensor channels </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">ker_weight</td><td>pointer of kernel weights </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_tensor_ch</td><td>number of output tensor channels </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">ker_dim_x</td><td>x dimension of the filter kernel </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">ker_dim_y</td><td>y dimension of the filter kernel </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">pad_x</td><td>padding size in the x dimension </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">pad_y</td><td>padding size in the y dimension </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">stride_x</td><td>convolution stride in the x dimension </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">stride_y</td><td>convolution stride in the y dimension </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">bias</td><td>pointer of the bias vector </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">bias_lshift</td><td>left shift amount for the bias </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_rshift</td><td>right shift amount for the output </td></tr>
    <tr><td class="paramdir">[out]</td><td class="paramname">out_tensor</td><td>pointer of the output tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_tensor_dim_x</td><td>x dimension of the output tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_tensor_dim_y</td><td>y dimension of the output tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tmp_buf</td><td>temporary buffer for the input tensor. It is required when -mext-dsp or -mext-vector is enabled and its size must be equal to "2 * in_tensor_ch *
                                     ker_dim_x * ker_dim_y". </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">tmp_buf</td><td>dummy </td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>This function returns 0 on success; otherwise, it returns -1 if its inputs do not meet the constraints (see the Note below for details).</dd></dl>
<dl class="section note"><dt>Note</dt><dd><ul>
<li>The input constraints of this function are:<ul>
<li>in_tensor_ch is a multiple of 4</li>
<li>out_tensor_ch is a multiple of 2</li>
<li>ker_dim_x is 1</li>
<li>ker_dim_y is 1</li>
<li>pad_x is 0</li>
<li>pad_y is 0</li>
<li>stride_x is 1</li>
<li>stride_y is 1</li>
</ul>
</li>
</ul>
</dd></dl>
<p><b>Example:</b> </p><div class="fragment"><div class="line"><span class="comment">//Convolve a 160x120x20 input tensor with a 1x1 kernel and generate a</span></div>
<div class="line"><span class="comment">//160x120x8 output tensor. Let both dimensions padding be 0 and their</span></div>
<div class="line"><span class="comment">//stride be 1.</span></div>
<div class="line"> </div>
<div class="line"><span class="preprocessor">#define IN_X 160</span></div>
<div class="line"><span class="preprocessor">#define IN_Y 120</span></div>
<div class="line"><span class="preprocessor">#define IN_CH 20</span></div>
<div class="line"><span class="preprocessor">#define OUT_CH 8</span></div>
<div class="line"><span class="preprocessor">#define KER_DIM_X 1</span></div>
<div class="line"><span class="preprocessor">#define KER_DIM_Y 1</span></div>
<div class="line"><span class="preprocessor">#define PAD_X 0</span></div>
<div class="line"><span class="preprocessor">#define PAD_Y 0</span></div>
<div class="line"><span class="preprocessor">#define STRIDE_X 1</span></div>
<div class="line"><span class="preprocessor">#define STRIDE_Y 1</span></div>
<div class="line"><span class="preprocessor">#define BIAS_LSHIFT 6       </span><span class="comment">//Scale up the bias by 2^6</span></div>
<div class="line"><span class="preprocessor">#define OUT_RSHIFT 9        </span><span class="comment">//Scale down the output tensor by 1/2^9</span></div>
<div class="line"><span class="preprocessor">#define OUT_X 160</span></div>
<div class="line"><span class="preprocessor">#define OUT_Y 120</span></div>
<div class="line"> </div>
<div class="line">q7_t in_data[IN_CH * IN_X * IN_Y] = {...};</div>
<div class="line">q7_t weight[IN_CH * KER_DIM_X * KER_DIM_Y * OUT_CH] = {...};</div>
<div class="line">q7_t <a class="code hl_variable" href="group__nnfullyconnect.html#ga602e28fc157c370e73e4df5712f9df84">bias</a>[OUT_CH] = {...};</div>
<div class="line">q15_t <a class="code hl_variable" href="group__nnfullyconnect.html#ga4972f5e62722e743bc2e14d86e130148">in_tmp_buf</a>[2 * IN_CH * KER_DIM_X * KER_DIM_Y] = {0};</div>
<div class="line">q7_t out_data[OUT_CH * OUT_X * OUT_Y];</div>
<div class="line"> </div>
<div class="line">riscv_nn_conv_1x1_HWC_s8_s8_s8_sft_bias_fast_any(in_data, IN_X, IN_Y ,</div>
<div class="line">    IN_CH, weight, OUT_CH, KER_DIM_X, KER_DIM_Y, PAD_X, PAD_Y, STRIDE_X,</div>
<div class="line">    STRIDE_Y, <a class="code hl_variable" href="group__nnfullyconnect.html#ga602e28fc157c370e73e4df5712f9df84">bias</a>, BIAS_LSHIFT, OUT_RSHIFT, out_data, OUT_X, OUT_Y,</div>
<div class="line">    <a class="code hl_variable" href="group__nnfullyconnect.html#ga4972f5e62722e743bc2e14d86e130148">in_tmp_buf</a>, NULL);</div>
<div class="ttc" id="agroup__nnfullyconnect_html_ga4972f5e62722e743bc2e14d86e130148"><div class="ttname"><a href="group__nnfullyconnect.html#ga4972f5e62722e743bc2e14d86e130148">in_tmp_buf</a></div><div class="ttdeci">static int32_t in_tmp_buf</div><div class="ttdef"><b>Definition</b> hpm_math.h:14080</div></div>
<div class="ttc" id="agroup__nnfullyconnect_html_ga602e28fc157c370e73e4df5712f9df84"><div class="ttname"><a href="group__nnfullyconnect.html#ga602e28fc157c370e73e4df5712f9df84">bias</a></div><div class="ttdeci">static int32_t bias</div><div class="ttdef"><b>Definition</b> hpm_math.h:14079</div></div>
</div><!-- fragment --> 
</div>
</div>
<a id="ga291d3433cfdeac37ddedd621e0cea855" name="ga291d3433cfdeac37ddedd621e0cea855"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ga291d3433cfdeac37ddedd621e0cea855">&#9670;&#160;</a></span>hpm_nn_conv_1x1_HWC_s8_s8_s8_sym_bias_fast_any()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">static int32_t hpm_nn_conv_1x1_HWC_s8_s8_s8_sym_bias_fast_any </td>
          <td>(</td>
          <td class="paramtype">const q7_t *</td>          <td class="paramname"><span class="paramname"><em>in_tensor</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>in_tensor_dim_x</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>in_tensor_dim_y</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>in_tensor_ch</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const q7_t *</td>          <td class="paramname"><span class="paramname"><em>ker_weight</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>out_tensor_ch</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>ker_dim_x</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>ker_dim_y</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>pad_x</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>pad_y</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>stride_x</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>stride_y</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const q31_t *</td>          <td class="paramname"><span class="paramname"><em>bias</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>pre_rshift</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>out_scale</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>post_rshift</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">q7_t *</td>          <td class="paramname"><span class="paramname"><em>out_tensor</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>out_tensor_dim_x</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>out_tensor_dim_y</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">q15_t *</td>          <td class="paramname"><span class="paramname"><em>in_tmp_buf</em></span>&#160;)</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span><span class="mlabel">static</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p><code>#include &lt;<a class="el" href="hpm__math_8h.html">middleware/hpm_math/hpm_math.h</a>&gt;</code></p>

<p>This function performs 1x1 kernels convolution for signed 8-bit integer inputs/outputs in any x and y dimensions with bias inputs and symmetric quantization on the outputs.. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor</td><td>pointer of the input tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor_dim_x</td><td>x dimension of the input tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor_dim_y</td><td>y dimension of the input tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor_ch</td><td>number of input tensor channels </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">ker_weight</td><td>pointer of kernel weights </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_tensor_ch</td><td>number of output tensor channels </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">ker_dim_x</td><td>x dimension of the filter kernel </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">ker_dim_y</td><td>y dimension of the filter kernel </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">pad_x</td><td>padding size in the x dimension </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">pad_y</td><td>padding size in the y dimension </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">stride_x</td><td>convolution stride in the x dimension </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">stride_y</td><td>convolution stride in the y dimension </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">bias</td><td>pointer of the bias vector </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">pre_rshift</td><td>right shift amount for the output </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_scale</td><td>value of scaling for the output </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">post_rshift</td><td>right shift amount for the output </td></tr>
    <tr><td class="paramdir">[out]</td><td class="paramname">out_tensor</td><td>pointer of the output tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_tensor_dim_x</td><td>x dimension of the output tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_tensor_dim_y</td><td>y dimension of the output tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tmp_buf</td><td>temporary buffer for the input tensor. It is required when -mext-dsp or -mext-vector is enabled and its size must be equal to "2 * in_tensor_ch *
                                     ker_dim_x * ker_dim_y". </td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>This function returns 0 on success; otherwise, it returns -1 if its inputs do not meet the constraints (see the Note below for details).</dd></dl>
<dl class="section note"><dt>Note</dt><dd><ul>
<li>The input constraints of this function are:<ul>
<li>in_tensor_ch is a multiple of 4</li>
<li>out_tensor_ch is a multiple of 2</li>
<li>ker_dim_x is 1</li>
<li>ker_dim_y is 1</li>
<li>pad_x is 0</li>
<li>pad_y is 0</li>
<li>stride_x is 1</li>
<li>stride_y is 1</li>
</ul>
</li>
<li>The outputs will be 2-stage shifted before being stored, i.e., out = ((out &gt;&gt; pre_rshift) *out_scale) &gt;&gt; post_rshift. </li>
</ul>
</dd></dl>

</div>
</div>
<a id="ga1353634c6dd78e51d72ad649f1851741" name="ga1353634c6dd78e51d72ad649f1851741"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ga1353634c6dd78e51d72ad649f1851741">&#9670;&#160;</a></span>hpm_nn_conv_1x1_HWC_s8_s8_s8_sym_fast_any()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">static int32_t hpm_nn_conv_1x1_HWC_s8_s8_s8_sym_fast_any </td>
          <td>(</td>
          <td class="paramtype">const q7_t *</td>          <td class="paramname"><span class="paramname"><em>in_tensor</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>in_tensor_dim_x</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>in_tensor_dim_y</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>in_tensor_ch</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const q7_t *</td>          <td class="paramname"><span class="paramname"><em>ker_weight</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>out_tensor_ch</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>ker_dim_x</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>ker_dim_y</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>pad_x</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>pad_y</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>stride_x</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>stride_y</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>pre_rshift</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>out_scale</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>post_rshift</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">q7_t *</td>          <td class="paramname"><span class="paramname"><em>out_tensor</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>out_tensor_dim_x</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>out_tensor_dim_y</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">q15_t *</td>          <td class="paramname"><span class="paramname"><em>in_tmp_buf</em></span>&#160;)</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span><span class="mlabel">static</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p><code>#include &lt;<a class="el" href="hpm__math_8h.html">middleware/hpm_math/hpm_math.h</a>&gt;</code></p>

<p>This function performs 1x1 kernels convolution for signed 8-bit integer inputs/outputs in any x and y dimensions with symmetric quantization on the outputs. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor</td><td>pointer of the input tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor_dim_x</td><td>x dimension of the input tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor_dim_y</td><td>y dimension of the input tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor_ch</td><td>number of input tensor channels </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">ker_weight</td><td>pointer of kernel weights </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_tensor_ch</td><td>number of output tensor channels </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">ker_dim_x</td><td>x dimension of the filter kernel </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">ker_dim_y</td><td>y dimension of the filter kernel </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">pad_x</td><td>padding size in the x dimension </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">pad_y</td><td>padding size in the y dimension </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">stride_x</td><td>convolution stride in the x dimension </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">stride_y</td><td>convolution stride in the y dimension </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">pre_rshift</td><td>right shift amount for the output </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_scale</td><td>value of scaling for the output </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">post_rshift</td><td>right shift amount for the output </td></tr>
    <tr><td class="paramdir">[out]</td><td class="paramname">out_tensor</td><td>pointer of the output tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_tensor_dim_x</td><td>x dimension of the output tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_tensor_dim_y</td><td>y dimension of the output tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tmp_buf</td><td>temporary buffer for the input tensor. It is required when -mext-dsp or -mext-vector is enabled and its size must be equal to 2 * in_tensor_ch * ker_dim_x * ker_dim_y. </td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>This function returns 0 on success; otherwise, it returns -1 if its inputs do not meet the constraints (see the Note below for details).</dd></dl>
<dl class="section note"><dt>Note</dt><dd><ul>
<li>The input constraints of this function are:<ul>
<li>in_tensor_ch is a multiple of 4</li>
<li>out_tensor_ch is a multiple of 2</li>
<li>ker_dim_x is 1</li>
<li>ker_dim_y is 1</li>
<li>pad_x is 0</li>
<li>pad_y is 0</li>
<li>stride_x is 1</li>
<li>stride_y is 1</li>
</ul>
</li>
<li>The outputs will be 2-stage shifted before being stored, i.e., out = ((out &gt;&gt; pre_rshift) *out_scale) &gt;&gt; post_rshift. </li>
</ul>
</dd></dl>

</div>
</div>
<a id="gac7a64479b1a28db67739740f7797c0ad" name="gac7a64479b1a28db67739740f7797c0ad"></a>
<h2 class="memtitle"><span class="permalink"><a href="#gac7a64479b1a28db67739740f7797c0ad">&#9670;&#160;</a></span>hpm_nn_conv_1x1_HWC_u8_s16_s8_sym_bias_fast_any()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">static int32_t hpm_nn_conv_1x1_HWC_u8_s16_s8_sym_bias_fast_any </td>
          <td>(</td>
          <td class="paramtype">const u8_t *</td>          <td class="paramname"><span class="paramname"><em>in_tensor</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>in_tensor_dim_x</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>in_tensor_dim_y</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>in_tensor_ch</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const q7_t *</td>          <td class="paramname"><span class="paramname"><em>ker_weight</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>out_tensor_ch</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>ker_dim_x</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>ker_dim_y</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>pad_x</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>pad_y</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>stride_x</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>stride_y</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const q31_t *</td>          <td class="paramname"><span class="paramname"><em>bias</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>pre_rshift</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>out_scale</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>post_rshift</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">q15_t *</td>          <td class="paramname"><span class="paramname"><em>out_tensor</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>out_tensor_dim_x</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>out_tensor_dim_y</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">q15_t *</td>          <td class="paramname"><span class="paramname"><em>in_tmp_buf</em></span>&#160;)</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span><span class="mlabel">static</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p><code>#include &lt;<a class="el" href="hpm__math_8h.html">middleware/hpm_math/hpm_math.h</a>&gt;</code></p>

<p>This function performs 1x1 kernels convolution for unsigned 8-bit integer inputs and signed 16-bit integer outputs in any x and y dimensions with bias inputs and symmetric quantization on the outputs. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor</td><td>pointer of the input tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor_dim_x</td><td>x dimension of the input tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor_dim_y</td><td>y dimension of the input tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor_ch</td><td>number of input tensor channels </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">ker_weight</td><td>pointer of kernel weights </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_tensor_ch</td><td>number of output tensor channels </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">ker_dim_x</td><td>x dimension of the filter kernel </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">ker_dim_y</td><td>y dimension of the filter kernel </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">pad_x</td><td>padding size in the x dimension </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">pad_y</td><td>padding size in the y dimension </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">stride_x</td><td>convolution stride in the x dimension </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">stride_y</td><td>convolution stride in the y dimension </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">bias</td><td>pointer of the bias vector </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">pre_rshift</td><td>right shift amount for the output </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_scale</td><td>value of scaling for the output </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">post_rshift</td><td>right shift amount for the output </td></tr>
    <tr><td class="paramdir">[out]</td><td class="paramname">out_tensor</td><td>pointer of the output tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_tensor_dim_x</td><td>x dimension of the output tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_tensor_dim_y</td><td>y dimension of the output tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tmp_buf</td><td>temporary buffer for the input tensor. It is required when -mext-dsp or -mext-vector is enabled and its size must be equal to "2 * in_tensor_ch *
                                     ker_dim_x * ker_dim_y". </td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>This function returns 0 on success; otherwise, it returns -1 if its inputs do not meet the constraints (see the Note below for details).</dd></dl>
<dl class="section note"><dt>Note</dt><dd><ul>
<li>The input constraints of this function are:<ul>
<li>in_tensor_ch is a multiple of 4</li>
<li>out_tensor_ch is a multiple of 2</li>
<li>ker_dim_x is 1</li>
<li>ker_dim_y is 1</li>
<li>pad_x is 0</li>
<li>pad_y is 0</li>
<li>stride_x is 1</li>
<li>stride_y is 1</li>
</ul>
</li>
<li>The outputs will be 2-stage shifted before being stored, i.e., out = ((out &gt;&gt; pre_rshift) *out_scale) &gt;&gt; post_rshift. </li>
</ul>
</dd></dl>

</div>
</div>
<a id="ga2e95b6dd2dc0ebe0fb31b4ce4e97b5c0" name="ga2e95b6dd2dc0ebe0fb31b4ce4e97b5c0"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ga2e95b6dd2dc0ebe0fb31b4ce4e97b5c0">&#9670;&#160;</a></span>hpm_nn_conv_1x1_HWC_u8_s16_s8_sym_fast_any()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">static int32_t hpm_nn_conv_1x1_HWC_u8_s16_s8_sym_fast_any </td>
          <td>(</td>
          <td class="paramtype">const u8_t *</td>          <td class="paramname"><span class="paramname"><em>in_tensor</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>in_tensor_dim_x</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>in_tensor_dim_y</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>in_tensor_ch</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const q7_t *</td>          <td class="paramname"><span class="paramname"><em>ker_weight</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>out_tensor_ch</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>ker_dim_x</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>ker_dim_y</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>pad_x</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>pad_y</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>stride_x</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>stride_y</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>pre_rshift</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>out_scale</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>post_rshift</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">q15_t *</td>          <td class="paramname"><span class="paramname"><em>out_tensor</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>out_tensor_dim_x</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>out_tensor_dim_y</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">q15_t *</td>          <td class="paramname"><span class="paramname"><em>in_tmp_buf</em></span>&#160;)</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span><span class="mlabel">static</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p><code>#include &lt;<a class="el" href="hpm__math_8h.html">middleware/hpm_math/hpm_math.h</a>&gt;</code></p>

<p>This function performs 1x1 kernels convolution for unsigned 8-bit integer inputs and signed 16-bit integer outputs in any x and y dimensions with symmetric quantization on the outputs. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor</td><td>pointer of the input tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor_dim_x</td><td>x dimension of the input tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor_dim_y</td><td>y dimension of the input tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor_ch</td><td>number of input tensor channels </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">ker_weight</td><td>pointer of kernel weights </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_tensor_ch</td><td>number of output tensor channels </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">ker_dim_x</td><td>x dimension of the filter kernel </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">ker_dim_y</td><td>y dimension of the filter kernel </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">pad_x</td><td>padding size in the x dimension </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">pad_y</td><td>padding size in the y dimension </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">stride_x</td><td>convolution stride in the x dimension </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">stride_y</td><td>convolution stride in the y dimension </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">pre_rshift</td><td>right shift amount for the output </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_scale</td><td>value of scaling for the output </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">post_rshift</td><td>right shift amount for the output </td></tr>
    <tr><td class="paramdir">[out]</td><td class="paramname">out_tensor</td><td>pointer of the output tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_tensor_dim_x</td><td>x dimension of the output tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_tensor_dim_y</td><td>y dimension of the output tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tmp_buf</td><td>temporary buffer for the input tensor. It is required when -mext-dsp or -mext-vector is enabled and its size must be equal to "2 * in_tensor_ch *
                                     ker_dim_x * ker_dim_y". </td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>This function returns 0 on success; otherwise, it returns -1 if its inputs do not meet the constraints (see the Note below for details).</dd></dl>
<dl class="section note"><dt>Note</dt><dd><ul>
<li>The input constraints of this function are:<ul>
<li>in_tensor_ch is a multiple of 4</li>
<li>out_tensor_ch is a multiple of 2</li>
<li>ker_dim_x is 1</li>
<li>ker_dim_y is 1</li>
<li>pad_x is 0</li>
<li>pad_y is 0</li>
<li>stride_x is 1</li>
<li>stride_y is 1</li>
</ul>
</li>
<li>The outputs will be 2-stage shifted before being stored, i.e., out = ((out &gt;&gt; pre_rshift) *out_scale) &gt;&gt; post_rshift. </li>
</ul>
</dd></dl>

</div>
</div>
<a id="ga1ee3747f0f50187370bb25d91b412447" name="ga1ee3747f0f50187370bb25d91b412447"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ga1ee3747f0f50187370bb25d91b412447">&#9670;&#160;</a></span>hpm_nn_conv_1x1_HWC_u8_s8_s8_sym_bias_fast_any()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">static int32_t hpm_nn_conv_1x1_HWC_u8_s8_s8_sym_bias_fast_any </td>
          <td>(</td>
          <td class="paramtype">const u8_t *</td>          <td class="paramname"><span class="paramname"><em>in_tensor</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>in_tensor_dim_x</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>in_tensor_dim_y</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>in_tensor_ch</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const q7_t *</td>          <td class="paramname"><span class="paramname"><em>ker_weight</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>out_tensor_ch</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>ker_dim_x</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>ker_dim_y</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>pad_x</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>pad_y</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>stride_x</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>stride_y</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const q31_t *</td>          <td class="paramname"><span class="paramname"><em>bias</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>pre_rshift</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>out_scale</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>post_rshift</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">q7_t *</td>          <td class="paramname"><span class="paramname"><em>out_tensor</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>out_tensor_dim_x</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>out_tensor_dim_y</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">q15_t *</td>          <td class="paramname"><span class="paramname"><em>in_tmp_buf</em></span>&#160;)</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span><span class="mlabel">static</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p><code>#include &lt;<a class="el" href="hpm__math_8h.html">middleware/hpm_math/hpm_math.h</a>&gt;</code></p>

<p>This function performs 1x1 kernels convolution for unsigned 8-bit integer inputs and signed 8-bit integer outputs in any x and y dimensions with bias inputs and symmetric quantization on the outputs. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor</td><td>pointer of the input tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor_dim_x</td><td>x dimension of the input tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor_dim_y</td><td>y dimension of the input tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor_ch</td><td>number of input tensor channels </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">ker_weight</td><td>pointer of kernel weights </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_tensor_ch</td><td>number of output tensor channels </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">ker_dim_x</td><td>x dimension of the filter kernel </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">ker_dim_y</td><td>y dimension of the filter kernel </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">pad_x</td><td>padding size in the x dimension </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">pad_y</td><td>padding size in the y dimension </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">stride_x</td><td>convolution stride in the x dimension </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">stride_y</td><td>convolution stride in the y dimension </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">bias</td><td>pointer of the bias vector </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">pre_rshift</td><td>right shift amount for the output </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_scale</td><td>value of scaling for the output </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">post_rshift</td><td>right shift amount for the output </td></tr>
    <tr><td class="paramdir">[out]</td><td class="paramname">out_tensor</td><td>pointer of the output tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_tensor_dim_x</td><td>x dimension of the output tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_tensor_dim_y</td><td>y dimension of the output tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tmp_buf</td><td>temporary buffer for the input tensor. It is required when -mext-dsp or -mext-vector is enabled and its size must be equal to "2 * in_tensor_ch *
                                     ker_dim_x * ker_dim_y". </td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>This function returns 0 on success; otherwise, it returns -1 if its inputs do not meet the constraints (see the Note below for details).</dd></dl>
<dl class="section note"><dt>Note</dt><dd><ul>
<li>The input constraints of this function are:<ul>
<li>in_tensor_ch is a multiple of 4</li>
<li>out_tensor_ch is a multiple of 2</li>
<li>ker_dim_x is 1</li>
<li>ker_dim_y is 1</li>
<li>pad_x is 0</li>
<li>pad_y is 0</li>
<li>stride_x is 1</li>
<li>stride_y is 1</li>
</ul>
</li>
<li>The outputs will be 2-stage shifted before being stored, i.e., out = ((out &gt;&gt; pre_rshift) *out_scale) &gt;&gt; post_rshift. </li>
</ul>
</dd></dl>

</div>
</div>
<a id="ga13dceb3700caa3c22c53bd7f6017a40d" name="ga13dceb3700caa3c22c53bd7f6017a40d"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ga13dceb3700caa3c22c53bd7f6017a40d">&#9670;&#160;</a></span>hpm_nn_conv_1x1_HWC_u8_s8_s8_sym_fast_any()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">static int32_t hpm_nn_conv_1x1_HWC_u8_s8_s8_sym_fast_any </td>
          <td>(</td>
          <td class="paramtype">const u8_t *</td>          <td class="paramname"><span class="paramname"><em>in_tensor</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>in_tensor_dim_x</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>in_tensor_dim_y</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>in_tensor_ch</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const q7_t *</td>          <td class="paramname"><span class="paramname"><em>ker_weight</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>out_tensor_ch</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>ker_dim_x</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>ker_dim_y</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>pad_x</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>pad_y</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>stride_x</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>stride_y</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>pre_rshift</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>out_scale</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>post_rshift</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">q7_t *</td>          <td class="paramname"><span class="paramname"><em>out_tensor</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>out_tensor_dim_x</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>out_tensor_dim_y</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">q15_t *</td>          <td class="paramname"><span class="paramname"><em>in_tmp_buf</em></span>&#160;)</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span><span class="mlabel">static</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p><code>#include &lt;<a class="el" href="hpm__math_8h.html">middleware/hpm_math/hpm_math.h</a>&gt;</code></p>

<p>This function performs 1x1 kernels convolution for unsigned 8-bit integer inputs and signed 8-bit integer outputs in any x and y dimensions with symmetric quantization on the outputs. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor</td><td>pointer of the input tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor_dim_x</td><td>x dimension of the input tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor_dim_y</td><td>y dimension of the input tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor_ch</td><td>number of input tensor channels </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">ker_weight</td><td>pointer of kernel weights </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_tensor_ch</td><td>number of output tensor channels </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">ker_dim_x</td><td>x dimension of the filter kernel </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">ker_dim_y</td><td>y dimension of the filter kernel </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">pad_x</td><td>padding size in the x dimension </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">pad_y</td><td>padding size in the y dimension </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">stride_x</td><td>convolution stride in the x dimension </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">stride_y</td><td>convolution stride in the y dimension </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">pre_rshift</td><td>right shift amount for the output </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_scale</td><td>value of scaling for the output </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">post_rshift</td><td>right shift amount for the output </td></tr>
    <tr><td class="paramdir">[out]</td><td class="paramname">out_tensor</td><td>pointer of the output tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_tensor_dim_x</td><td>x dimension of the output tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_tensor_dim_y</td><td>y dimension of the output tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tmp_buf</td><td>temporary buffer for the input tensor. It is required when -mext-dsp or -mext-vector is enabled and its size must be equal to 2 * in_tensor_ch * ker_dim_x * ker_dim_y. </td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>This function returns 0 on success; otherwise, it returns -1 if its inputs do not meet the constraints (see the Note below for details).</dd></dl>
<dl class="section note"><dt>Note</dt><dd><ul>
<li>The input constraints of this function are:<ul>
<li>in_tensor_ch is a multiple of 4</li>
<li>out_tensor_ch is a multiple of 2</li>
<li>ker_dim_x is 1</li>
<li>ker_dim_y is 1</li>
<li>pad_x is 0</li>
<li>pad_y is 0</li>
<li>stride_x is 1</li>
<li>stride_y is 1</li>
</ul>
</li>
<li>The outputs will be 2-stage shifted before being stored, i.e., out = ((out &gt;&gt; pre_rshift) *out_scale) &gt;&gt; post_rshift. </li>
</ul>
</dd></dl>

</div>
</div>
<a id="gad97f5d188a38e067ca8afe1d26a3f9e6" name="gad97f5d188a38e067ca8afe1d26a3f9e6"></a>
<h2 class="memtitle"><span class="permalink"><a href="#gad97f5d188a38e067ca8afe1d26a3f9e6">&#9670;&#160;</a></span>hpm_nn_conv_1x1_HWC_u8_u8_s8_sym_bias_fast_any()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">static int32_t hpm_nn_conv_1x1_HWC_u8_u8_s8_sym_bias_fast_any </td>
          <td>(</td>
          <td class="paramtype">const u8_t *</td>          <td class="paramname"><span class="paramname"><em>in_tensor</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>in_tensor_dim_x</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>in_tensor_dim_y</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>in_tensor_ch</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const q7_t *</td>          <td class="paramname"><span class="paramname"><em>ker_weight</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>out_tensor_ch</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>ker_dim_x</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>ker_dim_y</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>pad_x</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>pad_y</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>stride_x</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>stride_y</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const q31_t *</td>          <td class="paramname"><span class="paramname"><em>bias</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>pre_rshift</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>out_scale</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>post_rshift</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">u8_t *</td>          <td class="paramname"><span class="paramname"><em>out_tensor</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>out_tensor_dim_x</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>out_tensor_dim_y</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">q15_t *</td>          <td class="paramname"><span class="paramname"><em>in_tmp_buf</em></span>&#160;)</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span><span class="mlabel">static</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p><code>#include &lt;<a class="el" href="hpm__math_8h.html">middleware/hpm_math/hpm_math.h</a>&gt;</code></p>

<p>This function performs 1x1 kernels convolution for unsigned 8-bit integer inputs/outputs in any x and y dimensions with bias inputs and symmetric quantization on the outputs. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor</td><td>pointer of the input tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor_dim_x</td><td>x dimension of the input tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor_dim_y</td><td>y dimension of the input tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor_ch</td><td>number of input tensor channels </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">ker_weight</td><td>pointer of kernel weights </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_tensor_ch</td><td>number of output tensor channels </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">ker_dim_x</td><td>x dimension of the filter kernel </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">ker_dim_y</td><td>y dimension of the filter kernel </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">pad_x</td><td>padding size in the x dimension </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">pad_y</td><td>padding size in the y dimension </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">stride_x</td><td>convolution stride in the x dimension </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">stride_y</td><td>convolution stride in the y dimension </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">bias</td><td>pointer of the bias vector </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">pre_rshift</td><td>right shift amount for the output </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_scale</td><td>value of scaling for the output </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">post_rshift</td><td>right shift amount for the output </td></tr>
    <tr><td class="paramdir">[out]</td><td class="paramname">out_tensor</td><td>pointer of the output tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_tensor_dim_x</td><td>x dimension of the output tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_tensor_dim_y</td><td>y dimension of the output tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tmp_buf</td><td>temporary buffer for the input tensor. It is required when -mext-dsp or -mext-vector is enabled and its size must be equal to "2 * in_tensor_ch *
                                     ker_dim_x * ker_dim_y". </td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>This function returns 0 on success; otherwise, it returns -1 if its inputs do not meet the constraints (see the Note below for details).</dd></dl>
<dl class="section note"><dt>Note</dt><dd><ul>
<li>The input constraints of this function are:<ul>
<li>in_tensor_ch is a multiple of 4</li>
<li>out_tensor_ch is a multiple of 2</li>
<li>ker_dim_x is 1</li>
<li>ker_dim_y is 1</li>
<li>pad_x is 0</li>
<li>pad_y is 0</li>
<li>stride_x is 1</li>
<li>stride_y is 1</li>
</ul>
</li>
<li>The outputs will be 2-stage shifted before being stored, i.e., out = ((out &gt;&gt; pre_rshift) *out_scale) &gt;&gt; post_rshift. </li>
</ul>
</dd></dl>

</div>
</div>
<a id="ga1a24af57ab9a2be65f085e36c0c80520" name="ga1a24af57ab9a2be65f085e36c0c80520"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ga1a24af57ab9a2be65f085e36c0c80520">&#9670;&#160;</a></span>hpm_nn_conv_1x1_HWC_u8_u8_s8_sym_fast_any()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">static int32_t hpm_nn_conv_1x1_HWC_u8_u8_s8_sym_fast_any </td>
          <td>(</td>
          <td class="paramtype">const u8_t *</td>          <td class="paramname"><span class="paramname"><em>in_tensor</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>in_tensor_dim_x</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>in_tensor_dim_y</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>in_tensor_ch</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const q7_t *</td>          <td class="paramname"><span class="paramname"><em>ker_weight</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>out_tensor_ch</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>ker_dim_x</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>ker_dim_y</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>pad_x</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>pad_y</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>stride_x</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>stride_y</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>pre_rshift</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>out_scale</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>post_rshift</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">u8_t *</td>          <td class="paramname"><span class="paramname"><em>out_tensor</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>out_tensor_dim_x</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>out_tensor_dim_y</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">q15_t *</td>          <td class="paramname"><span class="paramname"><em>in_tmp_buf</em></span>&#160;)</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span><span class="mlabel">static</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p><code>#include &lt;<a class="el" href="hpm__math_8h.html">middleware/hpm_math/hpm_math.h</a>&gt;</code></p>

<p>This function performs 1x1 kernels convolution for unsigned 8-bit integer inputs/outputs in any x and y dimensions with symmetric quantization on the outputs. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor</td><td>pointer of the input tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor_dim_x</td><td>x dimension of the input tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor_dim_y</td><td>y dimension of the input tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor_ch</td><td>number of input tensor channels </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">ker_weight</td><td>pointer of kernel weights </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_tensor_ch</td><td>number of output tensor channels </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">ker_dim_x</td><td>x dimension of the filter kernel </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">ker_dim_y</td><td>y dimension of the filter kernel </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">pad_x</td><td>padding size in the x dimension </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">pad_y</td><td>padding size in the y dimension </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">stride_x</td><td>convolution stride in the x dimension </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">stride_y</td><td>convolution stride in the y dimension </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">pre_rshift</td><td>right shift amount for the output </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_scale</td><td>value of scaling for the output </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">post_rshift</td><td>right shift amount for the output </td></tr>
    <tr><td class="paramdir">[out]</td><td class="paramname">out_tensor</td><td>pointer of the output tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_tensor_dim_x</td><td>x dimension of the output tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_tensor_dim_y</td><td>y dimension of the output tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tmp_buf</td><td>temporary buffer for the input tensor. It is required when -mext-dsp or -mext-vector is enabled and its size must be equal to "2 * in_tensor_ch *
                                     ker_dim_x * ker_dim_y". </td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>This function returns 0 on success; otherwise, it returns -1 if its inputs do not meet the constraints (see the Note below for details).</dd></dl>
<dl class="section note"><dt>Note</dt><dd><ul>
<li>The input constraints of this function are:<ul>
<li>in_tensor_ch is a multiple of 4</li>
<li>out_tensor_ch is a multiple of 2</li>
<li>ker_dim_x is 1</li>
<li>ker_dim_y is 1</li>
<li>pad_x is 0</li>
<li>pad_y is 0</li>
<li>stride_x is 1</li>
<li>stride_y is 1</li>
</ul>
</li>
<li>The outputs will be 2-stage shifted before being stored, i.e., out = ((out &gt;&gt; pre_rshift) *out_scale) &gt;&gt; post_rshift. </li>
</ul>
</dd></dl>

</div>
</div>
<a id="gae1c62cb7f29063bf12498148562fdca7" name="gae1c62cb7f29063bf12498148562fdca7"></a>
<h2 class="memtitle"><span class="permalink"><a href="#gae1c62cb7f29063bf12498148562fdca7">&#9670;&#160;</a></span>hpm_nn_conv_1xn_HWC_s8_s8_s8_asym_bias_any()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">static int hpm_nn_conv_1xn_HWC_s8_s8_s8_asym_bias_any </td>
          <td>(</td>
          <td class="paramtype">const q7_t *</td>          <td class="paramname"><span class="paramname"><em>in_tensor</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>in_tensor_dim_x</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>in_tensor_ch</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>in_tensor_group</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const q7_t *</td>          <td class="paramname"><span class="paramname"><em>ker_weight</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>out_tensor_ch</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>ker_dim_x</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>pad_x</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>stride_x</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const int32_t *</td>          <td class="paramname"><span class="paramname"><em>bias</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">q7_t *</td>          <td class="paramname"><span class="paramname"><em>out_tensor</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const int32_t *</td>          <td class="paramname"><span class="paramname"><em>out_shift</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const int32_t *</td>          <td class="paramname"><span class="paramname"><em>out_scale</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const int32_t</td>          <td class="paramname"><span class="paramname"><em>out_offset</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const int32_t</td>          <td class="paramname"><span class="paramname"><em>in_offset</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const int32_t</td>          <td class="paramname"><span class="paramname"><em>act_min</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const int32_t</td>          <td class="paramname"><span class="paramname"><em>act_max</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>out_tensor_dim_x</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">q15_t *</td>          <td class="paramname"><span class="paramname"><em>in_tmp_buf</em></span>&#160;)</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span><span class="mlabel">static</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p><code>#include &lt;<a class="el" href="hpm__math_8h.html">middleware/hpm_math/hpm_math.h</a>&gt;</code></p>

<p>This function performs 1xn kernels convolution for signed 8-bit integer inputs/outputs in any x and y dimensions with asymmetric quantization on the outputs. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor</td><td>pointer of the input tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor_dim_x</td><td>x dimension of the input tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor_ch</td><td>number of input tensor channels </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor_group</td><td>dummy </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">ker_weight</td><td>pointer of kernel weights </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_tensor_ch</td><td>number of output tensor channels </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">ker_dim_x</td><td>x dimension of the filter kernel </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">pad_x</td><td>padding size in the x dimension </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">stride_x</td><td>convolution stride in the x dimension </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">bias</td><td>pointer of the bias vector </td></tr>
    <tr><td class="paramdir">[out]</td><td class="paramname">out_tensor</td><td>pointer of the output tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_shift</td><td>pointer of the shift vector for output tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_scale</td><td>pointer of the scaling vector for output tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_offset</td><td>value of offset for the output tensor. It should be in the range of -128 to 127. </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_offset</td><td>value of offset for the input tensor It should be in the range of -127 to 128. </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">act_min</td><td>minimum value to clip out the ouput tensor. It should be in the range of -128 to 127. </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">act_max</td><td>maximum value to clip out the ouput tensor. It should be in the range of -128 to 127. </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_tensor_dim_x</td><td>x dimension of the output tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tmp_buf</td><td>temporary buffer for the input tensor. It is required when -mext-dsp or -mext-vector is enabled and its needed size could be get by calling riscv_nn_conv_1xn_HWC_s8_s8_s8_asym_bias_any_get_buffer_size. </td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>This function returns 0 on success; otherwise, it returns -1 if its inputs do not meet the constraint that out_tensor_dim_x is a multiple of 4. </dd></dl>

</div>
</div>
<a id="ga1e0aac3f254eb048c027362e2fa40c0a" name="ga1e0aac3f254eb048c027362e2fa40c0a"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ga1e0aac3f254eb048c027362e2fa40c0a">&#9670;&#160;</a></span>hpm_nn_conv_1xn_HWC_s8_s8_s8_asym_bias_any_get_buffer_size()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">static int32_t hpm_nn_conv_1xn_HWC_s8_s8_s8_asym_bias_any_get_buffer_size </td>
          <td>(</td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>in_tensor_ch</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>ker_dim_x</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>ker_dim_y</em></span>&#160;)</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span><span class="mlabel">static</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p><code>#include &lt;<a class="el" href="hpm__math_8h.html">middleware/hpm_math/hpm_math.h</a>&gt;</code></p>

<p>This function is used to get the needed size, in bytes, by the input temporary buffer of riscv_nn_conv_1xn_HWC_s8_s8_s8_asym_bias_any. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor_ch</td><td>number of input tensor channels </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">ker_dim_x</td><td>x dimension of the filter kernel </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">ker_dim_y</td><td>y dimension of the filter kernel. It is always 1 here. </td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>This function returns the needed size by the temporary buffer. </dd></dl>

</div>
</div>
<a id="ga9cfa87c1ba0068ad397a429d1ac1aab2" name="ga9cfa87c1ba0068ad397a429d1ac1aab2"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ga9cfa87c1ba0068ad397a429d1ac1aab2">&#9670;&#160;</a></span>hpm_nn_conv_dw_HWC_3x3_s8_s8_s8_asym_bias_any()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">static int32_t hpm_nn_conv_dw_HWC_3x3_s8_s8_s8_asym_bias_any </td>
          <td>(</td>
          <td class="paramtype">const int8_t *</td>          <td class="paramname"><span class="paramname"><em>in_tensor</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const int32_t</td>          <td class="paramname"><span class="paramname"><em>in_tensor_dim_x</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const int32_t</td>          <td class="paramname"><span class="paramname"><em>in_tensor_dim_y</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const int32_t</td>          <td class="paramname"><span class="paramname"><em>in_tensor_ch</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const int8_t *</td>          <td class="paramname"><span class="paramname"><em>ker_weight</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const int32_t</td>          <td class="paramname"><span class="paramname"><em>out_tensor_ch</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const int32_t</td>          <td class="paramname"><span class="paramname"><em>pad_x</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const int32_t</td>          <td class="paramname"><span class="paramname"><em>pad_y</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const int32_t</td>          <td class="paramname"><span class="paramname"><em>stride_x</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const int32_t</td>          <td class="paramname"><span class="paramname"><em>stride_y</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const int32_t *</td>          <td class="paramname"><span class="paramname"><em>bias</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int8_t *</td>          <td class="paramname"><span class="paramname"><em>out_tensor</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const int32_t *</td>          <td class="paramname"><span class="paramname"><em>out_shift</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const int32_t *</td>          <td class="paramname"><span class="paramname"><em>out_scale</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const int32_t</td>          <td class="paramname"><span class="paramname"><em>out_tensor_dim_x</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const int32_t</td>          <td class="paramname"><span class="paramname"><em>out_tensor_dim_y</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const int32_t</td>          <td class="paramname"><span class="paramname"><em>out_offset</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const int32_t</td>          <td class="paramname"><span class="paramname"><em>in_offset</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const int32_t</td>          <td class="paramname"><span class="paramname"><em>act_min</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const int32_t</td>          <td class="paramname"><span class="paramname"><em>act_max</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const int32_t</td>          <td class="paramname"><span class="paramname"><em>dilation_x</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const int32_t</td>          <td class="paramname"><span class="paramname"><em>dilation_y</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int16_t *</td>          <td class="paramname"><span class="paramname"><em>tmp_buf</em></span>&#160;)</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span><span class="mlabel">static</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p><code>#include &lt;<a class="el" href="hpm__math_8h.html">middleware/hpm_math/hpm_math.h</a>&gt;</code></p>

<p>This function performs depthwise 3x3 kernels convolution for signed 8-bit integer inputs/outputs in any x and y dimensions with asymmetric quantization on the outputs. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor</td><td>pointer of the input tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor_dim_x</td><td>x dimension of the input tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor_dim_y</td><td>y dimension of the input tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor_ch</td><td>number of input tensor channels </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">ker_weight</td><td>pointer of kernel weights </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_tensor_ch</td><td>number of output tensor channels </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">pad_x</td><td>padding size in the x dimension </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">pad_y</td><td>padding size in the y dimension </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">stride_x</td><td>convolution stride in the x dimension </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">stride_y</td><td>convolution stride in the y dimension </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">bias</td><td>pointer of the bias vector </td></tr>
    <tr><td class="paramdir">[out]</td><td class="paramname">out_tensor</td><td>pointer of the output tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_shift</td><td>pointer of the shift vector for output tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_scale</td><td>pointer of the scaling vector for output tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_tensor_dim_x</td><td>x dimension of the output tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_tensor_dim_y</td><td>y dimension of the output tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_offset</td><td>value of offset for the output tensor. It should be in the range of -128 to 127. </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_offset</td><td>value of offset for the input tensor It should be in the range of -127 to 128. </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">act_min</td><td>minimum value to clip out the ouput tensor. It should be in the range of -128 to 127. </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">act_max</td><td>maximum value to clip out the ouput tensor. It should be in the range of -128 to 127. </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">dilation_x</td><td>dummy </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">dilation_y</td><td>dummy </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">tmp_buf</td><td>dummy </td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>This function returns 0 on success; otherwise, it returns -1 if its inputs do not meet the constraints that in_tensor_ch has to be equal to out_tensor_ch and pad_x is less than 1. </dd></dl>

</div>
</div>
<a id="gacb88aa3904d0374b532ac0dfae36d0ae" name="gacb88aa3904d0374b532ac0dfae36d0ae"></a>
<h2 class="memtitle"><span class="permalink"><a href="#gacb88aa3904d0374b532ac0dfae36d0ae">&#9670;&#160;</a></span>hpm_nn_conv_dw_HWC_s8_s16_s8_sym()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">static int32_t hpm_nn_conv_dw_HWC_s8_s16_s8_sym </td>
          <td>(</td>
          <td class="paramtype">const q7_t *</td>          <td class="paramname"><span class="paramname"><em>in_tensor</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>in_tensor_dim</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>in_tensor_ch</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const q7_t *</td>          <td class="paramname"><span class="paramname"><em>ker_weight</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>out_tensor_ch</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>ker_dim</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>pad</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>stride</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>pre_rshift</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>out_scale</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>post_rshift</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">q15_t *</td>          <td class="paramname"><span class="paramname"><em>out_tensor</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>out_tensor_dim</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">q15_t *</td>          <td class="paramname"><span class="paramname"><em>in_tmp_buf</em></span>&#160;)</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span><span class="mlabel">static</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p><code>#include &lt;<a class="el" href="hpm__math_8h.html">middleware/hpm_math/hpm_math.h</a>&gt;</code></p>

<p>This function performs depthwise convolution for signed 8-bit integer inputs and signed 16-bit integer outputs with symmetric quantization on the outputs. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor</td><td>pointer of the input tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor_dim</td><td>dimension of the input tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor_ch</td><td>number of input tensor channels </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">ker_weight</td><td>pointer of kernel weights </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_tensor_ch</td><td>number of output tensor channels </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">ker_dim</td><td>dimension of the filter kernel </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">pad</td><td>padding size </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">stride</td><td>convolution stride </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">pre_rshift</td><td>right shift amount for the output </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_scale</td><td>value of scaling for the output </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">post_rshift</td><td>right shift amount for the output </td></tr>
    <tr><td class="paramdir">[out]</td><td class="paramname">out_tensor</td><td>pointer of the output tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_tensor_dim</td><td>dimension of the output tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tmp_buf</td><td>temporary buffer for the input tensor. It is required when -mext-dsp or -mext-vector is enabled and its size must be equal to "(in_tensor_ch * ker_dim * ker_dim + 1) / 2". </td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>This function returns 0 on success; otherwise, it returns -1 if its inputs do not meet the constraints that in_tensor_ch has to be equal to out_tensor_ch.</dd></dl>
<dl class="section note"><dt>Note</dt><dd>The outputs will be 2-stage shifted before being stored, i.e., out = ((out &gt;&gt; pre_rshift) *out_scale) &gt;&gt; post_rshift. </dd></dl>

</div>
</div>
<a id="ga6bf168c41fda67552bd4b5f5c200a268" name="ga6bf168c41fda67552bd4b5f5c200a268"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ga6bf168c41fda67552bd4b5f5c200a268">&#9670;&#160;</a></span>hpm_nn_conv_dw_HWC_s8_s16_s8_sym_any()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">static int32_t hpm_nn_conv_dw_HWC_s8_s16_s8_sym_any </td>
          <td>(</td>
          <td class="paramtype">const q7_t *</td>          <td class="paramname"><span class="paramname"><em>in_tensor</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>in_tensor_dim_x</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>in_tensor_dim_y</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>in_tensor_ch</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const q7_t *</td>          <td class="paramname"><span class="paramname"><em>ker_weight</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>out_tensor_ch</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>ker_dim_x</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>ker_dim_y</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>pad_x</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>pad_y</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>stride_x</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>stride_y</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>pre_rshift</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>out_scale</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>post_rshift</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">q15_t *</td>          <td class="paramname"><span class="paramname"><em>out_tensor</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>out_tensor_dim_x</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>out_tensor_dim_y</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">q15_t *</td>          <td class="paramname"><span class="paramname"><em>in_tmp_buf</em></span>&#160;)</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span><span class="mlabel">static</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p><code>#include &lt;<a class="el" href="hpm__math_8h.html">middleware/hpm_math/hpm_math.h</a>&gt;</code></p>

<p>This function performs depthwise convolution for signed 8-bit integer inputs and signed 16-bit integer outputs in any x and y dimensions with symmetric quantization on the outputs. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor</td><td>pointer of the input tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor_dim_x</td><td>x dimension of the input tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor_dim_y</td><td>y dimension of the input tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor_ch</td><td>number of input tensor channels </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">ker_weight</td><td>pointer of kernel weights </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_tensor_ch</td><td>number of output tensor channels </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">ker_dim_x</td><td>x dimension of the filter kernel </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">ker_dim_y</td><td>y dimension of the filter kernel </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">pad_x</td><td>padding size in the x dimension </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">pad_y</td><td>padding size in the y dimension </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">stride_x</td><td>convolution stride in the x dimension </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">stride_y</td><td>convolution stride in the y dimension </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">pre_rshift</td><td>right shift amount for the output </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_scale</td><td>value of scaling for the output </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">post_rshift</td><td>right shift amount for the output </td></tr>
    <tr><td class="paramdir">[out]</td><td class="paramname">out_tensor</td><td>pointer of the output tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_tensor_dim_x</td><td>x dimension of the output tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_tensor_dim_y</td><td>y dimension of the output tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tmp_buf</td><td>temporary buffer for the input tensor. It is required when -mext-dsp or -mext-vector is enabled and its size must be equal to "(in_tensor_ch *
                                     ker_dim_x * ker_dim_y + 1) / 2". </td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>This function returns 0 on success; otherwise, it returns -1 if its inputs do not meet the constraints that in_tensor_ch must be equal to out_tensor_ch.</dd></dl>
<dl class="section note"><dt>Note</dt><dd>The outputs will be 2-stage shifted before being stored, i.e., out = ((out &gt;&gt; pre_rshift) *out_scale) &gt;&gt; post_rshift. </dd></dl>

</div>
</div>
<a id="ga3c6fcf87e6f94a46600aab9b8154e747" name="ga3c6fcf87e6f94a46600aab9b8154e747"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ga3c6fcf87e6f94a46600aab9b8154e747">&#9670;&#160;</a></span>hpm_nn_conv_dw_HWC_s8_s16_s8_sym_bias()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">static int32_t hpm_nn_conv_dw_HWC_s8_s16_s8_sym_bias </td>
          <td>(</td>
          <td class="paramtype">const q7_t *</td>          <td class="paramname"><span class="paramname"><em>in_tensor</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>in_tensor_dim</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>in_tensor_ch</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const q7_t *</td>          <td class="paramname"><span class="paramname"><em>ker_weight</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>out_tensor_ch</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>ker_dim</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>pad</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>stride</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const q31_t *</td>          <td class="paramname"><span class="paramname"><em>bias</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>pre_rshift</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>out_scale</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>post_rshift</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">q15_t *</td>          <td class="paramname"><span class="paramname"><em>out_tensor</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>out_tensor_dim</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">q15_t *</td>          <td class="paramname"><span class="paramname"><em>in_tmp_buf</em></span>&#160;)</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span><span class="mlabel">static</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p><code>#include &lt;<a class="el" href="hpm__math_8h.html">middleware/hpm_math/hpm_math.h</a>&gt;</code></p>

<p>This function performs depthwise convolution for signed 8-bit integer inputs and signed 16-bit integer outputs with bias inputs and symmetric quantization on the outputs. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor</td><td>pointer of the input tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor_dim</td><td>dimension of the input tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor_ch</td><td>number of input tensor channels </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">ker_weight</td><td>pointer of kernel weights </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_tensor_ch</td><td>number of output tensor channels </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">ker_dim</td><td>dimension of the filter kernel </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">pad</td><td>padding size </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">stride</td><td>convolution stride </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">bias</td><td>pointer of the bias vector </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">pre_rshift</td><td>right shift amount for the output </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_scale</td><td>value of scaling for the output </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">post_rshift</td><td>right shift amount for the output </td></tr>
    <tr><td class="paramdir">[out]</td><td class="paramname">out_tensor</td><td>pointer of the output tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_tensor_dim</td><td>dimension of the output tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tmp_buf</td><td>temporary buffer for the input tensor. It is required when -mext-dsp or -mext-vector is enabled and its size must be equal to "(in_tensor_ch * ker_dim * ker_dim + 1) / 2". </td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>This function returns 0 on success; otherwise, it returns -1 if its inputs do not meet the constraints that in_tensor_ch has to be equal to out_tensor_ch.</dd></dl>
<dl class="section note"><dt>Note</dt><dd>The outputs will be 2-stage shifted before being stored, i.e., out = ((out &gt;&gt; pre_rshift) *out_scale) &gt;&gt; post_rshift. </dd></dl>

</div>
</div>
<a id="ga0a8c643e8c77051213ccf469486ddccb" name="ga0a8c643e8c77051213ccf469486ddccb"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ga0a8c643e8c77051213ccf469486ddccb">&#9670;&#160;</a></span>hpm_nn_conv_dw_HWC_s8_s16_s8_sym_bias_any()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">static int32_t hpm_nn_conv_dw_HWC_s8_s16_s8_sym_bias_any </td>
          <td>(</td>
          <td class="paramtype">const q7_t *</td>          <td class="paramname"><span class="paramname"><em>in_tensor</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>in_tensor_dim_x</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>in_tensor_dim_y</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>in_tensor_ch</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const q7_t *</td>          <td class="paramname"><span class="paramname"><em>ker_weight</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>out_tensor_ch</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>ker_dim_x</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>ker_dim_y</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>pad_x</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>pad_y</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>stride_x</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>stride_y</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const q31_t *</td>          <td class="paramname"><span class="paramname"><em>bias</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>pre_rshift</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>out_scale</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>post_rshift</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">q15_t *</td>          <td class="paramname"><span class="paramname"><em>out_tensor</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>out_tensor_dim_x</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>out_tensor_dim_y</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">q15_t *</td>          <td class="paramname"><span class="paramname"><em>in_tmp_buf</em></span>&#160;)</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span><span class="mlabel">static</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p><code>#include &lt;<a class="el" href="hpm__math_8h.html">middleware/hpm_math/hpm_math.h</a>&gt;</code></p>

<p>This function performs depthwise convolution for signed 8-bit integer inputs and signed 16-bit integer outputs in any x and y dimensions with bias inputs and symmetric quantization on the outputs. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor</td><td>pointer of the input tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor_dim_x</td><td>x dimension of the input tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor_dim_y</td><td>y dimension of the input tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor_ch</td><td>number of input tensor channels </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">ker_weight</td><td>pointer of kernel weights </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_tensor_ch</td><td>number of output tensor channels </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">ker_dim_x</td><td>x dimension of the filter kernel </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">ker_dim_y</td><td>y dimension of the filter kernel </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">pad_x</td><td>padding size in the x dimension </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">pad_y</td><td>padding size in the y dimension </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">stride_x</td><td>convolution stride in the x dimension </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">stride_y</td><td>convolution stride in the y dimension </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">bias</td><td>pointer of the bias vector </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">pre_rshift</td><td>right shift amount for the output </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_scale</td><td>value of scaling for the output </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">post_rshift</td><td>right shift amount for the output </td></tr>
    <tr><td class="paramdir">[out]</td><td class="paramname">out_tensor</td><td>pointer of the output tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_tensor_dim_x</td><td>x dimension of the output tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_tensor_dim_y</td><td>y dimension of the output tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tmp_buf</td><td>temporary buffer for the input tensor. It is required when -mext-dsp or -mext-vector is enabled and its size must be equal to "(in_tensor_ch *
                                     ker_dim_x * ker_dim_y + 1) / 2". </td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>This function returns 0 on success; otherwise, it returns -1 if its inputs do not meet the constraints that in_tensor_ch must be equal to out_tensor_ch.</dd></dl>
<dl class="section note"><dt>Note</dt><dd>The outputs will be 2-stage shifted before being stored, i.e., out = ((out &gt;&gt; pre_rshift) *out_scale) &gt;&gt; post_rshift. </dd></dl>

</div>
</div>
<a id="ga455407b84cfc71528b0dd8680c64a8b3" name="ga455407b84cfc71528b0dd8680c64a8b3"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ga455407b84cfc71528b0dd8680c64a8b3">&#9670;&#160;</a></span>hpm_nn_conv_dw_HWC_s8_s8_s8_asym_bias_any()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">static int32_t hpm_nn_conv_dw_HWC_s8_s8_s8_asym_bias_any </td>
          <td>(</td>
          <td class="paramtype">const q7_t *</td>          <td class="paramname"><span class="paramname"><em>in_tensor</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>in_tensor_dim_x</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>in_tensor_dim_y</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>in_tensor_ch</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const q7_t *</td>          <td class="paramname"><span class="paramname"><em>ker_weight</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>out_tensor_ch</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>ch_mult</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>ker_dim_x</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>ker_dim_y</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>pad_x</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>pad_y</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>stride_x</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>stride_y</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const int32_t *</td>          <td class="paramname"><span class="paramname"><em>bias</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">q7_t *</td>          <td class="paramname"><span class="paramname"><em>out_tensor</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const int32_t *</td>          <td class="paramname"><span class="paramname"><em>out_shift</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const int32_t *</td>          <td class="paramname"><span class="paramname"><em>out_scale</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>out_tensor_dim_x</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>out_tensor_dim_y</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const int32_t</td>          <td class="paramname"><span class="paramname"><em>out_offset</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const int32_t</td>          <td class="paramname"><span class="paramname"><em>in_offset</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const int32_t</td>          <td class="paramname"><span class="paramname"><em>act_min</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const int32_t</td>          <td class="paramname"><span class="paramname"><em>act_max</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>dilation_x</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>dilation_y</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">q15_t *</td>          <td class="paramname"><span class="paramname"><em>tmp_buf</em></span>&#160;)</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span><span class="mlabel">static</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p><code>#include &lt;<a class="el" href="hpm__math_8h.html">middleware/hpm_math/hpm_math.h</a>&gt;</code></p>

<p>This function performs depthwise convolution for signed 8-bit interger inputs/outputs in any x and y dimensions with asymmetric quantization on the outputs. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor</td><td>pointer of the input tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor_dim_x</td><td>x dimension of the input tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor_dim_y</td><td>y dimension of the input tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor_ch</td><td>number of input tensor channels </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">ker_weight</td><td>pointer of kernel weights </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_tensor_ch</td><td>number of output tensor channels. out_tensor_ch is equal to ch_mult * in_tensor_ch. </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">ch_mult</td><td>multiplier of input tensor channels </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">ker_dim_x</td><td>x dimension of the filter kernel </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">ker_dim_y</td><td>y dimension of the filter kernel </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">pad_x</td><td>padding size in the x dimension </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">pad_y</td><td>padding size in the y dimension </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">stride_x</td><td>convolution stride in the x dimension </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">stride_y</td><td>convolution stride in the y dimension </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">bias</td><td>pointer of the bias vector </td></tr>
    <tr><td class="paramdir">[out]</td><td class="paramname">out_tensor</td><td>pointer of the output tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_shift</td><td>pointer of the shift vector for output tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_scale</td><td>pointer of the scaling vector for output tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_tensor_dim_x</td><td>x dimension of the output tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_tensor_dim_y</td><td>y dimension of the output tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_offset</td><td>value of offset for the output tensor. It should be in the range of -128 to 127. </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_offset</td><td>value of offset for the input tensor It should be in the range of -127 to 128. </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">act_min</td><td>minimum value to clip out the ouput tensor. It should be in the range of -128 to 127. </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">act_max</td><td>maximum value to clip out the ouput tensor. It should be in the range of -128 to 127. </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">dilation_x</td><td>dummy </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">dilation_y</td><td>dummy </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">tmp_buf</td><td>dummy </td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>This function only returns 0.</dd></dl>
<p><b>Example:</b> </p><div class="fragment"><div class="line">to be modified...</div>
</div><!-- fragment --> 
</div>
</div>
<a id="gad954df9be69373bdc385362c70b140dc" name="gad954df9be69373bdc385362c70b140dc"></a>
<h2 class="memtitle"><span class="permalink"><a href="#gad954df9be69373bdc385362c70b140dc">&#9670;&#160;</a></span>hpm_nn_conv_dw_HWC_s8_s8_s8_asym_bias_fast_any()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">static int32_t hpm_nn_conv_dw_HWC_s8_s8_s8_asym_bias_fast_any </td>
          <td>(</td>
          <td class="paramtype">const q7_t *</td>          <td class="paramname"><span class="paramname"><em>in_tensor</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>in_tensor_dim_x</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>in_tensor_dim_y</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>in_tensor_ch</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const q7_t *</td>          <td class="paramname"><span class="paramname"><em>ker_weight</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>out_tensor_ch</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>ker_dim_x</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>ker_dim_y</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>pad_x</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>pad_y</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>stride_x</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>stride_y</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const int32_t *</td>          <td class="paramname"><span class="paramname"><em>bias</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">q7_t *</td>          <td class="paramname"><span class="paramname"><em>out_tensor</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const int32_t *</td>          <td class="paramname"><span class="paramname"><em>out_shift</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const int32_t *</td>          <td class="paramname"><span class="paramname"><em>out_scale</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>out_tensor_dim_x</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>out_tensor_dim_y</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const int32_t</td>          <td class="paramname"><span class="paramname"><em>out_offset</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const int32_t</td>          <td class="paramname"><span class="paramname"><em>in_offset</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const int32_t</td>          <td class="paramname"><span class="paramname"><em>act_min</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const int32_t</td>          <td class="paramname"><span class="paramname"><em>act_max</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>dilation_x</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>dilation_y</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">q15_t *</td>          <td class="paramname"><span class="paramname"><em>in_tmp_buf</em></span>&#160;)</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span><span class="mlabel">static</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p><code>#include &lt;<a class="el" href="hpm__math_8h.html">middleware/hpm_math/hpm_math.h</a>&gt;</code></p>

<p>This function performs fast depthwise convolution for signed 8-bit integer inputs/outputs in any x and y dimensions with asymmetric quantization on the outputs. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor</td><td>pointer of the input tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor_dim_x</td><td>x dimension of the input tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor_dim_y</td><td>y dimension of the input tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor_ch</td><td>number of input tensor channels </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">ker_weight</td><td>pointer of kernel weights </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_tensor_ch</td><td>number of output tensor channels </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">ker_dim_x</td><td>x dimension of the filter kernel </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">ker_dim_y</td><td>y dimension of the filter kernel </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">pad_x</td><td>padding size in the x dimension </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">pad_y</td><td>padding size in the y dimension </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">stride_x</td><td>convolution stride in the x dimension </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">stride_y</td><td>convolution stride in the y dimension </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">bias</td><td>pointer of the bias vector </td></tr>
    <tr><td class="paramdir">[out]</td><td class="paramname">out_tensor</td><td>pointer of the output tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_shift</td><td>pointer of the shift vector for output tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_scale</td><td>pointer of the scaling vector for output tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_tensor_dim_x</td><td>x dimension of the output tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_tensor_dim_y</td><td>y dimension of the output tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_offset</td><td>value of offset for the output tensor. It should be in the range of -128 to 127. </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_offset</td><td>value of offset for the input tensor It should be in the range of -127 to 128. </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">act_min</td><td>minimum value to clip out the ouput tensor. It should be in the range of -128 to 127. </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">act_max</td><td>maximum value to clip out the ouput tensor. It should be in the range of -128 to 127. </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">dilation_x</td><td>dummy </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">dilation_y</td><td>dummy </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tmp_buf</td><td>temporary buffer for the input tensor. It is required when -mext-dsp or -mext-vector is enabled and its needed size could be get by calling riscv_nn_conv_dw_HWC_s8_s8_s8_asym_bias_fast_any_get_buffer_size. </td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>This function returns 0 on success; otherwise, it returns -1 if its inputs do not meet the constraint that in_tensor_ch has to be equal to out_tensor_ch. </dd></dl>

</div>
</div>
<a id="gad9339201eff1c27fd41039bfc4a4756c" name="gad9339201eff1c27fd41039bfc4a4756c"></a>
<h2 class="memtitle"><span class="permalink"><a href="#gad9339201eff1c27fd41039bfc4a4756c">&#9670;&#160;</a></span>hpm_nn_conv_dw_HWC_s8_s8_s8_asym_bias_fast_any_get_buffer_size()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">static int32_t hpm_nn_conv_dw_HWC_s8_s8_s8_asym_bias_fast_any_get_buffer_size </td>
          <td>(</td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>in_tensor_ch</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>ker_dim_x</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>ker_dim_y</em></span>&#160;)</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span><span class="mlabel">static</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p><code>#include &lt;<a class="el" href="hpm__math_8h.html">middleware/hpm_math/hpm_math.h</a>&gt;</code></p>

<p>This function is used to get the needed size, in bytes, by the input temporary buffer of riscv_nn_conv_dw_HWC_s8_s8_s8_asym_bias_fast_any. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor_ch</td><td>number of input tensor channels </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">ker_dim_x</td><td>x dimension of the filter kernel </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">ker_dim_y</td><td>y dimension of the filter kernel </td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>This function returns the needed size by the temporary buffer. </dd></dl>

</div>
</div>
<a id="ga14a5303eb12476d8342725b778f3d60f" name="ga14a5303eb12476d8342725b778f3d60f"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ga14a5303eb12476d8342725b778f3d60f">&#9670;&#160;</a></span>hpm_nn_conv_dw_HWC_s8_s8_s8_sft_bias()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">static int32_t hpm_nn_conv_dw_HWC_s8_s8_s8_sft_bias </td>
          <td>(</td>
          <td class="paramtype">const q7_t *</td>          <td class="paramname"><span class="paramname"><em>in_tensor</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>in_tensor_dim</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>in_tensor_ch</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const q7_t *</td>          <td class="paramname"><span class="paramname"><em>ker_weight</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>out_tensor_ch</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>ker_dim</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>pad</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>stride</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const q7_t *</td>          <td class="paramname"><span class="paramname"><em>bias</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>bias_lshift</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>out_rshift</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">q7_t *</td>          <td class="paramname"><span class="paramname"><em>out_tensor</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>out_tensor_dim</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">q15_t *</td>          <td class="paramname"><span class="paramname"><em>in_tmp_buf</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">q7_t *</td>          <td class="paramname"><span class="paramname"><em>tmp_buf</em></span>&#160;)</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span><span class="mlabel">static</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p><code>#include &lt;<a class="el" href="hpm__math_8h.html">middleware/hpm_math/hpm_math.h</a>&gt;</code></p>

<p>This function performs signed 8-bit integer depthwise convolution with shift-based quantization on the outputs. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor</td><td>pointer of the input tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor_dim</td><td>dimension of the input tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor_ch</td><td>number of input tensor channels </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">ker_weight</td><td>pointer of kernel weights </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_tensor_ch</td><td>number of output tensor channels </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">ker_dim</td><td>dimension of the filter kernel </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">pad</td><td>padding size </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">stride</td><td>convolution stride </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">bias</td><td>pointer of the bias vector </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">bias_lshift</td><td>left shift amount for the bias </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_rshift</td><td>right shift amount for the output </td></tr>
    <tr><td class="paramdir">[out]</td><td class="paramname">out_tensor</td><td>pointer of the output tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_tensor_dim</td><td>dimension of the output tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tmp_buf</td><td>temporary buffer for the input tensor. It is required when -mext-dsp or -mext-vector is enabled and its size must be equal to "(in_tensor_ch * ker_dim * ker_dim + 1) / 2". </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">tmp_buf</td><td>dummy </td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>This function returns 0 on success; otherwise, it returns -1 if its inputs do not meet the constraints that in_tensor_ch has to be equal to out_tensor_ch.</dd></dl>
<p><b>Example:</b> </p><div class="fragment"><div class="line"><span class="comment">//Convolve a 11x11x28 input tensor with a 3x3 kernel and generate a 9x9x48</span></div>
<div class="line"><span class="comment">//output tensor. Let both dimensions padding be 0 and their stride be 1.</span></div>
<div class="line"> </div>
<div class="line"><span class="preprocessor">#define IN_DIM 11</span></div>
<div class="line"><span class="preprocessor">#define IN_CH 28</span></div>
<div class="line"><span class="preprocessor">#define OUT_CH 48</span></div>
<div class="line"><span class="preprocessor">#define KER_DIM 3</span></div>
<div class="line"><span class="preprocessor">#define PAD 0</span></div>
<div class="line"><span class="preprocessor">#define STRIDE 1</span></div>
<div class="line"><span class="preprocessor">#define OUT_RSHIFT 7</span></div>
<div class="line"><span class="preprocessor">#define OUT_DIM 9</span></div>
<div class="line"> </div>
<div class="line">q7_t in_data[IN_CH * IN_DIM * IN_DIM] = {...};</div>
<div class="line">q7_t weight[IN_CH * KER_DIM * KER_DIM * IN_CH] = {...};</div>
<div class="line">q7_t <a class="code hl_variable" href="group__nnfullyconnect.html#ga602e28fc157c370e73e4df5712f9df84">bias</a>[IN_CH] = {...};</div>
<div class="line">q15_t <a class="code hl_variable" href="group__nnfullyconnect.html#ga4972f5e62722e743bc2e14d86e130148">in_tmp_buf</a>[2 * OUT_CH * KER_DIM * KER_DIM] = {0};</div>
<div class="line">q7_t out_data[OUT_CH * OUT_DIM * OUT_DIM];</div>
<div class="line"> </div>
<div class="line">riscv_nn_conv_dw_HWC_s8_s8_s8_sft_bias(in_data, IN_DIM, IN_CH, weight,</div>
<div class="line">    OUT_CH, KER_DIM, PAD, STRIDE, <a class="code hl_variable" href="group__nnfullyconnect.html#ga602e28fc157c370e73e4df5712f9df84">bias</a>, 0, OUT_RSHIFT, out_data, OUT_DIM,</div>
<div class="line">    <a class="code hl_variable" href="group__nnfullyconnect.html#ga4972f5e62722e743bc2e14d86e130148">in_tmp_buf</a>, NULL);</div>
</div><!-- fragment --> 
</div>
</div>
<a id="gacbd18e7251df9494ddf4619156237efd" name="gacbd18e7251df9494ddf4619156237efd"></a>
<h2 class="memtitle"><span class="permalink"><a href="#gacbd18e7251df9494ddf4619156237efd">&#9670;&#160;</a></span>hpm_nn_conv_dw_HWC_s8_s8_s8_sft_bias_any()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">static int32_t hpm_nn_conv_dw_HWC_s8_s8_s8_sft_bias_any </td>
          <td>(</td>
          <td class="paramtype">const q7_t *</td>          <td class="paramname"><span class="paramname"><em>in_tensor</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>in_tensor_dim_x</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>in_tensor_dim_y</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>in_tensor_ch</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const q7_t *</td>          <td class="paramname"><span class="paramname"><em>ker_weight</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>out_tensor_ch</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>ker_dim_x</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>ker_dim_y</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>pad_x</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>pad_y</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>stride_x</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>stride_y</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const q7_t *</td>          <td class="paramname"><span class="paramname"><em>bias</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>bias_lshift</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>out_rshift</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">q7_t *</td>          <td class="paramname"><span class="paramname"><em>out_tensor</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>out_tensor_dim_x</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>out_tensor_dim_y</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">q15_t *</td>          <td class="paramname"><span class="paramname"><em>in_tmp_buf</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">q7_t *</td>          <td class="paramname"><span class="paramname"><em>tmp_buf</em></span>&#160;)</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span><span class="mlabel">static</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p><code>#include &lt;<a class="el" href="hpm__math_8h.html">middleware/hpm_math/hpm_math.h</a>&gt;</code></p>

<p>This function performs signed 8-bit integer depthwise convolution in any x and y dimensions with shift-based quantization on the outputs. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor</td><td>pointer of the input tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor_dim_x</td><td>x dimension of the input tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor_dim_y</td><td>y dimension of the input tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor_ch</td><td>number of input tensor channels </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">ker_weight</td><td>pointer of kernel weights </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_tensor_ch</td><td>number of output tensor channels </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">ker_dim_x</td><td>x dimension of the filter kernel </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">ker_dim_y</td><td>y dimension of the filter kernel </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">pad_x</td><td>padding size in the x dimension </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">pad_y</td><td>padding size in the y dimension </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">stride_x</td><td>convolution stride in the x dimension </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">stride_y</td><td>convolution stride in the y dimension </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">bias</td><td>pointer of the bias vector </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">bias_lshift</td><td>left shift amount for the bias </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_rshift</td><td>right shift amount for the output </td></tr>
    <tr><td class="paramdir">[out]</td><td class="paramname">out_tensor</td><td>pointer of the output tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_tensor_dim_x</td><td>x dimension of the output tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_tensor_dim_y</td><td>y dimension of the output tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tmp_buf</td><td>temporary buffer for the input tensor. It is required when -mext-dsp or -mext-vector is enabled and its size must be equal to "(in_tensor_ch *
                                     ker_dim_x * ker_dim_y + 1) / 2". </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">tmp_buf</td><td>dummy </td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>This function returns 0 on success; otherwise, it returns -1 if its inputs do not meet the constraints that in_tensor_ch must be equal to out_tensor_ch.</dd></dl>
<p><b>Example:</b> </p><div class="fragment"><div class="line"><span class="comment">//Perform a depth-wise convolution for a 79x59x12 input tensor with a 3x3</span></div>
<div class="line"><span class="comment">//kernel and generate a 77x57x12 output tensor. Let both dimensions padding</span></div>
<div class="line"><span class="comment">//be 0 and their stride be 1.</span></div>
<div class="line"> </div>
<div class="line"><span class="preprocessor">#define IN_DIM_X 79</span></div>
<div class="line"><span class="preprocessor">#define IN_DIM_Y 59</span></div>
<div class="line"><span class="preprocessor">#define IN_CH 12</span></div>
<div class="line"><span class="preprocessor">#define OUT_CH 12</span></div>
<div class="line"><span class="preprocessor">#define KER_DIM 3</span></div>
<div class="line"><span class="preprocessor">#define PAD 0</span></div>
<div class="line"><span class="preprocessor">#define STRIDE 1</span></div>
<div class="line"><span class="preprocessor">#define BIAS_SHIFT 0</span></div>
<div class="line"><span class="preprocessor">#define OUT_RSHIFT 7</span></div>
<div class="line"><span class="preprocessor">#define OUT_DIM_X 77</span></div>
<div class="line"><span class="preprocessor">#define OUT_DIM_Y 57</span></div>
<div class="line"> </div>
<div class="line">q7_t in_data[IN_CH * IN_DIM_X * IN_DIM_Y] = {...};</div>
<div class="line">q7_t weight[IN_CH * KER_DIM * KER_DIM * IN_CH] = {...};</div>
<div class="line">q7_t <a class="code hl_variable" href="group__nnfullyconnect.html#ga602e28fc157c370e73e4df5712f9df84">bias</a>[IN_CH] = {...};</div>
<div class="line">q15_t <a class="code hl_variable" href="group__nnfullyconnect.html#ga4972f5e62722e743bc2e14d86e130148">in_tmp_buf</a>[2 * OUT_CH * KER_DIM * KER_DIM] = {0};</div>
<div class="line">q7_t out_data[OUT_CH * OUT_DIM_X * OUT_DIM_Y];</div>
<div class="line"> </div>
<div class="line">riscv_nn_conv_dw_HWC_s8_s8_s8_sft_bias_any(in_data, IN_DIM_X, IN_DIM_Y,</div>
<div class="line">    IN_CH, weight, OUT_CH, KER_DIM, KER_DIM, PAD, PAD, STRIDE, STRIDE, <a class="code hl_variable" href="group__nnfullyconnect.html#ga602e28fc157c370e73e4df5712f9df84">bias</a>,</div>
<div class="line">    BIAS_SHIFT, OUT_RSHIFT, out_data, OUT_DIM_X, OUT_DIM_Y, <a class="code hl_variable" href="group__nnfullyconnect.html#ga4972f5e62722e743bc2e14d86e130148">in_tmp_buf</a>,</div>
<div class="line">    NULL);</div>
</div><!-- fragment --> 
</div>
</div>
<a id="gaddf5ec832e3e3306da2089d5bb742aee" name="gaddf5ec832e3e3306da2089d5bb742aee"></a>
<h2 class="memtitle"><span class="permalink"><a href="#gaddf5ec832e3e3306da2089d5bb742aee">&#9670;&#160;</a></span>hpm_nn_conv_dw_HWC_s8_s8_s8_sym()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">static int32_t hpm_nn_conv_dw_HWC_s8_s8_s8_sym </td>
          <td>(</td>
          <td class="paramtype">const q7_t *</td>          <td class="paramname"><span class="paramname"><em>in_tensor</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>in_tensor_dim</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>in_tensor_ch</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const q7_t *</td>          <td class="paramname"><span class="paramname"><em>ker_weight</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>out_tensor_ch</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>ker_dim</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>pad</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>stride</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>pre_rshift</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>out_scale</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>post_rshift</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">q7_t *</td>          <td class="paramname"><span class="paramname"><em>out_tensor</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>out_tensor_dim</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">q15_t *</td>          <td class="paramname"><span class="paramname"><em>in_tmp_buf</em></span>&#160;)</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span><span class="mlabel">static</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p><code>#include &lt;<a class="el" href="hpm__math_8h.html">middleware/hpm_math/hpm_math.h</a>&gt;</code></p>

<p>This function performs depthwise convolution for signed 8-bit integer inputs/outputs with symmetric quantization on the outputs. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor</td><td>pointer of the input tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor_dim</td><td>dimension of the input tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor_ch</td><td>number of input tensor channels </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">ker_weight</td><td>pointer of kernel weights </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_tensor_ch</td><td>number of output tensor channels </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">ker_dim</td><td>dimension of the filter kernel </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">pad</td><td>padding size </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">stride</td><td>convolution stride </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">pre_rshift</td><td>right shift amount for the output </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_scale</td><td>value of scaling for the output </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">post_rshift</td><td>right shift amount for the output </td></tr>
    <tr><td class="paramdir">[out]</td><td class="paramname">out_tensor</td><td>pointer of the output tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_tensor_dim</td><td>dimension of the output tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tmp_buf</td><td>temporary buffer for the input tensor. It is required when -mext-dsp or -mext-vector is enabled and its size must be equal to "(in_tensor_ch * ker_dim * ker_dim + 1) / 2". </td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>This function returns 0 on success; otherwise, it returns -1 if its inputs do not meet the constraints that in_tensor_ch has to be equal to out_tensor_ch.</dd></dl>
<dl class="section note"><dt>Note</dt><dd>The outputs will be 2-stage shifted before being stored, i.e., out = ((out &gt;&gt; pre_rshift) *out_scale) &gt;&gt; post_rshift. </dd></dl>

</div>
</div>
<a id="gae8250ca3c328de6b4ea93e4f62bcf541" name="gae8250ca3c328de6b4ea93e4f62bcf541"></a>
<h2 class="memtitle"><span class="permalink"><a href="#gae8250ca3c328de6b4ea93e4f62bcf541">&#9670;&#160;</a></span>hpm_nn_conv_dw_HWC_s8_s8_s8_sym_any()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">static int32_t hpm_nn_conv_dw_HWC_s8_s8_s8_sym_any </td>
          <td>(</td>
          <td class="paramtype">const q7_t *</td>          <td class="paramname"><span class="paramname"><em>in_tensor</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>in_tensor_dim_x</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>in_tensor_dim_y</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>in_tensor_ch</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const q7_t *</td>          <td class="paramname"><span class="paramname"><em>ker_weight</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>out_tensor_ch</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>ker_dim_x</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>ker_dim_y</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>pad_x</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>pad_y</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>stride_x</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>stride_y</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>pre_rshift</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>out_scale</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>post_rshift</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">q7_t *</td>          <td class="paramname"><span class="paramname"><em>out_tensor</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>out_tensor_dim_x</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>out_tensor_dim_y</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">q15_t *</td>          <td class="paramname"><span class="paramname"><em>in_tmp_buf</em></span>&#160;)</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span><span class="mlabel">static</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p><code>#include &lt;<a class="el" href="hpm__math_8h.html">middleware/hpm_math/hpm_math.h</a>&gt;</code></p>

<p>This function performs depthwise convolution for signed 8-bit integer inputs/outputs in any x and y dimensions with bias inputs and symmetric quantization on the outputs. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor</td><td>pointer of the input tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor_dim_x</td><td>x dimension of the input tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor_dim_y</td><td>y dimension of the input tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor_ch</td><td>number of input tensor channels </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">ker_weight</td><td>pointer of kernel weights </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_tensor_ch</td><td>number of output tensor channels </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">ker_dim_x</td><td>x dimension of the filter kernel </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">ker_dim_y</td><td>y dimension of the filter kernel </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">pad_x</td><td>padding size in the x dimension </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">pad_y</td><td>padding size in the y dimension </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">stride_x</td><td>convolution stride in the x dimension </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">stride_y</td><td>convolution stride in the y dimension </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">pre_rshift</td><td>right shift amount for the output </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_scale</td><td>value of scaling for the output </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">post_rshift</td><td>right shift amount for the output </td></tr>
    <tr><td class="paramdir">[out]</td><td class="paramname">out_tensor</td><td>pointer of the output tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_tensor_dim_x</td><td>x dimension of the output tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_tensor_dim_y</td><td>y dimension of the output tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tmp_buf</td><td>temporary buffer for the input tensor. It is required when -mext-dsp or -mext-vector is enabled and its size must be equal to "(in_tensor_ch *
                                     ker_dim_x * ker_dim_y + 1) / 2". </td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>This function returns 0 on success; otherwise, it returns -1 if its inputs do not meet the constraints that in_tensor_ch must be equal to out_tensor_ch.</dd></dl>
<dl class="section note"><dt>Note</dt><dd>The outputs will be 2-stage shifted before being stored, i.e., out = ((out &gt;&gt; pre_rshift) *out_scale) &gt;&gt; post_rshift. </dd></dl>

</div>
</div>
<a id="gaa2232c5f84cbe4d40d4201756d87c308" name="gaa2232c5f84cbe4d40d4201756d87c308"></a>
<h2 class="memtitle"><span class="permalink"><a href="#gaa2232c5f84cbe4d40d4201756d87c308">&#9670;&#160;</a></span>hpm_nn_conv_dw_HWC_s8_s8_s8_sym_bias()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">static int32_t hpm_nn_conv_dw_HWC_s8_s8_s8_sym_bias </td>
          <td>(</td>
          <td class="paramtype">const q7_t *</td>          <td class="paramname"><span class="paramname"><em>in_tensor</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>in_tensor_dim</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>in_tensor_ch</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const q7_t *</td>          <td class="paramname"><span class="paramname"><em>ker_weight</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>out_tensor_ch</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>ker_dim</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>pad</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>stride</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const q31_t *</td>          <td class="paramname"><span class="paramname"><em>bias</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>pre_rshift</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>out_scale</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>post_rshift</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">q7_t *</td>          <td class="paramname"><span class="paramname"><em>out_tensor</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>out_tensor_dim</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">q15_t *</td>          <td class="paramname"><span class="paramname"><em>in_tmp_buf</em></span>&#160;)</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span><span class="mlabel">static</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p><code>#include &lt;<a class="el" href="hpm__math_8h.html">middleware/hpm_math/hpm_math.h</a>&gt;</code></p>

<p>This function performs depthwise convolution for signed 8-bit integer inputs/outputs with bias inputs and symmetric quantization on the outputs. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor</td><td>pointer of the input tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor_dim</td><td>dimension of the input tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor_ch</td><td>number of input tensor channels </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">ker_weight</td><td>pointer of kernel weights </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_tensor_ch</td><td>number of output tensor channels </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">ker_dim</td><td>dimension of the filter kernel </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">pad</td><td>padding size </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">stride</td><td>convolution stride </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">bias</td><td>pointer of the bias vector </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">pre_rshift</td><td>right shift amount for the output </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_scale</td><td>value of scaling for the output </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">post_rshift</td><td>right shift amount for the output </td></tr>
    <tr><td class="paramdir">[out]</td><td class="paramname">out_tensor</td><td>pointer of the output tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_tensor_dim</td><td>dimension of the output tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tmp_buf</td><td>temporary buffer for the input tensor. It is required when -mext-dsp or -mext-vector is enabled and its size must be equal to "(in_tensor_ch * ker_dim * ker_dim + 1) / 2". </td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>This function returns 0 on success; otherwise, it returns -1 if its inputs do not meet the constraints that in_tensor_ch has to be equal to out_tensor_ch.</dd></dl>
<dl class="section note"><dt>Note</dt><dd>The outputs will be 2-stage shifted before being stored, i.e., out = ((out &gt;&gt; pre_rshift) *out_scale) &gt;&gt; post_rshift. </dd></dl>

</div>
</div>
<a id="ga425531141b804498f1b04ab9203c35c3" name="ga425531141b804498f1b04ab9203c35c3"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ga425531141b804498f1b04ab9203c35c3">&#9670;&#160;</a></span>hpm_nn_conv_dw_HWC_s8_s8_s8_sym_bias_any()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">static int32_t hpm_nn_conv_dw_HWC_s8_s8_s8_sym_bias_any </td>
          <td>(</td>
          <td class="paramtype">const q7_t *</td>          <td class="paramname"><span class="paramname"><em>in_tensor</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>in_tensor_dim_x</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>in_tensor_dim_y</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>in_tensor_ch</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const q7_t *</td>          <td class="paramname"><span class="paramname"><em>ker_weight</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>out_tensor_ch</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>ker_dim_x</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>ker_dim_y</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>pad_x</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>pad_y</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>stride_x</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>stride_y</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const q31_t *</td>          <td class="paramname"><span class="paramname"><em>bias</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>pre_rshift</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>out_scale</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>post_rshift</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">q7_t *</td>          <td class="paramname"><span class="paramname"><em>out_tensor</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>out_tensor_dim_x</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>out_tensor_dim_y</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">q15_t *</td>          <td class="paramname"><span class="paramname"><em>in_tmp_buf</em></span>&#160;)</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span><span class="mlabel">static</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p><code>#include &lt;<a class="el" href="hpm__math_8h.html">middleware/hpm_math/hpm_math.h</a>&gt;</code></p>

<p>This function performs depthwise convolution for signed 8-bit integer inputs/outputs in any x and y dimensions with bias inputs and symmetric quantization on the outputs. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor</td><td>pointer of the input tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor_dim_x</td><td>x dimension of the input tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor_dim_y</td><td>y dimension of the input tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor_ch</td><td>number of input tensor channels </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">ker_weight</td><td>pointer of kernel weights </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_tensor_ch</td><td>number of output tensor channels </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">ker_dim_x</td><td>x dimension of the filter kernel </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">ker_dim_y</td><td>y dimension of the filter kernel </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">pad_x</td><td>padding size in the x dimension </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">pad_y</td><td>padding size in the y dimension </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">stride_x</td><td>convolution stride in the x dimension </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">stride_y</td><td>convolution stride in the y dimension </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">bias</td><td>pointer of the bias vector </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">pre_rshift</td><td>right shift amount for the output </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_scale</td><td>value of scaling for the output </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">post_rshift</td><td>right shift amount for the output </td></tr>
    <tr><td class="paramdir">[out]</td><td class="paramname">out_tensor</td><td>pointer of the output tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_tensor_dim_x</td><td>x dimension of the output tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_tensor_dim_y</td><td>y dimension of the output tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tmp_buf</td><td>temporary buffer for the input tensor. It is required when -mext-dsp or -mext-vector is enabled and its size must be equal to "(in_tensor_ch *
                                     ker_dim_x * ker_dim_y + 1) / 2". </td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>This function returns 0 on success; otherwise, it returns -1 if its inputs do not meet the constraints that in_tensor_ch must be equal to out_tensor_ch.</dd></dl>
<dl class="section note"><dt>Note</dt><dd>The outputs will be 2-stage shifted before being stored, i.e., out = ((out &gt;&gt; pre_rshift) *out_scale) &gt;&gt; post_rshift. </dd></dl>

</div>
</div>
<a id="ga19633dab07a1ccb79712b58dbf7e9a51" name="ga19633dab07a1ccb79712b58dbf7e9a51"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ga19633dab07a1ccb79712b58dbf7e9a51">&#9670;&#160;</a></span>hpm_nn_conv_dw_HWC_u8_s16_s8_sym()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">static int32_t hpm_nn_conv_dw_HWC_u8_s16_s8_sym </td>
          <td>(</td>
          <td class="paramtype">const u8_t *</td>          <td class="paramname"><span class="paramname"><em>in_tensor</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>in_tensor_dim</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>in_tensor_ch</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const q7_t *</td>          <td class="paramname"><span class="paramname"><em>ker_weight</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>out_tensor_ch</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>ker_dim</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>pad</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>stride</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>pre_rshift</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>out_scale</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>post_rshift</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">q15_t *</td>          <td class="paramname"><span class="paramname"><em>out_tensor</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>out_tensor_dim</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">q15_t *</td>          <td class="paramname"><span class="paramname"><em>in_tmp_buf</em></span>&#160;)</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span><span class="mlabel">static</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p><code>#include &lt;<a class="el" href="hpm__math_8h.html">middleware/hpm_math/hpm_math.h</a>&gt;</code></p>

<p>This function performs depthwise convolution for unsigned 8-bit integer inputs and signed 16-bit integer outputs with symmetric quantization on the outputs. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor</td><td>pointer of the input tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor_dim</td><td>dimension of the input tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor_ch</td><td>number of input tensor channels </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">ker_weight</td><td>pointer of kernel weights </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_tensor_ch</td><td>number of output tensor channels </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">ker_dim</td><td>dimension of the filter kernel </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">pad</td><td>padding size </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">stride</td><td>convolution stride </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">pre_rshift</td><td>right shift amount for the output </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_scale</td><td>value of scaling for the output </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">post_rshift</td><td>right shift amount for the output </td></tr>
    <tr><td class="paramdir">[out]</td><td class="paramname">out_tensor</td><td>pointer of the output tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_tensor_dim</td><td>dimension of the output tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tmp_buf</td><td>temporary buffer for the input tensor. It is required when -mext-dsp or -mext-vector is enabled and its size must be equal to "(in_tensor_ch * ker_dim * ker_dim + 1) / 2". </td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>This function returns 0 on success; otherwise, it returns -1 if its inputs do not meet the constraints that in_tensor_ch has to be equal to out_tensor_ch.</dd></dl>
<dl class="section note"><dt>Note</dt><dd>The outputs will be 2-stage shifted before being stored, i.e., out = ((out &gt;&gt; pre_rshift) *out_scale) &gt;&gt; post_rshift. </dd></dl>

</div>
</div>
<a id="gae9744bde30c4e26b17ef6dc89acb16d7" name="gae9744bde30c4e26b17ef6dc89acb16d7"></a>
<h2 class="memtitle"><span class="permalink"><a href="#gae9744bde30c4e26b17ef6dc89acb16d7">&#9670;&#160;</a></span>hpm_nn_conv_dw_HWC_u8_s16_s8_sym_any()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">static int32_t hpm_nn_conv_dw_HWC_u8_s16_s8_sym_any </td>
          <td>(</td>
          <td class="paramtype">const u8_t *</td>          <td class="paramname"><span class="paramname"><em>in_tensor</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>in_tensor_dim_x</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>in_tensor_dim_y</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>in_tensor_ch</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const q7_t *</td>          <td class="paramname"><span class="paramname"><em>ker_weight</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>out_tensor_ch</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>ker_dim_x</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>ker_dim_y</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>pad_x</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>pad_y</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>stride_x</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>stride_y</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>pre_rshift</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>out_scale</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>post_rshift</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">q15_t *</td>          <td class="paramname"><span class="paramname"><em>out_tensor</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>out_tensor_dim_x</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>out_tensor_dim_y</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">q15_t *</td>          <td class="paramname"><span class="paramname"><em>in_tmp_buf</em></span>&#160;)</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span><span class="mlabel">static</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p><code>#include &lt;<a class="el" href="hpm__math_8h.html">middleware/hpm_math/hpm_math.h</a>&gt;</code></p>

<p>This function performs depthwise convolution for unsigned 8-bit integer inputs and signed 16-bit integer outputs in any x and y dimensions with symmetric quantization on the outputs. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor</td><td>pointer of the input tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor_dim_x</td><td>x dimension of the input tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor_dim_y</td><td>y dimension of the input tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor_ch</td><td>number of input tensor channels </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">ker_weight</td><td>pointer of kernel weights </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_tensor_ch</td><td>number of output tensor channels </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">ker_dim_x</td><td>x dimension of the filter kernel </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">ker_dim_y</td><td>y dimension of the filter kernel </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">pad_x</td><td>padding size in the x dimension </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">pad_y</td><td>padding size in the y dimension </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">stride_x</td><td>convolution stride in the x dimension </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">stride_y</td><td>convolution stride in the y dimension </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">pre_rshift</td><td>right shift amount for the output </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_scale</td><td>value of scaling for the output </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">post_rshift</td><td>right shift amount for the output </td></tr>
    <tr><td class="paramdir">[out]</td><td class="paramname">out_tensor</td><td>pointer of the output tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_tensor_dim_x</td><td>x dimension of the output tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_tensor_dim_y</td><td>y dimension of the output tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tmp_buf</td><td>temporary buffer for the input tensor. It is required when -mext-dsp or -mext-vector is enabled and its size must be equal to "(in_tensor_ch *
                                     ker_dim_x * ker_dim_y + 1) / 2". </td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>This function returns 0 on success; otherwise, it returns -1 if its inputs do not meet the constraints that in_tensor_ch must be equal to out_tensor_ch.</dd></dl>
<dl class="section note"><dt>Note</dt><dd>The outputs will be 2-stage shifted before being stored, i.e., out = ((out &gt;&gt; pre_rshift) *out_scale) &gt;&gt; post_rshift. </dd></dl>

</div>
</div>
<a id="gae3cdb24a3bc9374cc98a97d1cf66d713" name="gae3cdb24a3bc9374cc98a97d1cf66d713"></a>
<h2 class="memtitle"><span class="permalink"><a href="#gae3cdb24a3bc9374cc98a97d1cf66d713">&#9670;&#160;</a></span>hpm_nn_conv_dw_HWC_u8_s16_s8_sym_bias()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">static int32_t hpm_nn_conv_dw_HWC_u8_s16_s8_sym_bias </td>
          <td>(</td>
          <td class="paramtype">const u8_t *</td>          <td class="paramname"><span class="paramname"><em>in_tensor</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>in_tensor_dim</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>in_tensor_ch</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const q7_t *</td>          <td class="paramname"><span class="paramname"><em>ker_weight</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>out_tensor_ch</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>ker_dim</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>pad</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>stride</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const q31_t *</td>          <td class="paramname"><span class="paramname"><em>bias</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>pre_rshift</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>out_scale</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>post_rshift</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">q15_t *</td>          <td class="paramname"><span class="paramname"><em>out_tensor</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>out_tensor_dim</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">q15_t *</td>          <td class="paramname"><span class="paramname"><em>in_tmp_buf</em></span>&#160;)</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span><span class="mlabel">static</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p><code>#include &lt;<a class="el" href="hpm__math_8h.html">middleware/hpm_math/hpm_math.h</a>&gt;</code></p>

<p>This function performs depthwise convolution for unsigned 8-bit integer inputs and signed 16-bit integer outputs with bias inputs and symmetric quantization on the outputs. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor</td><td>pointer of the input tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor_dim</td><td>dimension of the input tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor_ch</td><td>number of input tensor channels </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">ker_weight</td><td>pointer of kernel weights </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_tensor_ch</td><td>number of output tensor channels </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">ker_dim</td><td>dimension of the filter kernel </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">pad</td><td>padding size </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">stride</td><td>convolution stride </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">bias</td><td>pointer of the bias vector </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">pre_rshift</td><td>right shift amount for the output </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_scale</td><td>value of scaling for the output </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">post_rshift</td><td>right shift amount for the output </td></tr>
    <tr><td class="paramdir">[out]</td><td class="paramname">out_tensor</td><td>pointer of the output tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_tensor_dim</td><td>dimension of the output tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tmp_buf</td><td>temporary buffer for the input tensor. It is required when -mext-dsp or -mext-vector is enabled and its size must be equal to "(in_tensor_ch * ker_dim * ker_dim + 1) / 2". </td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>This function returns 0 on success; otherwise, it returns -1 if its inputs do not meet the constraints that in_tensor_ch has to be equal to out_tensor_ch.</dd></dl>
<dl class="section note"><dt>Note</dt><dd>The outputs will be 2-stage shifted before being stored, i.e., out = ((out &gt;&gt; pre_rshift) *out_scale) &gt;&gt; post_rshift. </dd></dl>

</div>
</div>
<a id="ga24277b452593c20ae17ff2086fb8253a" name="ga24277b452593c20ae17ff2086fb8253a"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ga24277b452593c20ae17ff2086fb8253a">&#9670;&#160;</a></span>hpm_nn_conv_dw_HWC_u8_s16_s8_sym_bias_any()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">static int32_t hpm_nn_conv_dw_HWC_u8_s16_s8_sym_bias_any </td>
          <td>(</td>
          <td class="paramtype">const u8_t *</td>          <td class="paramname"><span class="paramname"><em>in_tensor</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>in_tensor_dim_x</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>in_tensor_dim_y</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>in_tensor_ch</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const q7_t *</td>          <td class="paramname"><span class="paramname"><em>ker_weight</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>out_tensor_ch</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>ker_dim_x</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>ker_dim_y</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>pad_x</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>pad_y</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>stride_x</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>stride_y</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const q31_t *</td>          <td class="paramname"><span class="paramname"><em>bias</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>pre_rshift</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>out_scale</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>post_rshift</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">q15_t *</td>          <td class="paramname"><span class="paramname"><em>out_tensor</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>out_tensor_dim_x</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>out_tensor_dim_y</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">q15_t *</td>          <td class="paramname"><span class="paramname"><em>in_tmp_buf</em></span>&#160;)</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span><span class="mlabel">static</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p><code>#include &lt;<a class="el" href="hpm__math_8h.html">middleware/hpm_math/hpm_math.h</a>&gt;</code></p>

<p>This function performs depthwise convolution for unsigned 8-bit integer inputs and signed 16-bit integer outputs in any x and y dimensions with bias inputs and symmetric quantization on the outputs. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor</td><td>pointer of the input tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor_dim_x</td><td>x dimension of the input tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor_dim_y</td><td>y dimension of the input tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor_ch</td><td>number of input tensor channels </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">ker_weight</td><td>pointer of kernel weights </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_tensor_ch</td><td>number of output tensor channels </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">ker_dim_x</td><td>x dimension of the filter kernel </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">ker_dim_y</td><td>y dimension of the filter kernel </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">pad_x</td><td>padding size in the x dimension </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">pad_y</td><td>padding size in the y dimension </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">stride_x</td><td>convolution stride in the x dimension </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">stride_y</td><td>convolution stride in the y dimension </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">bias</td><td>pointer of the bias vector </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">pre_rshift</td><td>right shift amount for the output </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_scale</td><td>value of scaling for the output </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">post_rshift</td><td>right shift amount for the output </td></tr>
    <tr><td class="paramdir">[out]</td><td class="paramname">out_tensor</td><td>pointer of the output tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_tensor_dim_x</td><td>x dimension of the output tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_tensor_dim_y</td><td>y dimension of the output tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tmp_buf</td><td>temporary buffer for the input tensor. It is required when -mext-dsp or -mext-vector is enabled and its size must be equal to "(in_tensor_ch *
                                     ker_dim_x * ker_dim_y + 1) / 2". </td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>This function returns 0 on success; otherwise, it returns -1 if its inputs do not meet the constraints that in_tensor_ch must be equal to out_tensor_ch.</dd></dl>
<dl class="section note"><dt>Note</dt><dd>The outputs will be 2-stage shifted before being stored, i.e., out = ((out &gt;&gt; pre_rshift) *out_scale) &gt;&gt; post_rshift. </dd></dl>

</div>
</div>
<a id="ga8021fde290f091b9348e56ae24fdf912" name="ga8021fde290f091b9348e56ae24fdf912"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ga8021fde290f091b9348e56ae24fdf912">&#9670;&#160;</a></span>hpm_nn_conv_dw_HWC_u8_s8_s8_sym()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">static int32_t hpm_nn_conv_dw_HWC_u8_s8_s8_sym </td>
          <td>(</td>
          <td class="paramtype">const u8_t *</td>          <td class="paramname"><span class="paramname"><em>in_tensor</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>in_tensor_dim</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>in_tensor_ch</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const q7_t *</td>          <td class="paramname"><span class="paramname"><em>ker_weight</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>out_tensor_ch</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>ker_dim</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>pad</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>stride</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>pre_rshift</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>out_scale</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>post_rshift</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">q7_t *</td>          <td class="paramname"><span class="paramname"><em>out_tensor</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>out_tensor_dim</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">q15_t *</td>          <td class="paramname"><span class="paramname"><em>in_tmp_buf</em></span>&#160;)</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span><span class="mlabel">static</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p><code>#include &lt;<a class="el" href="hpm__math_8h.html">middleware/hpm_math/hpm_math.h</a>&gt;</code></p>

<p>This function performs depthwise convolution for unsigned 8-bit integer inputs and signed 8-bit integer outputs, and with symmetric quantization on the outputs. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor</td><td>pointer of the input tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor_dim</td><td>dimension of the input tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor_ch</td><td>number of input tensor channels </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">ker_weight</td><td>pointer of kernel weights </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_tensor_ch</td><td>number of output tensor channels </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">ker_dim</td><td>dimension of the filter kernel </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">pad</td><td>padding size </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">stride</td><td>convolution stride </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">pre_rshift</td><td>right shift amount for the output </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_scale</td><td>value of scaling for the output </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">post_rshift</td><td>right shift amount for the output </td></tr>
    <tr><td class="paramdir">[out]</td><td class="paramname">out_tensor</td><td>pointer of the output tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_tensor_dim</td><td>dimension of the output tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tmp_buf</td><td>temporary buffer for the input tensor. It is required when -mext-dsp or -mext-vector is enabled and its size must be equal to "(in_tensor_ch * ker_dim * ker_dim + 1) / 2". </td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>This function returns 0 on success; otherwise, it returns -1 if its inputs do not meet the constraints that in_tensor_ch has to be equal to out_tensor_ch.</dd></dl>
<dl class="section note"><dt>Note</dt><dd>The outputs will be 2-stage shifted before being stored, i.e., out = ((out &gt;&gt; pre_rshift) *out_scale) &gt;&gt; post_rshift. </dd></dl>

</div>
</div>
<a id="gac080214be9e1938ba324ca42c0aade2c" name="gac080214be9e1938ba324ca42c0aade2c"></a>
<h2 class="memtitle"><span class="permalink"><a href="#gac080214be9e1938ba324ca42c0aade2c">&#9670;&#160;</a></span>hpm_nn_conv_dw_HWC_u8_s8_s8_sym_any()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">static int32_t hpm_nn_conv_dw_HWC_u8_s8_s8_sym_any </td>
          <td>(</td>
          <td class="paramtype">const u8_t *</td>          <td class="paramname"><span class="paramname"><em>in_tensor</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>in_tensor_dim_x</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>in_tensor_dim_y</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>in_tensor_ch</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const q7_t *</td>          <td class="paramname"><span class="paramname"><em>ker_weight</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>out_tensor_ch</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>ker_dim_x</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>ker_dim_y</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>pad_x</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>pad_y</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>stride_x</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>stride_y</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>pre_rshift</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>out_scale</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>post_rshift</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">q7_t *</td>          <td class="paramname"><span class="paramname"><em>out_tensor</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>out_tensor_dim_x</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>out_tensor_dim_y</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">q15_t *</td>          <td class="paramname"><span class="paramname"><em>in_tmp_buf</em></span>&#160;)</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span><span class="mlabel">static</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p><code>#include &lt;<a class="el" href="hpm__math_8h.html">middleware/hpm_math/hpm_math.h</a>&gt;</code></p>

<p>This function performs depthwise convolution for unsigned 8-bit integer inputs and signed 8-bit integer outputs in any x and y dimensions with symmetric quantization on the outputs. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor</td><td>pointer of the input tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor_dim_x</td><td>x dimension of the input tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor_dim_y</td><td>y dimension of the input tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor_ch</td><td>number of input tensor channels </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">ker_weight</td><td>pointer of kernel weights </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_tensor_ch</td><td>number of output tensor channels </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">ker_dim_x</td><td>x dimension of the filter kernel </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">ker_dim_y</td><td>y dimension of the filter kernel </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">pad_x</td><td>padding size in the x dimension </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">pad_y</td><td>padding size in the y dimension </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">stride_x</td><td>convolution stride in the x dimension </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">stride_y</td><td>convolution stride in the y dimension </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">pre_rshift</td><td>right shift amount for the output </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_scale</td><td>value of scaling for the output </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">post_rshift</td><td>right shift amount for the output </td></tr>
    <tr><td class="paramdir">[out]</td><td class="paramname">out_tensor</td><td>pointer of the output tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_tensor_dim_x</td><td>x dimension of the output tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_tensor_dim_y</td><td>y dimension of the output tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tmp_buf</td><td>temporary buffer for the input tensor. It is required when -mext-dsp or -mext-vector is enabled and its size must be equal to "(in_tensor_ch *
                                     ker_dim_x * ker_dim_y + 1) / 2". </td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>This function returns 0 on success; otherwise, it returns -1 if its inputs do not meet the constraints that in_tensor_ch must be equal to out_tensor_ch.</dd></dl>
<dl class="section note"><dt>Note</dt><dd>The outputs will be 2-stage shifted before being stored, i.e., out = ((out &gt;&gt; pre_rshift) *out_scale) &gt;&gt; post_rshift. </dd></dl>

</div>
</div>
<a id="ga3c07fe5b1305f89f094eb44de887288e" name="ga3c07fe5b1305f89f094eb44de887288e"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ga3c07fe5b1305f89f094eb44de887288e">&#9670;&#160;</a></span>hpm_nn_conv_dw_HWC_u8_s8_s8_sym_bias()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">static int32_t hpm_nn_conv_dw_HWC_u8_s8_s8_sym_bias </td>
          <td>(</td>
          <td class="paramtype">const u8_t *</td>          <td class="paramname"><span class="paramname"><em>in_tensor</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>in_tensor_dim</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>in_tensor_ch</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const q7_t *</td>          <td class="paramname"><span class="paramname"><em>ker_weight</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>out_tensor_ch</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>ker_dim</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>pad</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>stride</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const q31_t *</td>          <td class="paramname"><span class="paramname"><em>bias</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>pre_rshift</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>out_scale</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>post_rshift</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">q7_t *</td>          <td class="paramname"><span class="paramname"><em>out_tensor</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>out_tensor_dim</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">q15_t *</td>          <td class="paramname"><span class="paramname"><em>in_tmp_buf</em></span>&#160;)</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span><span class="mlabel">static</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p><code>#include &lt;<a class="el" href="hpm__math_8h.html">middleware/hpm_math/hpm_math.h</a>&gt;</code></p>

<p>This function performs depthwise convolution for unsigned 8-bit integer inputs and signed 8-bit integer outputs with bias inputs and symmetric quantization on the outputs. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor</td><td>pointer of the input tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor_dim</td><td>dimension of the input tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor_ch</td><td>number of input tensor channels </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">ker_weight</td><td>pointer of kernel weights </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_tensor_ch</td><td>number of output tensor channels </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">ker_dim</td><td>dimension of the filter kernel </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">pad</td><td>padding size </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">stride</td><td>convolution stride </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">bias</td><td>pointer of the bias vector </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">pre_rshift</td><td>right shift amount for the output </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_scale</td><td>value of scaling for the output </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">post_rshift</td><td>right shift amount for the output </td></tr>
    <tr><td class="paramdir">[out]</td><td class="paramname">out_tensor</td><td>pointer of the output tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_tensor_dim</td><td>dimension of the output tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tmp_buf</td><td>temporary buffer for the input tensor. It is required when -mext-dsp or -mext-vector is enabled and its size must be equal to "(in_tensor_ch * ker_dim * ker_dim + 1) / 2". </td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>This function returns 0 on success; otherwise, it returns -1 if its inputs do not meet the constraints that in_tensor_ch has to be equal to out_tensor_ch.</dd></dl>
<dl class="section note"><dt>Note</dt><dd>The outputs will be 2-stage shifted before being stored, i.e., out = ((out &gt;&gt; pre_rshift) *out_scale) &gt;&gt; post_rshift. </dd></dl>

</div>
</div>
<a id="gab6af36649c64102a6e1c80e623bed9f3" name="gab6af36649c64102a6e1c80e623bed9f3"></a>
<h2 class="memtitle"><span class="permalink"><a href="#gab6af36649c64102a6e1c80e623bed9f3">&#9670;&#160;</a></span>hpm_nn_conv_dw_HWC_u8_s8_s8_sym_bias_any()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">static int32_t hpm_nn_conv_dw_HWC_u8_s8_s8_sym_bias_any </td>
          <td>(</td>
          <td class="paramtype">const u8_t *</td>          <td class="paramname"><span class="paramname"><em>in_tensor</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>in_tensor_dim_x</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>in_tensor_dim_y</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>in_tensor_ch</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const q7_t *</td>          <td class="paramname"><span class="paramname"><em>ker_weight</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>out_tensor_ch</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>ker_dim_x</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>ker_dim_y</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>pad_x</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>pad_y</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>stride_x</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>stride_y</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const q31_t *</td>          <td class="paramname"><span class="paramname"><em>bias</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>pre_rshift</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>out_scale</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>post_rshift</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">q7_t *</td>          <td class="paramname"><span class="paramname"><em>out_tensor</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>out_tensor_dim_x</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>out_tensor_dim_y</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">q15_t *</td>          <td class="paramname"><span class="paramname"><em>in_tmp_buf</em></span>&#160;)</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span><span class="mlabel">static</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p><code>#include &lt;<a class="el" href="hpm__math_8h.html">middleware/hpm_math/hpm_math.h</a>&gt;</code></p>

<p>This function performs depthwise convolution for unsigned 8-bit integer inputs and signed 8-bit integer outputs in any x and y dimensions with bias inputs and symmetric quantization on the outputs. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor</td><td>pointer of the input tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor_dim_x</td><td>x dimension of the input tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor_dim_y</td><td>y dimension of the input tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor_ch</td><td>number of input tensor channels </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">ker_weight</td><td>pointer of kernel weights </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_tensor_ch</td><td>number of output tensor channels </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">ker_dim_x</td><td>x dimension of the filter kernel </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">ker_dim_y</td><td>y dimension of the filter kernel </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">pad_x</td><td>padding size in the x dimension </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">pad_y</td><td>padding size in the y dimension </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">stride_x</td><td>convolution stride in the x dimension </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">stride_y</td><td>convolution stride in the y dimension </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">bias</td><td>pointer of the bias vector </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">pre_rshift</td><td>right shift amount for the output </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_scale</td><td>value of scaling for the output </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">post_rshift</td><td>right shift amount for the output </td></tr>
    <tr><td class="paramdir">[out]</td><td class="paramname">out_tensor</td><td>pointer of the output tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_tensor_dim_x</td><td>x dimension of the output tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_tensor_dim_y</td><td>y dimension of the output tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tmp_buf</td><td>temporary buffer for the input tensor. It is required when -mext-dsp or -mext-vector is enabled and its size must be equal to "(in_tensor_ch *
                                     ker_dim_x * ker_dim_y + 1) / 2". </td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>This function returns 0 on success; otherwise, it returns -1 if its inputs do not meet the constraints that in_tensor_ch must be equal to out_tensor_ch.</dd></dl>
<dl class="section note"><dt>Note</dt><dd>The outputs will be 2-stage shifted before being stored, i.e., out = ((out &gt;&gt; pre_rshift) *out_scale) &gt;&gt; post_rshift. </dd></dl>

</div>
</div>
<a id="ga11e8db5b74e51807c0f6c264ceb88a3f" name="ga11e8db5b74e51807c0f6c264ceb88a3f"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ga11e8db5b74e51807c0f6c264ceb88a3f">&#9670;&#160;</a></span>hpm_nn_conv_dw_HWC_u8_u8_s8_sym()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">static int32_t hpm_nn_conv_dw_HWC_u8_u8_s8_sym </td>
          <td>(</td>
          <td class="paramtype">const u8_t *</td>          <td class="paramname"><span class="paramname"><em>in_tensor</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>in_tensor_dim</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>in_tensor_ch</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const q7_t *</td>          <td class="paramname"><span class="paramname"><em>ker_weight</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>out_tensor_ch</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>ker_dim</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>pad</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>stride</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>pre_rshift</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>out_scale</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>post_rshift</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">u8_t *</td>          <td class="paramname"><span class="paramname"><em>out_tensor</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>out_tensor_dim</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">q15_t *</td>          <td class="paramname"><span class="paramname"><em>in_tmp_buf</em></span>&#160;)</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span><span class="mlabel">static</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p><code>#include &lt;<a class="el" href="hpm__math_8h.html">middleware/hpm_math/hpm_math.h</a>&gt;</code></p>

<p>This function performs depthwise convolution for unsigned 8-bit integer inputs/outputs with symmetric quantization on the outputs. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor</td><td>pointer of the input tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor_dim</td><td>dimension of the input tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor_ch</td><td>number of input tensor channels </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">ker_weight</td><td>pointer of kernel weights </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_tensor_ch</td><td>number of output tensor channels </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">ker_dim</td><td>dimension of the filter kernel </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">pad</td><td>padding size </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">stride</td><td>convolution stride </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">pre_rshift</td><td>right shift amount for the output </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_scale</td><td>value of scaling for the output </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">post_rshift</td><td>right shift amount for the output </td></tr>
    <tr><td class="paramdir">[out]</td><td class="paramname">out_tensor</td><td>pointer of the output tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_tensor_dim</td><td>dimension of the output tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tmp_buf</td><td>temporary buffer for the input tensor. It is required when -mext-dsp or -mext-vector is enabled and its size must be equal to (in_tensor_ch * ker_dim * ker_dim + 1) / 2. </td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>This function returns 0 on success; otherwise, it returns -1 if its inputs do not meet the constraints that in_tensor_ch has to be equal to out_tensor_ch.</dd></dl>
<dl class="section note"><dt>Note</dt><dd>The outputs will be 2-stage shifted before being stored, i.e., out = ((out &gt;&gt; pre_rshift) *out_scale) &gt;&gt; post_rshift. </dd></dl>

</div>
</div>
<a id="gab5cb8f3dc2985f57b742036399164798" name="gab5cb8f3dc2985f57b742036399164798"></a>
<h2 class="memtitle"><span class="permalink"><a href="#gab5cb8f3dc2985f57b742036399164798">&#9670;&#160;</a></span>hpm_nn_conv_dw_HWC_u8_u8_s8_sym_any()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">static int32_t hpm_nn_conv_dw_HWC_u8_u8_s8_sym_any </td>
          <td>(</td>
          <td class="paramtype">const u8_t *</td>          <td class="paramname"><span class="paramname"><em>in_tensor</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>in_tensor_dim_x</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>in_tensor_dim_y</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>in_tensor_ch</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const q7_t *</td>          <td class="paramname"><span class="paramname"><em>ker_weight</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>out_tensor_ch</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>ker_dim_x</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>ker_dim_y</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>pad_x</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>pad_y</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>stride_x</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>stride_y</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>pre_rshift</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>out_scale</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>post_rshift</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">u8_t *</td>          <td class="paramname"><span class="paramname"><em>out_tensor</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>out_tensor_dim_x</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>out_tensor_dim_y</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">q15_t *</td>          <td class="paramname"><span class="paramname"><em>in_tmp_buf</em></span>&#160;)</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span><span class="mlabel">static</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p><code>#include &lt;<a class="el" href="hpm__math_8h.html">middleware/hpm_math/hpm_math.h</a>&gt;</code></p>

<p>This function performs depthwise convolution for unsigned 8-bit integer inputs/outputs in any x and y dimensions with symmetric quantization on the outputs. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor</td><td>pointer of the input tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor_dim_x</td><td>x dimension of the input tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor_dim_y</td><td>y dimension of the input tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor_ch</td><td>number of input tensor channels </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">ker_weight</td><td>pointer of kernel weights </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_tensor_ch</td><td>number of output tensor channels </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">ker_dim_x</td><td>x dimension of the filter kernel </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">ker_dim_y</td><td>y dimension of the filter kernel </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">pad_x</td><td>padding size in the x dimension </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">pad_y</td><td>padding size in the y dimension </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">stride_x</td><td>convolution stride in the x dimension </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">stride_y</td><td>convolution stride in the y dimension </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">pre_rshift</td><td>right shift amount for the output </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_scale</td><td>value of scaling for the output </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">post_rshift</td><td>right shift amount for the output </td></tr>
    <tr><td class="paramdir">[out]</td><td class="paramname">out_tensor</td><td>pointer of the output tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_tensor_dim_x</td><td>x dimension of the output tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_tensor_dim_y</td><td>y dimension of the output tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tmp_buf</td><td>temporary buffer for the input tensor. It is required when -mext-dsp or -mext-vector is enabled and its size must be equal to "(in_tensor_ch *
                                     ker_dim_x * ker_dim_y + 1) / 2". </td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>This function returns 0 on success; otherwise, it returns -1 if its inputs do not meet the constraints that in_tensor_ch must be equal to out_tensor_ch.</dd></dl>
<dl class="section note"><dt>Note</dt><dd>The outputs will be 2-stage shifted before being stored, i.e., out = ((out &gt;&gt; pre_rshift) *out_scale) &gt;&gt; post_rshift. </dd></dl>

</div>
</div>
<a id="ga88f4d9ab1a22cc7d551664bf37c11f4a" name="ga88f4d9ab1a22cc7d551664bf37c11f4a"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ga88f4d9ab1a22cc7d551664bf37c11f4a">&#9670;&#160;</a></span>hpm_nn_conv_dw_HWC_u8_u8_s8_sym_bias()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">static int32_t hpm_nn_conv_dw_HWC_u8_u8_s8_sym_bias </td>
          <td>(</td>
          <td class="paramtype">const u8_t *</td>          <td class="paramname"><span class="paramname"><em>in_tensor</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>in_tensor_dim</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>in_tensor_ch</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const q7_t *</td>          <td class="paramname"><span class="paramname"><em>ker_weight</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>out_tensor_ch</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>ker_dim</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>pad</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>stride</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const q31_t *</td>          <td class="paramname"><span class="paramname"><em>bias</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>pre_rshift</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>out_scale</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>post_rshift</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">u8_t *</td>          <td class="paramname"><span class="paramname"><em>out_tensor</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>out_tensor_dim</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">q15_t *</td>          <td class="paramname"><span class="paramname"><em>in_tmp_buf</em></span>&#160;)</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span><span class="mlabel">static</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p><code>#include &lt;<a class="el" href="hpm__math_8h.html">middleware/hpm_math/hpm_math.h</a>&gt;</code></p>

<p>This function performs depthwise convolution for unsigned 8-bit integer inputs/outputs with bias inputs and symmetric quantization on the outputs. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor</td><td>pointer of the input tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor_dim</td><td>dimension of the input tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor_ch</td><td>number of input tensor channels </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">ker_weight</td><td>pointer of kernel weights </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_tensor_ch</td><td>number of output tensor channels </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">ker_dim</td><td>dimension of the filter kernel </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">pad</td><td>padding size </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">stride</td><td>convolution stride </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">bias</td><td>pointer of the bias vector </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">pre_rshift</td><td>right shift amount for the output </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_scale</td><td>value of scaling for the output </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">post_rshift</td><td>right shift amount for the output </td></tr>
    <tr><td class="paramdir">[out]</td><td class="paramname">out_tensor</td><td>pointer of the output tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_tensor_dim</td><td>dimension of the output tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tmp_buf</td><td>temporary buffer for the input tensor. It is required when -mext-dsp or -mext-vector is enabled and its size must be equal to "(in_tensor_ch * ker_dim * ker_dim + 1) / 2". </td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>This function returns 0 on success; otherwise, it returns -1 if its inputs do not meet the constraints that in_tensor_ch has to be equal to out_tensor_ch.</dd></dl>
<dl class="section note"><dt>Note</dt><dd>The outputs will be 2-stage shifted before being stored, i.e., out = ((out &gt;&gt; pre_rshift) *out_scale) &gt;&gt; post_rshift. </dd></dl>

</div>
</div>
<a id="ga048ff15cdd4652c25b9b250f8356f335" name="ga048ff15cdd4652c25b9b250f8356f335"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ga048ff15cdd4652c25b9b250f8356f335">&#9670;&#160;</a></span>hpm_nn_conv_dw_HWC_u8_u8_s8_sym_bias_any()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">static int32_t hpm_nn_conv_dw_HWC_u8_u8_s8_sym_bias_any </td>
          <td>(</td>
          <td class="paramtype">const u8_t *</td>          <td class="paramname"><span class="paramname"><em>in_tensor</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>in_tensor_dim_x</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>in_tensor_dim_y</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>in_tensor_ch</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const q7_t *</td>          <td class="paramname"><span class="paramname"><em>ker_weight</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>out_tensor_ch</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>ker_dim_x</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>ker_dim_y</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>pad_x</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>pad_y</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>stride_x</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>stride_y</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const q31_t *</td>          <td class="paramname"><span class="paramname"><em>bias</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>pre_rshift</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>out_scale</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>post_rshift</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">u8_t *</td>          <td class="paramname"><span class="paramname"><em>out_tensor</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>out_tensor_dim_x</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>out_tensor_dim_y</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">q15_t *</td>          <td class="paramname"><span class="paramname"><em>in_tmp_buf</em></span>&#160;)</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span><span class="mlabel">static</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p><code>#include &lt;<a class="el" href="hpm__math_8h.html">middleware/hpm_math/hpm_math.h</a>&gt;</code></p>

<p>This function performs depthwise convolution for unsigned 8-bit integer inputs/outputs in any x and y dimensions with bias inputs and symmetric quantization on the outputs. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor</td><td>pointer of the input tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor_dim_x</td><td>x dimension of the input tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor_dim_y</td><td>y dimension of the input tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor_ch</td><td>number of input tensor channels </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">ker_weight</td><td>pointer of kernel weights </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_tensor_ch</td><td>number of output tensor channels </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">ker_dim_x</td><td>x dimension of the filter kernel </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">ker_dim_y</td><td>y dimension of the filter kernel </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">pad_x</td><td>padding size in the x dimension </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">pad_y</td><td>padding size in the y dimension </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">stride_x</td><td>convolution stride in the x dimension </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">stride_y</td><td>convolution stride in the y dimension </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">bias</td><td>pointer of the bias vector </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">pre_rshift</td><td>right shift amount for the output </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_scale</td><td>value of scaling for the output </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">post_rshift</td><td>right shift amount for the output </td></tr>
    <tr><td class="paramdir">[out]</td><td class="paramname">out_tensor</td><td>pointer of the output tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_tensor_dim_x</td><td>x dimension of the output tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_tensor_dim_y</td><td>y dimension of the output tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tmp_buf</td><td>temporary buffer for the input tensor. It is required when -mext-dsp or -mext-vector is enabled and its size must be equal to "(in_tensor_ch *
                                     ker_dim_x * ker_dim_y + 1) / 2". </td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>This function returns 0 on success; otherwise, it returns -1 if its inputs do not meet the constraints that in_tensor_ch must be equal to out_tensor_ch.</dd></dl>
<dl class="section note"><dt>Note</dt><dd>The outputs will be 2-stage shifted before being stored, i.e., out = ((out &gt;&gt; pre_rshift) *out_scale) &gt;&gt; post_rshift. </dd></dl>

</div>
</div>
<a id="ga0b9ce54b2ac422932e71b67b66d657c1" name="ga0b9ce54b2ac422932e71b67b66d657c1"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ga0b9ce54b2ac422932e71b67b66d657c1">&#9670;&#160;</a></span>hpm_nn_conv_dw_HWC_u8_u8_u8_asym_bias_any()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">static int32_t hpm_nn_conv_dw_HWC_u8_u8_u8_asym_bias_any </td>
          <td>(</td>
          <td class="paramtype">const uint8_t *</td>          <td class="paramname"><span class="paramname"><em>in_tensor</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>in_tensor_dim_x</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>in_tensor_dim_y</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>in_tensor_ch</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint8_t *</td>          <td class="paramname"><span class="paramname"><em>ker_weight</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>ker_dim_x</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>ker_dim_y</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const int16_t</td>          <td class="paramname"><span class="paramname"><em>ch_mult</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const int16_t</td>          <td class="paramname"><span class="paramname"><em>pad_x</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const int16_t</td>          <td class="paramname"><span class="paramname"><em>pad_y</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const int16_t</td>          <td class="paramname"><span class="paramname"><em>stride_x</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const int16_t</td>          <td class="paramname"><span class="paramname"><em>stride_y</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const int16_t</td>          <td class="paramname"><span class="paramname"><em>dilation_x</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const int16_t</td>          <td class="paramname"><span class="paramname"><em>dilation_y</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const int32_t *</td>          <td class="paramname"><span class="paramname"><em>bias</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const int32_t</td>          <td class="paramname"><span class="paramname"><em>in_offset</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const int32_t</td>          <td class="paramname"><span class="paramname"><em>ker_offset</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const int32_t</td>          <td class="paramname"><span class="paramname"><em>out_offset</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">uint8_t *</td>          <td class="paramname"><span class="paramname"><em>out_tensor</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>out_tensor_dim_x</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>out_tensor_dim_y</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const int32_t</td>          <td class="paramname"><span class="paramname"><em>act_min</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const int32_t</td>          <td class="paramname"><span class="paramname"><em>act_max</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const int32_t</td>          <td class="paramname"><span class="paramname"><em>out_shift</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const int32_t</td>          <td class="paramname"><span class="paramname"><em>out_scale</em></span>&#160;)</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span><span class="mlabel">static</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p><code>#include &lt;<a class="el" href="hpm__math_8h.html">middleware/hpm_math/hpm_math.h</a>&gt;</code></p>

<p>This function performs depthwise convolution for unsigned 8-bit integer inputs/outputs in any x and y dimensions with asymmetric quantization on the outputs. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor</td><td>pointer of the input tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor_dim_x</td><td>x dimension of the input tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor_dim_y</td><td>y dimension of the input tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor_ch</td><td>number of input tensor channels </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">ker_weight</td><td>pointer of kernel weights </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">ker_dim_x</td><td>x dimension of the filter kernel </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">ker_dim_y</td><td>y dimension of the filter kernel </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">ch_mult</td><td>multiplier of input tensor channels </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">pad_x</td><td>padding size in the x dimension </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">pad_y</td><td>padding size in the y dimension </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">stride_x</td><td>convolution stride in the x dimension </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">stride_y</td><td>convolution stride in the y dimension </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">dilation_x</td><td>dummy </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">dilation_y</td><td>dummy </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">bias</td><td>pointer of the bias vector </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_offset</td><td>value of offset for the input tensor It should be in the range of -255 to 0. </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">ker_offset</td><td>value of offset for the filter kernel It should be in the range of -255 to 0. </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_offset</td><td>value of offset for the output tensor. It should be in the range of 0 to 255. </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_tensor</td><td>pointer of the output tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_tensor_dim_x</td><td>x dimension of the output tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_tensor_dim_y</td><td>y dimension of the output tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">act_min</td><td>minimum value to clip out the ouput tensor. It should be in the range of 0 to 255. </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">act_max</td><td>maximum value to clip out the ouput tensor. It should be in the range of 0 to 255. </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_shift</td><td>shift amount for the output tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_scale</td><td>value of sacling for the output tensor </td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>This function returns 0 on success; otherwise, it returns -1 if its inputs do not meet the constraint that both ch_mult and ker_dim_x are multiple of 2. </dd></dl>

</div>
</div>
<a id="gae45d9ea581aa690f6bc604878b7ff56a" name="gae45d9ea581aa690f6bc604878b7ff56a"></a>
<h2 class="memtitle"><span class="permalink"><a href="#gae45d9ea581aa690f6bc604878b7ff56a">&#9670;&#160;</a></span>hpm_nn_conv_HWC_s16_s16_s16_sft_bias()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">static int32_t hpm_nn_conv_HWC_s16_s16_s16_sft_bias </td>
          <td>(</td>
          <td class="paramtype">const q15_t *</td>          <td class="paramname"><span class="paramname"><em>in_tensor</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>in_tensor_dim</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>in_tensor_ch</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const q15_t *</td>          <td class="paramname"><span class="paramname"><em>ker_weight</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>out_tensor_ch</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>ker_dim</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>pad</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>stride</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const q15_t *</td>          <td class="paramname"><span class="paramname"><em>bias</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>bias_lshift</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>out_rshift</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">q15_t *</td>          <td class="paramname"><span class="paramname"><em>out_tensor</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>out_tensor_dim</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">q15_t *</td>          <td class="paramname"><span class="paramname"><em>in_tmp_buf</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">q7_t *</td>          <td class="paramname"><span class="paramname"><em>tmp_buf</em></span>&#160;)</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span><span class="mlabel">static</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p><code>#include &lt;<a class="el" href="hpm__math_8h.html">middleware/hpm_math/hpm_math.h</a>&gt;</code></p>

<p>This function performs signed 16-bit integer convolution with shift-based quantization on the outputs. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor</td><td>pointer of the input tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor_dim</td><td>dimension of the input tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor_ch</td><td>number of input tensor channels </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">ker_weight</td><td>pointer of kernel weights </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_tensor_ch</td><td>number of output tensor channels </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">ker_dim</td><td>dimension of the filter kernel </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">pad</td><td>padding size </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">stride</td><td>convolution stride </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">bias</td><td>pointer of the bias vector </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">bias_lshift</td><td>left shift amount for the bias </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_rshift</td><td>right shift amount for the output </td></tr>
    <tr><td class="paramdir">[out]</td><td class="paramname">out_tensor</td><td>pointer of the output tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_tensor_dim</td><td>dimension of the output tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tmp_buf</td><td>temporary buffer for the input tensor. It is required when -mext-dsp or -mext-vector is enabled and its size must be equal to "in_tensor_ch * ker_dim * ker_dim". </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">tmp_buf</td><td>dummy </td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>This function only returns 0.</dd></dl>
<p><b>Example:</b> </p><div class="fragment"><div class="line"><span class="comment">//Convolve a 28x28x1 input tensor with a 5x5 kernel and generate a 24x24x20</span></div>
<div class="line"><span class="comment">//output tensor. Let both dimensions padding be 0 and their stride be 1.</span></div>
<div class="line"> </div>
<div class="line"><span class="preprocessor">#define IN_DIM 28</span></div>
<div class="line"><span class="preprocessor">#define IN_CH 1</span></div>
<div class="line"><span class="preprocessor">#define KER_DIM 5</span></div>
<div class="line"><span class="preprocessor">#define PAD 0</span></div>
<div class="line"><span class="preprocessor">#define STRIDE 1</span></div>
<div class="line"><span class="preprocessor">#define BIAS_LSHIFT 6</span></div>
<div class="line"><span class="preprocessor">#define OUT_RSHIFT 10</span></div>
<div class="line"><span class="preprocessor">#define OUT_CH 20</span></div>
<div class="line"><span class="preprocessor">#define OUT_DIM 24</span></div>
<div class="line"> </div>
<div class="line">q15_t input_data[IN_CH * IN_DIM * IN_DIM] = {...};</div>
<div class="line">q15_t weight[IN_CH * KER_DIM * KER_DIM * OUT_CH] = {...};</div>
<div class="line">q15_t <a class="code hl_variable" href="group__nnfullyconnect.html#ga602e28fc157c370e73e4df5712f9df84">bias</a>[OUT_CH] = {...};</div>
<div class="line">q15_t <a class="code hl_variable" href="group__nnfullyconnect.html#ga4972f5e62722e743bc2e14d86e130148">in_tmp_buf</a>[IN_CH * KER_DIM * KER_DIM] = {0};</div>
<div class="line">q15_t out_data[OUT_CH * OUT_DIM * OUT_DIM];</div>
<div class="line"> </div>
<div class="line">riscv_nn_conv_HWC_s16_s16_s16_sft_bias(input_data, IN_DIM, IN_CH, weight,</div>
<div class="line">    OUT_CH, KER_DIM, PAD, STRIDE, <a class="code hl_variable" href="group__nnfullyconnect.html#ga602e28fc157c370e73e4df5712f9df84">bias</a>, BIAS_LSHIFT, OUT_RSHIFT, out_data,</div>
<div class="line">    OUT_DIM, <a class="code hl_variable" href="group__nnfullyconnect.html#ga4972f5e62722e743bc2e14d86e130148">in_tmp_buf</a>, NULL);</div>
</div><!-- fragment --> 
</div>
</div>
<a id="ga2ad7e5bbd56df8f95bd183850900ff56" name="ga2ad7e5bbd56df8f95bd183850900ff56"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ga2ad7e5bbd56df8f95bd183850900ff56">&#9670;&#160;</a></span>hpm_nn_conv_HWC_s16_s16_s16_sft_bias_fast()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">static int32_t hpm_nn_conv_HWC_s16_s16_s16_sft_bias_fast </td>
          <td>(</td>
          <td class="paramtype">const q15_t *</td>          <td class="paramname"><span class="paramname"><em>in_tensor</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>in_tensor_dim</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>in_tensor_ch</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const q15_t *</td>          <td class="paramname"><span class="paramname"><em>ker_weight</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>out_tensor_ch</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>ker_dim</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>pad</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>stride</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const q15_t *</td>          <td class="paramname"><span class="paramname"><em>bias</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>bias_lshift</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>out_rshift</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">q15_t *</td>          <td class="paramname"><span class="paramname"><em>out_tensor</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>out_tensor_dim</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">q15_t *</td>          <td class="paramname"><span class="paramname"><em>in_tmp_buf</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">q7_t *</td>          <td class="paramname"><span class="paramname"><em>tmp_buf</em></span>&#160;)</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span><span class="mlabel">static</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p><code>#include &lt;<a class="el" href="hpm__math_8h.html">middleware/hpm_math/hpm_math.h</a>&gt;</code></p>

<p>This function performs fast signed 16-bit integer convolution with shift-based quantization on the outputs. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor</td><td>pointer of the input tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor_dim</td><td>dimension of the input tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor_ch</td><td>number of input tensor channels </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">ker_weight</td><td>pointer of kernel weights </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_tensor_ch</td><td>number of output tensor channels </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">ker_dim</td><td>dimension of the filter kernel </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">pad</td><td>padding size </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">stride</td><td>convolution stride </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">bias</td><td>pointer of the bias vector </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">bias_lshift</td><td>left shift amount for the bias </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_rshift</td><td>right shift amount for the output </td></tr>
    <tr><td class="paramdir">[out]</td><td class="paramname">out_tensor</td><td>pointer of the output tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_tensor_dim</td><td>dimension of the output tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tmp_buf</td><td>temporary buffer for the input tensor. It is required when -mext-dsp or -mext-vector is enabled and its size must be equal to "2 *
                                 in_tensor_ch * ker_dim * ker_dim". </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">tmp_buf</td><td>dummy </td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>This function returns 0 on success; otherwise, it returns -1 if its inputs do not meet the constraints that both in_tensor_ch and out_tensor_ch are multiple of 2.</dd></dl>
<p><b>Example:</b> </p><div class="fragment"><div class="line"><span class="comment">//Convolve a 28x28x4 input tensor with a 5x5 kernel and generate a 24x24x8</span></div>
<div class="line"><span class="comment">//output tensor. Let both dimensions padding be 0 and their stride be 1.</span></div>
<div class="line"> </div>
<div class="line"><span class="preprocessor">#define IN_DIM 28</span></div>
<div class="line"><span class="preprocessor">#define IN_CH 4</span></div>
<div class="line"><span class="preprocessor">#define KER_DIM 5</span></div>
<div class="line"><span class="preprocessor">#define PAD 0</span></div>
<div class="line"><span class="preprocessor">#define STRIDE 1</span></div>
<div class="line"><span class="preprocessor">#define BIAS_LSHIFT 6</span></div>
<div class="line"><span class="preprocessor">#define OUT_RSHIFT 10</span></div>
<div class="line"><span class="preprocessor">#define OUT_CH 8</span></div>
<div class="line"><span class="preprocessor">#define OUT_DIM 24</span></div>
<div class="line"> </div>
<div class="line">q15_t in_data[IN_CH * IN_DIM * IN_DIM] = {...};</div>
<div class="line">q15_t weight[IN_CH * KER_DIM * KER_DIM * OUT_CH] = {...};</div>
<div class="line">q15_t <a class="code hl_variable" href="group__nnfullyconnect.html#ga602e28fc157c370e73e4df5712f9df84">bias</a>[OUT_CH] = {...};</div>
<div class="line">q15_t <a class="code hl_variable" href="group__nnfullyconnect.html#ga4972f5e62722e743bc2e14d86e130148">in_tmp_buf</a>[IN_CH * KER_DIM * KER_DIM] = {0};</div>
<div class="line">q15_t out_data[OUT_CH * OUT_DIM * OUT_DIM];</div>
<div class="line"> </div>
<div class="line">riscv_nn_conv_HWC_s16_s16_s16_sft_bias_fast(in_data, IN_DIM, IN_CH, weight,</div>
<div class="line">    OUT_CH, KER_DIM, PAD, STRIDE, <a class="code hl_variable" href="group__nnfullyconnect.html#ga602e28fc157c370e73e4df5712f9df84">bias</a>, BIAS_LSHIFT, OUT_RSHIFT, out_data,</div>
<div class="line">    OUT_DIM, <a class="code hl_variable" href="group__nnfullyconnect.html#ga4972f5e62722e743bc2e14d86e130148">in_tmp_buf</a>, NULL);</div>
</div><!-- fragment --> 
</div>
</div>
<a id="gab92665e531cb2e24620d923c487f5697" name="gab92665e531cb2e24620d923c487f5697"></a>
<h2 class="memtitle"><span class="permalink"><a href="#gab92665e531cb2e24620d923c487f5697">&#9670;&#160;</a></span>hpm_nn_conv_HWC_s16_s16_s16_sft_bias_fast_any()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">static int32_t hpm_nn_conv_HWC_s16_s16_s16_sft_bias_fast_any </td>
          <td>(</td>
          <td class="paramtype">const q15_t *</td>          <td class="paramname"><span class="paramname"><em>in_tensor</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>in_tensor_dim_x</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>in_tensor_dim_y</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>in_tensor_ch</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const q15_t *</td>          <td class="paramname"><span class="paramname"><em>ker_weight</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>out_tensor_ch</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>ker_dim_x</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>ker_dim_y</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>pad_x</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>pad_y</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>stride_x</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>stride_y</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const q15_t *</td>          <td class="paramname"><span class="paramname"><em>bias</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>bias_lshift</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>out_rshift</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">q15_t *</td>          <td class="paramname"><span class="paramname"><em>out_tensor</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>out_tensor_dim_x</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>out_tensor_dim_y</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">q15_t *</td>          <td class="paramname"><span class="paramname"><em>in_tmp_buf</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">q7_t *</td>          <td class="paramname"><span class="paramname"><em>tmp_buf</em></span>&#160;)</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span><span class="mlabel">static</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p><code>#include &lt;<a class="el" href="hpm__math_8h.html">middleware/hpm_math/hpm_math.h</a>&gt;</code></p>

<p>This function performs fast signed 16-bit integer convolution in any x and y dimensions with shift-based quantization on the outputs. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor</td><td>pointer of the input tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor_dim_x</td><td>x dimension of the input tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor_dim_y</td><td>y dimension of the input tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor_ch</td><td>number of input tensor channels </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">ker_weight</td><td>pointer of kernel weights </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_tensor_ch</td><td>number of output tensor channels </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">ker_dim_x</td><td>x dimension of the filter kernel </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">ker_dim_y</td><td>y dimension of the filter kernel </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">pad_x</td><td>padding size in the x dimension </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">pad_y</td><td>padding size in the y dimension </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">stride_x</td><td>convolution stride in the x dimension </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">stride_y</td><td>convolution stride in the y dimension </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">bias</td><td>pointer of the bias vector </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">bias_lshift</td><td>left shift amount for the bias </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_rshift</td><td>right shift amount for the output </td></tr>
    <tr><td class="paramdir">[out]</td><td class="paramname">out_tensor</td><td>pointer of the output tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_tensor_dim_x</td><td>x dimension of the output tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_tensor_dim_y</td><td>y dimension of the output tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tmp_buf</td><td>temporary buffer for the input tensor. It is required when -mext-dsp or -mext-vector is enabled and its size must be equal to "2 * in_tensor_ch *
                                     ker_dim_x * ker_dim_y". </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">tmp_buf</td><td>dummy </td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>This function returns 0 on success; otherwise, it returns -1 if its inputs do not meet the constraints that both in_tensor_ch and out_tensor_ch are multiple of 2.</dd></dl>
<p><b>Example:</b> </p><div class="fragment"><div class="line"><span class="comment">//Convolve a 160x120x20 input tensor with a 3x5 kernel and generate a</span></div>
<div class="line"><span class="comment">//80x59x8 output tensor. Let both dimensions padding be 1 and their stride</span></div>
<div class="line"><span class="comment">//be 2.</span></div>
<div class="line"> </div>
<div class="line"><span class="preprocessor">#define IN_X 160</span></div>
<div class="line"><span class="preprocessor">#define IN_Y 120</span></div>
<div class="line"><span class="preprocessor">#define IN_CH 20</span></div>
<div class="line"><span class="preprocessor">#define OUT_CH 8</span></div>
<div class="line"><span class="preprocessor">#define KER_DIM_X 3</span></div>
<div class="line"><span class="preprocessor">#define KER_DIM_Y 5</span></div>
<div class="line"><span class="preprocessor">#define PAD_X 1</span></div>
<div class="line"><span class="preprocessor">#define PAD_Y 1</span></div>
<div class="line"><span class="preprocessor">#define STRIDE_X 2</span></div>
<div class="line"><span class="preprocessor">#define STRIDE_Y 2</span></div>
<div class="line"><span class="preprocessor">#define BIAS_LSHIFT 6</span></div>
<div class="line"><span class="preprocessor">#define OUT_RSHIFT 9</span></div>
<div class="line"><span class="preprocessor">#define OUT_X 80</span></div>
<div class="line"><span class="preprocessor">#define OUT_Y 59</span></div>
<div class="line"> </div>
<div class="line">q15_t in_data[IN_CH * IN_X * IN_Y] = {...};</div>
<div class="line">q15_t weight[IN_CH * KER_DIM_X * KER_DIM_Y * OUT_CH] = {...};</div>
<div class="line">q15_t <a class="code hl_variable" href="group__nnfullyconnect.html#ga602e28fc157c370e73e4df5712f9df84">bias</a>[OUT_CH] = {...};</div>
<div class="line">q15_t <a class="code hl_variable" href="group__nnfullyconnect.html#ga4972f5e62722e743bc2e14d86e130148">in_tmp_buf</a>[2 * IN_CH * KER_DIM_X  * KER_DIM_Y] = {0};</div>
<div class="line">q15_t out_data[OUT_CH * OUT_X * OUT_Y];</div>
<div class="line"> </div>
<div class="line">riscv_nn_conv_HWC_s16_s16_s16_sft_bias_fast_any(in_data, IN_X, IN_Y , IN_CH,</div>
<div class="line">    weight, OUT_CH, KER_DIM_X, KER_DIM_Y, PAD_X, PAD_Y, STRIDE_X, STRIDE_Y,</div>
<div class="line">    <a class="code hl_variable" href="group__nnfullyconnect.html#ga602e28fc157c370e73e4df5712f9df84">bias</a>, BIAS_LSHIFT, OUT_RSHIFT, out_data, OUT_X, OUT_Y, <a class="code hl_variable" href="group__nnfullyconnect.html#ga4972f5e62722e743bc2e14d86e130148">in_tmp_buf</a>,</div>
<div class="line">    NULL);</div>
</div><!-- fragment --> 
</div>
</div>
<a id="gadbb401015033df936d4547841e0c6778" name="gadbb401015033df936d4547841e0c6778"></a>
<h2 class="memtitle"><span class="permalink"><a href="#gadbb401015033df936d4547841e0c6778">&#9670;&#160;</a></span>hpm_nn_conv_HWC_s8_s16_s8_RGB_sym_bias_fast()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">static int32_t hpm_nn_conv_HWC_s8_s16_s8_RGB_sym_bias_fast </td>
          <td>(</td>
          <td class="paramtype">const q7_t *</td>          <td class="paramname"><span class="paramname"><em>in_tensor</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>in_tensor_dim</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const q7_t *</td>          <td class="paramname"><span class="paramname"><em>ker_weight</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>out_tensor_ch</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>ker_dim</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>pad</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>stride</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const q31_t *</td>          <td class="paramname"><span class="paramname"><em>bias</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>pre_rshift</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>out_scale</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>post_rshift</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">q15_t *</td>          <td class="paramname"><span class="paramname"><em>out_tensor</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>out_tensor_dim</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">q15_t *</td>          <td class="paramname"><span class="paramname"><em>in_tmp_buf</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">q15_t *</td>          <td class="paramname"><span class="paramname"><em>wt_tmp_buf</em></span>&#160;)</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span><span class="mlabel">static</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p><code>#include &lt;<a class="el" href="hpm__math_8h.html">middleware/hpm_math/hpm_math.h</a>&gt;</code></p>

<p>This function performs fast convolution on RGB images for signed 8-bit integer inputs and signed 16-bit integer outputs with bias inputs and symmetric quantization on the outputs. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor</td><td>pointer of the input tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor_dim</td><td>input tensor dimension </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">ker_weight</td><td>pointer of kernel weights </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_tensor_ch</td><td>number of output tensor channels </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">ker_dim</td><td>dimension of the filter kernel </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">pad</td><td>padding size </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">stride</td><td>convolution stride </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">bias</td><td>pointer of the bias vector </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">pre_rshift</td><td>right shift amount for the output </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_scale</td><td>value of scaling for the output </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">post_rshift</td><td>right shift amount for the output </td></tr>
    <tr><td class="paramdir">[out]</td><td class="paramname">out_tensor</td><td>pointer of the output tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_tensor_dim</td><td>dimension of the output tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tmp_buf</td><td>temporary buffer for the input tensor. It is required when -mext-dsp or -mext-vector enabled and its size must be "2 * (3 *
                                 ker_dim * ker_dim + 1)". </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">wt_tmp_buf</td><td>temporary buffer for kernel weights. It is required when -mext-dsp or -mext-vector enabled and its size must be "out_tensor_ch *
                                 (3 * ker_dim * ker_dim + 1)". </td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>This function only returns 0.</dd></dl>
<dl class="section note"><dt>Note</dt><dd>The outputs will be 2-stage shifted before being stored, i.e., out = ((out &gt;&gt; pre_rshift) *out_scale) &gt;&gt; post_rshift. </dd></dl>

</div>
</div>
<a id="ga760c3e28022de0cc9781549ec67b472a" name="ga760c3e28022de0cc9781549ec67b472a"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ga760c3e28022de0cc9781549ec67b472a">&#9670;&#160;</a></span>hpm_nn_conv_HWC_s8_s16_s8_RGB_sym_fast()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">static int32_t hpm_nn_conv_HWC_s8_s16_s8_RGB_sym_fast </td>
          <td>(</td>
          <td class="paramtype">const q7_t *</td>          <td class="paramname"><span class="paramname"><em>in_tensor</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>in_tensor_dim</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const q7_t *</td>          <td class="paramname"><span class="paramname"><em>ker_weight</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>out_tensor_ch</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>ker_dim</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>pad</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>stride</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>pre_rshift</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>out_scale</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>post_rshift</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">q15_t *</td>          <td class="paramname"><span class="paramname"><em>out_tensor</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>out_tensor_dim</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">q15_t *</td>          <td class="paramname"><span class="paramname"><em>in_tmp_buf</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">q15_t *</td>          <td class="paramname"><span class="paramname"><em>wt_tmp_buf</em></span>&#160;)</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span><span class="mlabel">static</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p><code>#include &lt;<a class="el" href="hpm__math_8h.html">middleware/hpm_math/hpm_math.h</a>&gt;</code></p>

<p>This function performs fast convolution on RGB images for signed 8-bit integer inputs and signed 16-bit integer outputs with symmetric quantization on the outputs. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor</td><td>pointer of the input tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor_dim</td><td>input tensor dimension </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">ker_weight</td><td>pointer of kernel weights </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_tensor_ch</td><td>number of output tensor channels </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">ker_dim</td><td>dimension of the filter kernel </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">pad</td><td>padding size </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">stride</td><td>convolution stride </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">pre_rshift</td><td>right shift amount for the output </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_scale</td><td>value of scaling for the output </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">post_rshift</td><td>right shift amount for the output </td></tr>
    <tr><td class="paramdir">[out]</td><td class="paramname">out_tensor</td><td>pointer of the output tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_tensor_dim</td><td>dimension of the output tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tmp_buf</td><td>temporary buffer for the input tensor. It is required when -mext-dsp or -mext-vector enabled and its size must be "2 * (3 *
                                 ker_dim * ker_dim + 1)". </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">wt_tmp_buf</td><td>temporary buffer for kernel weights. It is required when -mext-dsp or -mext-vector enabled and its size must be "out_tensor_ch *
                                 (3 * ker_dim * ker_dim + 1)". </td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>This function only returns 0.</dd></dl>
<dl class="section note"><dt>Note</dt><dd>The outputs will be 2-stage shifted before being stored, i.e., out = ((out &gt;&gt; pre_rshift) *out_scale) &gt;&gt; post_rshift. </dd></dl>

</div>
</div>
<a id="gaa32181a4fa9730dd1aaff34473aad105" name="gaa32181a4fa9730dd1aaff34473aad105"></a>
<h2 class="memtitle"><span class="permalink"><a href="#gaa32181a4fa9730dd1aaff34473aad105">&#9670;&#160;</a></span>hpm_nn_conv_HWC_s8_s16_s8_sym_bias_fast()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">static int32_t hpm_nn_conv_HWC_s8_s16_s8_sym_bias_fast </td>
          <td>(</td>
          <td class="paramtype">const q7_t *</td>          <td class="paramname"><span class="paramname"><em>in_tensor</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>in_tensor_dim</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>in_tensor_ch</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const q7_t *</td>          <td class="paramname"><span class="paramname"><em>ker_weight</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>out_tensor_ch</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>ker_dim</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>pad</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>stride</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const q31_t *</td>          <td class="paramname"><span class="paramname"><em>bias</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>pre_rshift</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>out_scale</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>post_rshift</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">q15_t *</td>          <td class="paramname"><span class="paramname"><em>out_tensor</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>out_tensor_dim</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">q15_t *</td>          <td class="paramname"><span class="paramname"><em>in_tmp_buf</em></span>&#160;)</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span><span class="mlabel">static</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p><code>#include &lt;<a class="el" href="hpm__math_8h.html">middleware/hpm_math/hpm_math.h</a>&gt;</code></p>

<p>This function performs fast convolution for signed 8-bit integer inputs and signed 16-bit integer outputs with bias inputs and symmetric quantization on the outputs. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor</td><td>pointer of the input vector </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor_dim</td><td>dimension of the input tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor_ch</td><td>number of input tensor channels </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">ker_weight</td><td>pointer of kernel weights </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_tensor_ch</td><td>number of output tensor channels </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">ker_dim</td><td>dimension of the filter kernel </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">pad</td><td>padding size </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">stride</td><td>convolution stride </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">bias</td><td>pointer of the bias vector </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">pre_rshift</td><td>right shift amount for the output </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_scale</td><td>value of scaling for the output </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">post_rshift</td><td>right shift amount for the output </td></tr>
    <tr><td class="paramdir">[out]</td><td class="paramname">out_tensor</td><td>pointer of the output tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_tensor_dim</td><td>dimension of the output tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tmp_buf</td><td>temporary buffer for the input tensor. It is required when -mext-dsp or -mext-vector enabled and its size must be equal to "2 *
                                 in_tensor_ch * ker_dim * ker_dim". </td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>This function returns 0 on success; otherwise, it returns -1 if its inputs do not meet the constraints that in_tensor_ch is a multiple of 4 and out_tensor_ch is a multiple of 2.</dd></dl>
<dl class="section note"><dt>Note</dt><dd>The outputs will be 2-stage shifted before being stored, i.e., out = ((out &gt;&gt; pre_rshift) *out_scale) &gt;&gt; post_rshift. </dd></dl>

</div>
</div>
<a id="gafa3b832483993fd1609f2744a7a1c6d5" name="gafa3b832483993fd1609f2744a7a1c6d5"></a>
<h2 class="memtitle"><span class="permalink"><a href="#gafa3b832483993fd1609f2744a7a1c6d5">&#9670;&#160;</a></span>hpm_nn_conv_HWC_s8_s16_s8_sym_bias_fast_any()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">static int32_t hpm_nn_conv_HWC_s8_s16_s8_sym_bias_fast_any </td>
          <td>(</td>
          <td class="paramtype">const q7_t *</td>          <td class="paramname"><span class="paramname"><em>in_tensor</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>in_tensor_dim_x</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>in_tensor_dim_y</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>in_tensor_ch</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const q7_t *</td>          <td class="paramname"><span class="paramname"><em>ker_weight</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>out_tensor_ch</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>ker_dim_x</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>ker_dim_y</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>pad_x</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>pad_y</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>stride_x</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>stride_y</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const q31_t *</td>          <td class="paramname"><span class="paramname"><em>bias</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>pre_rshift</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>out_scale</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>post_rshift</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">q15_t *</td>          <td class="paramname"><span class="paramname"><em>out_tensor</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>out_tensor_dim_x</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>out_tensor_dim_y</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">q15_t *</td>          <td class="paramname"><span class="paramname"><em>in_tmp_buf</em></span>&#160;)</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span><span class="mlabel">static</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p><code>#include &lt;<a class="el" href="hpm__math_8h.html">middleware/hpm_math/hpm_math.h</a>&gt;</code></p>

<p>This function performs fast convolution for signed 8-bit integer inputs and signed 16-bit integer outputs in any x and y dimensions with bias inputs and symmetric quantization on the outputs. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor</td><td>pointer of the input vector </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor_dim_x</td><td>x dimension of the input tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor_dim_y</td><td>y dimension of the input tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor_ch</td><td>number of input tensor channels </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">ker_weight</td><td>pointer of kernel weights </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_tensor_ch</td><td>number of output tensor channels </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">ker_dim_x</td><td>x dimension of the filter kernel </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">ker_dim_y</td><td>y dimension of the filter kernel </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">pad_x</td><td>padding size in the x dimension </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">pad_y</td><td>padding size in the y dimension </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">stride_x</td><td>convolution stride in the x dimension </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">stride_y</td><td>convolution stride in the y dimension </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">bias</td><td>pointer of the bias vector </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">pre_rshift</td><td>right shift amount for the output </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_scale</td><td>value of scaling for the output </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">post_rshift</td><td>right shift amount for the output </td></tr>
    <tr><td class="paramdir">[out]</td><td class="paramname">out_tensor</td><td>pointer of the output tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_tensor_dim_x</td><td>x dimension of the output tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_tensor_dim_y</td><td>y dimension of the output tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tmp_buf</td><td>temporary buffer for the input tensor. It is required when -mext-dsp or -mext-vector enabled and its size must be equal to "2 * in_tensor_ch * ker_dim_x
                                     * ker_dim_y". </td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>This function returns 0 on success; otherwise, it returns -1 if its inputs do not meet the constraints that in_tensor_ch is a multiple of 4 and out_tensor_ch is a multiple of 2.</dd></dl>
<dl class="section note"><dt>Note</dt><dd>The outputs will be 2-stage shifted before being stored, i.e., out = ((out &gt;&gt; pre_rshift) *out_scale) &gt;&gt; post_rshift. </dd></dl>

</div>
</div>
<a id="gaba554ffd11e415541ebab72f6161915d" name="gaba554ffd11e415541ebab72f6161915d"></a>
<h2 class="memtitle"><span class="permalink"><a href="#gaba554ffd11e415541ebab72f6161915d">&#9670;&#160;</a></span>hpm_nn_conv_HWC_s8_s16_s8_sym_fast()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">static int32_t hpm_nn_conv_HWC_s8_s16_s8_sym_fast </td>
          <td>(</td>
          <td class="paramtype">const q7_t *</td>          <td class="paramname"><span class="paramname"><em>in_tensor</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>in_tensor_dim</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>in_tensor_ch</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const q7_t *</td>          <td class="paramname"><span class="paramname"><em>ker_weight</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>out_tensor_ch</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>ker_dim</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>pad</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>stride</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>pre_rshift</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>out_scale</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>post_rshift</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">q15_t *</td>          <td class="paramname"><span class="paramname"><em>out_tensor</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>out_tensor_dim</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">q15_t *</td>          <td class="paramname"><span class="paramname"><em>in_tmp_buf</em></span>&#160;)</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span><span class="mlabel">static</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p><code>#include &lt;<a class="el" href="hpm__math_8h.html">middleware/hpm_math/hpm_math.h</a>&gt;</code></p>

<p>This function performs fast convolution for signed 8-bit integer inputs and signed 16-bit integer outputs with symmetric quantization on the outputs. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor</td><td>pointer of the input vector </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor_dim</td><td>dimension of the input tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor_ch</td><td>number of input tensor channels </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">ker_weight</td><td>pointer of kernel weights </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_tensor_ch</td><td>number of output tensor channels </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">ker_dim</td><td>dimension of the filter kernel </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">pad</td><td>padding size </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">stride</td><td>convolution stride </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">pre_rshift</td><td>right shift amount for the output </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_scale</td><td>value of scaling for the output </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">post_rshift</td><td>right shift amount for the output </td></tr>
    <tr><td class="paramdir">[out]</td><td class="paramname">out_tensor</td><td>pointer of the output tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_tensor_dim</td><td>dimension of the output tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tmp_buf</td><td>temporary buffer for the input tensor. It is required when -mext-dsp or -mext-vector enabled and its size must be equal to "2 *
                                 in_tensor_ch * ker_dim * ker_dim". </td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>This function returns 0 on success; otherwise, it returns -1 if its inputs do not meet the constraints that in_tensor_ch is a multiple of 4 and out_tensor_ch is a multiple of 2.</dd></dl>
<dl class="section note"><dt>Note</dt><dd>The outputs will be 2-stage shifted before being stored, i.e., out = ((out &gt;&gt; pre_rshift) *out_scale) &gt;&gt; post_rshift. </dd></dl>

</div>
</div>
<a id="gaea70ea34cd3a6e45bc89ada5e110e698" name="gaea70ea34cd3a6e45bc89ada5e110e698"></a>
<h2 class="memtitle"><span class="permalink"><a href="#gaea70ea34cd3a6e45bc89ada5e110e698">&#9670;&#160;</a></span>hpm_nn_conv_HWC_s8_s16_s8_sym_fast_any()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">static int32_t hpm_nn_conv_HWC_s8_s16_s8_sym_fast_any </td>
          <td>(</td>
          <td class="paramtype">const q7_t *</td>          <td class="paramname"><span class="paramname"><em>in_tensor</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>in_tensor_dim_x</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>in_tensor_dim_y</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>in_tensor_ch</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const q7_t *</td>          <td class="paramname"><span class="paramname"><em>ker_weight</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>out_tensor_ch</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>ker_dim_x</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>ker_dim_y</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>pad_x</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>pad_y</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>stride_x</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>stride_y</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>pre_rshift</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>out_scale</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>post_rshift</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">q15_t *</td>          <td class="paramname"><span class="paramname"><em>out_tensor</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>out_tensor_dim_x</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>out_tensor_dim_y</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">q15_t *</td>          <td class="paramname"><span class="paramname"><em>in_tmp_buf</em></span>&#160;)</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span><span class="mlabel">static</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p><code>#include &lt;<a class="el" href="hpm__math_8h.html">middleware/hpm_math/hpm_math.h</a>&gt;</code></p>

<p>This function performs fast convolution for signed 8-bit integer inputs and signed 16-bit integer outputs in any x and y dimensions with symmetric quantization on the outputs. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor</td><td>pointer of the input vector </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor_dim_x</td><td>x dimension of the input tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor_dim_y</td><td>y dimension of the input tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor_ch</td><td>number of input tensor channels </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">ker_weight</td><td>pointer of kernel weights </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_tensor_ch</td><td>number of output tensor channels </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">ker_dim_x</td><td>x dimension of the filter kernel </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">ker_dim_y</td><td>y dimension of the filter kernel </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">pad_x</td><td>padding size in the x dimension </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">pad_y</td><td>padding size in the y dimension </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">stride_x</td><td>convolution stride in the x dimension </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">stride_y</td><td>convolution stride in the y dimension </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">pre_rshift</td><td>right shift amount for the output </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_scale</td><td>value of scaling for the output </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">post_rshift</td><td>right shift amount for the output </td></tr>
    <tr><td class="paramdir">[out]</td><td class="paramname">out_tensor</td><td>pointer of the output tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_tensor_dim_x</td><td>x dimension of the output tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_tensor_dim_y</td><td>y dimension of the output tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tmp_buf</td><td>temporary buffer for the input tensor. It is required when -mext-dsp or -mext-vector enabled and its size must be equal to "2 * in_tensor_ch * ker_dim_x
                                     * ker_dim_y". </td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>This function returns 0 on success; otherwise, it returns -1 if its inputs do not meet the constraints that in_tensor_ch is a multiple of 4 and out_tensor_ch is a multiple of 2.</dd></dl>
<dl class="section note"><dt>Note</dt><dd>The outputs will be 2-stage shifted before being stored, i.e., out = ((out &gt;&gt; pre_rshift) *out_scale) &gt;&gt; post_rshift. </dd></dl>

</div>
</div>
<a id="gafcbbcd4692c657df2ab93d7529fc0adb" name="gafcbbcd4692c657df2ab93d7529fc0adb"></a>
<h2 class="memtitle"><span class="permalink"><a href="#gafcbbcd4692c657df2ab93d7529fc0adb">&#9670;&#160;</a></span>hpm_nn_conv_HWC_s8_s8_s8_asym_bias_any()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">static int32_t hpm_nn_conv_HWC_s8_s8_s8_asym_bias_any </td>
          <td>(</td>
          <td class="paramtype">const q7_t *</td>          <td class="paramname"><span class="paramname"><em>in_tensor</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>in_tensor_dim_x</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>in_tensor_dim_y</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>in_tensor_ch</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>in_tensor_group</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const q7_t *</td>          <td class="paramname"><span class="paramname"><em>ker_weight</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>out_tensor_ch</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>ker_dim_x</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>ker_dim_y</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>pad_x</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>pad_y</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>stride_x</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>stride_y</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const int32_t *</td>          <td class="paramname"><span class="paramname"><em>bias</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">q7_t *</td>          <td class="paramname"><span class="paramname"><em>out_tensor</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const int32_t *</td>          <td class="paramname"><span class="paramname"><em>out_shift</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const int32_t *</td>          <td class="paramname"><span class="paramname"><em>out_scale</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const int32_t</td>          <td class="paramname"><span class="paramname"><em>out_offset</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const int32_t</td>          <td class="paramname"><span class="paramname"><em>in_offset</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const int32_t</td>          <td class="paramname"><span class="paramname"><em>act_min</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const int32_t</td>          <td class="paramname"><span class="paramname"><em>act_max</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>out_tensor_dim_x</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>out_tensor_dim_y</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">q15_t *</td>          <td class="paramname"><span class="paramname"><em>in_tmp_buf</em></span>&#160;)</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span><span class="mlabel">static</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p><code>#include &lt;<a class="el" href="hpm__math_8h.html">middleware/hpm_math/hpm_math.h</a>&gt;</code></p>

<p>This function performs convolution for signed 8-bit integer inputs/outputs in any x and y dimensions with asymmetric quantization on the outputs. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor</td><td>pointer of the input tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor_dim_x</td><td>x dimension of the input tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor_dim_y</td><td>y dimension of the input tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor_ch</td><td>number of input tensor channels </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor_group</td><td>number of input tensor groups </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">ker_weight</td><td>pointer of kernel weights </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_tensor_ch</td><td>number of output tensor channels </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">ker_dim_x</td><td>x dimension of the filter kernel </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">ker_dim_y</td><td>y dimension of the filter kernel </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">pad_x</td><td>padding size in the x dimension </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">pad_y</td><td>padding size in the y dimension </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">stride_x</td><td>convolution stride in the x dimension </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">stride_y</td><td>convolution stride in the y dimension </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">bias</td><td>pointer of the bias vector </td></tr>
    <tr><td class="paramdir">[out]</td><td class="paramname">out_tensor</td><td>pointer of the output tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_shift</td><td>pointer of the shift vector for output tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_scale</td><td>pointer of the scaling vector for output tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_offset</td><td>value of offset for the output tensor. It should be in the range of -128 to 127. </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_offset</td><td>value of offset for the input tensor It should be in the range of -127 to 128. </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">act_min</td><td>minimum value to clip out the ouput tensor. It should be in the range of -128 to 127. </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">act_max</td><td>maximum value to clip out the ouput tensor. It should be in the range of -128 to 127. </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_tensor_dim_x</td><td>x dimension of the output tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_tensor_dim_y</td><td>y dimension of the output tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tmp_buf</td><td>temporary buffer for the input tensor. It is required when -mext-dsp or -mext-vector is enabled and its needed size could be get by calling riscv_nn_conv_HWC_s8_s8_s8_asym_bias_any_get_buffer_size. </td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>This function only returns 0. </dd></dl>

</div>
</div>
<a id="ga89509f5499197a1f65bc7e29ff471f2a" name="ga89509f5499197a1f65bc7e29ff471f2a"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ga89509f5499197a1f65bc7e29ff471f2a">&#9670;&#160;</a></span>hpm_nn_conv_HWC_s8_s8_s8_asym_bias_any_get_buffer_size()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">static int32_t hpm_nn_conv_HWC_s8_s8_s8_asym_bias_any_get_buffer_size </td>
          <td>(</td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>in_tensor_ch</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>ker_dim_x</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>ker_dim_y</em></span>&#160;)</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span><span class="mlabel">static</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p><code>#include &lt;<a class="el" href="hpm__math_8h.html">middleware/hpm_math/hpm_math.h</a>&gt;</code></p>

<p>This function is used to get the needed size, in bytes, by the input temporary buffer of riscv_nn_conv_HWC_s8_s8_s8_asym_bias_any. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor_ch</td><td>number of input tensor channels </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">ker_dim_x</td><td>x dimension of the filter kernel </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">ker_dim_y</td><td>y dimension of the filter kernel </td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>This function returns the needed size by the temporary buffer. </dd></dl>

</div>
</div>
<a id="ga48801812baf4ac44d8f420656e0d344e" name="ga48801812baf4ac44d8f420656e0d344e"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ga48801812baf4ac44d8f420656e0d344e">&#9670;&#160;</a></span>hpm_nn_conv_HWC_s8_s8_s8_RGB_sft_bias()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">static int32_t hpm_nn_conv_HWC_s8_s8_s8_RGB_sft_bias </td>
          <td>(</td>
          <td class="paramtype">const q7_t *</td>          <td class="paramname"><span class="paramname"><em>in_tensor</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>in_tensor_dim</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const q7_t *</td>          <td class="paramname"><span class="paramname"><em>ker_weight</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>out_tensor_ch</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>ker_dim</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>pad</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>stride</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const q7_t *</td>          <td class="paramname"><span class="paramname"><em>bias</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>bias_lshift</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>out_rshift</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">q7_t *</td>          <td class="paramname"><span class="paramname"><em>out_tensor</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>out_tensor_dim</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">q15_t *</td>          <td class="paramname"><span class="paramname"><em>in_tmp_buf</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">q7_t *</td>          <td class="paramname"><span class="paramname"><em>tmp_buf</em></span>&#160;)</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span><span class="mlabel">static</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p><code>#include &lt;<a class="el" href="hpm__math_8h.html">middleware/hpm_math/hpm_math.h</a>&gt;</code></p>

<p>This function performs signed 8-bit integer convolution for RGB images with shift-based quantization on the outputs. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor</td><td>pointer of the input tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor_dim</td><td>input tensor dimension </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">ker_weight</td><td>pointer of kernel weights </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_tensor_ch</td><td>number of output tensor channels </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">ker_dim</td><td>dimension of the filter kernel </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">pad</td><td>padding size </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">stride</td><td>convolution stride </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">bias</td><td>pointer of the bias vector </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">bias_lshift</td><td>left shift amount for the bias </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_rshift</td><td>right shift amount for the output </td></tr>
    <tr><td class="paramdir">[out]</td><td class="paramname">out_tensor</td><td>pointer of the output tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_tensor_dim</td><td>dimension of the output tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tmp_buf</td><td>temporary buffer for the input tensor. It is required when -mext-dsp or -mext-vector enabled and its size must be equal to "2 *
                                 (3 * ker_dim * ker_dim + 1)". </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">tmp_buf</td><td>temporary buffer for kernel weights. It is required when -mext-vector enabled and its size must be "out_tensor_ch * (3 * ker_dim *
                                 ker_dim + 1)". </td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>This function only returns 0.</dd></dl>
<p><b>Example:</b> </p><div class="fragment"><div class="line"><span class="comment">//Convolve a 28x28x3 input tensor with a 5x5 kernel and generate a 24x24x20</span></div>
<div class="line"><span class="comment">//output tensor. Let both dimensions padding be 0 and their stride be 1.</span></div>
<div class="line"> </div>
<div class="line"><span class="preprocessor">#define IN_DIM 28</span></div>
<div class="line"><span class="preprocessor">#define KER_DIM 5</span></div>
<div class="line"><span class="preprocessor">#define PAD 0</span></div>
<div class="line"><span class="preprocessor">#define STRIDE 1</span></div>
<div class="line"><span class="preprocessor">#define BIAS_LSHIFT 6</span></div>
<div class="line"><span class="preprocessor">#define OUT_RSHIFT 10</span></div>
<div class="line"><span class="preprocessor">#define OUT_CH 20</span></div>
<div class="line"><span class="preprocessor">#define OUT_DIM 24</span></div>
<div class="line"> </div>
<div class="line">q7_t in_data[3 * IN_DIM * IN_DIM] = {...};</div>
<div class="line">q7_t weight[3 * KER_DIM * KER_DIM * OUT_CH] = {...};</div>
<div class="line">q7_t <a class="code hl_variable" href="group__nnfullyconnect.html#ga602e28fc157c370e73e4df5712f9df84">bias</a>[OUT_CH] = {...};</div>
<div class="line">q15_t <a class="code hl_variable" href="group__nnfullyconnect.html#ga4972f5e62722e743bc2e14d86e130148">in_tmp_buf</a>[2 * 3 * KER_DIM * KER_DIM] = {0};</div>
<div class="line">q7_t out_data[OUT_CH * OUT_DIM * OUT_DIM];</div>
<div class="line"> </div>
<div class="line">riscv_nn_conv_HWC_s8_s8_s8_RGB_sft_bias(in_data, IN_DIM, weight, OUT_CH,</div>
<div class="line">    KER_DIM, PAD, STRIDE, <a class="code hl_variable" href="group__nnfullyconnect.html#ga602e28fc157c370e73e4df5712f9df84">bias</a>, BIAS_LSHIFT, OUT_RSHIFT, out_data, OUT_DIM,</div>
<div class="line">    <a class="code hl_variable" href="group__nnfullyconnect.html#ga4972f5e62722e743bc2e14d86e130148">in_tmp_buf</a>, NULL);</div>
</div><!-- fragment --> 
</div>
</div>
<a id="gacb280da3e5ee9dae757454a6f9fde55a" name="gacb280da3e5ee9dae757454a6f9fde55a"></a>
<h2 class="memtitle"><span class="permalink"><a href="#gacb280da3e5ee9dae757454a6f9fde55a">&#9670;&#160;</a></span>hpm_nn_conv_HWC_s8_s8_s8_RGB_sft_bias_fast()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">static int32_t hpm_nn_conv_HWC_s8_s8_s8_RGB_sft_bias_fast </td>
          <td>(</td>
          <td class="paramtype">const q7_t *</td>          <td class="paramname"><span class="paramname"><em>in_tensor</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>in_tensor_dim</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const q7_t *</td>          <td class="paramname"><span class="paramname"><em>ker_weight</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>out_tensor_ch</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>ker_dim</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>pad</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>stride</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const q7_t *</td>          <td class="paramname"><span class="paramname"><em>bias</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>bias_lshift</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>out_rshift</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">q7_t *</td>          <td class="paramname"><span class="paramname"><em>out_tensor</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>out_tensor_dim</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">q15_t *</td>          <td class="paramname"><span class="paramname"><em>in_tmp_buf</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">q15_t *</td>          <td class="paramname"><span class="paramname"><em>wt_tmp_buf</em></span>&#160;)</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span><span class="mlabel">static</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p><code>#include &lt;<a class="el" href="hpm__math_8h.html">middleware/hpm_math/hpm_math.h</a>&gt;</code></p>

<p>This function performs fast signed 8-bit integer convolution for RGB images with shift-based quantization on the outputs. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor</td><td>pointer of the input tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor_dim</td><td>dimension of the input tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">ker_weight</td><td>pointer of kernel weights </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_tensor_ch</td><td>number of output tensor channels </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">ker_dim</td><td>dimension of the filter kernel </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">pad</td><td>padding size </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">stride</td><td>convolution stride </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">bias</td><td>pointer of the bias vector </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">bias_lshift</td><td>left shift amount for the bias </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_rshift</td><td>right shift amount for the output </td></tr>
    <tr><td class="paramdir">[out]</td><td class="paramname">out_tensor</td><td>pointer of the output tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_tensor_dim</td><td>dimension of the output tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tmp_buf</td><td>temporary buffer for the input tensor. It is required when -mext-dsp or -mext-vector enabled and its size must be "2 * (3 *
                                 ker_dim * ker_dim + 1)". </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">wt_tmp_buf</td><td>temporary buffer for kernel weights. It is required when -mext-dsp or -mext-vector enabled and its size must be "out_tensor_ch *
                                 (3 * ker_dim * ker_dim + 1)". </td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>This function only returns 0.</dd></dl>
<p><b>Example:</b> </p><div class="fragment"><div class="line"><span class="comment">//Convolve a 28x28x3 input tensor with a 5x5 kernel and generate a 24x24x20</span></div>
<div class="line"><span class="comment">//output tensor. Let both dimensions padding be 0 and their stride be 1.</span></div>
<div class="line"> </div>
<div class="line"><span class="preprocessor">#define IN_DIM 28</span></div>
<div class="line"><span class="preprocessor">#define KER_DIM 5</span></div>
<div class="line"><span class="preprocessor">#define PAD 0</span></div>
<div class="line"><span class="preprocessor">#define STRIDE 1</span></div>
<div class="line"><span class="preprocessor">#define BIAS_LSHIFT 6</span></div>
<div class="line"><span class="preprocessor">#define OUT_RSHIFT 10</span></div>
<div class="line"><span class="preprocessor">#define OUT_CH 20</span></div>
<div class="line"><span class="preprocessor">#define OUT_DIM 24</span></div>
<div class="line"> </div>
<div class="line">q7_t in_data[3 * IN_DIM * IN_DIM] = {...};</div>
<div class="line">q7_t weight[3 * KER_DIM * KER_DIM * OUT_CH] = {...};</div>
<div class="line">q7_t <a class="code hl_variable" href="group__nnfullyconnect.html#ga602e28fc157c370e73e4df5712f9df84">bias</a>[OUT_CH] = {...};</div>
<div class="line">q15_t <a class="code hl_variable" href="group__nnfullyconnect.html#ga4972f5e62722e743bc2e14d86e130148">in_tmp_buf</a>[2 * (3 * KER_DIM * KER_DIM + 1)] = {0};</div>
<div class="line">q15_t wt_tmp_buf[OUT_CH * (3 * KER_DIM * KER_DIM + 1)];</div>
<div class="line">q7_t out_data[OUT_CH * OUT_DIM * OUT_DIM];</div>
<div class="line"> </div>
<div class="line">riscv_nn_conv_HWC_s8_s8_s8_RGB_sft_bias_fast(in_data, IN_DIM, weight,</div>
<div class="line">    OUT_CH, KER_DIM, PAD, STRIDE, <a class="code hl_variable" href="group__nnfullyconnect.html#ga602e28fc157c370e73e4df5712f9df84">bias</a>, BIAS_LSHIFT, OUT_RSHIFT, out_data,</div>
<div class="line">    OUT_DIM, <a class="code hl_variable" href="group__nnfullyconnect.html#ga4972f5e62722e743bc2e14d86e130148">in_tmp_buf</a>, wt_tmp_buf);</div>
</div><!-- fragment --> 
</div>
</div>
<a id="gaeed17db639b9ce3a896bc2bfeaaeb8ed" name="gaeed17db639b9ce3a896bc2bfeaaeb8ed"></a>
<h2 class="memtitle"><span class="permalink"><a href="#gaeed17db639b9ce3a896bc2bfeaaeb8ed">&#9670;&#160;</a></span>hpm_nn_conv_HWC_s8_s8_s8_RGB_sym_bias_fast()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">static int32_t hpm_nn_conv_HWC_s8_s8_s8_RGB_sym_bias_fast </td>
          <td>(</td>
          <td class="paramtype">const q7_t *</td>          <td class="paramname"><span class="paramname"><em>in_tensor</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>in_tensor_dim</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const q7_t *</td>          <td class="paramname"><span class="paramname"><em>ker_weight</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>out_tensor_ch</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>ker_dim</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>pad</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>stride</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const q31_t *</td>          <td class="paramname"><span class="paramname"><em>bias</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>pre_rshift</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>out_scale</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>post_rshift</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">q7_t *</td>          <td class="paramname"><span class="paramname"><em>out_tensor</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>out_tensor_dim</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">q15_t *</td>          <td class="paramname"><span class="paramname"><em>in_tmp_buf</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">q15_t *</td>          <td class="paramname"><span class="paramname"><em>wt_tmp_buf</em></span>&#160;)</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span><span class="mlabel">static</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p><code>#include &lt;<a class="el" href="hpm__math_8h.html">middleware/hpm_math/hpm_math.h</a>&gt;</code></p>

<p>This function performs fast convolution on RGB images for signed 8-bit integer inputs/outputs with bias inputs and symmetric quantization on the outputs. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor</td><td>pointer of the input tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor_dim</td><td>input tensor dimension </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">ker_weight</td><td>pointer of kernel weights </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_tensor_ch</td><td>number of output tensor channels </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">ker_dim</td><td>dimension of the filter kernel </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">pad</td><td>padding size </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">stride</td><td>convolution stride </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">bias</td><td>pointer of the bias vector </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">pre_rshift</td><td>right shift amount for the output </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_scale</td><td>value of scaling for the output </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">post_rshift</td><td>right shift amount for the output </td></tr>
    <tr><td class="paramdir">[out]</td><td class="paramname">out_tensor</td><td>pointer of the output tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_tensor_dim</td><td>dimension of the output tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tmp_buf</td><td>temporary buffer for the input tensor. It is required when -mext-dsp or -mext-vector enabled and its size must be "2 * (3 *
                                 ker_dim * ker_dim + 1)". </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">wt_tmp_buf</td><td>temporary buffer for kernel weights. It is required when -mext-dsp or -mext-vector enabled and its size must be "out_tensor_ch *
                                 (3 * ker_dim * ker_dim + 1)". </td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>This function only returns 0.</dd></dl>
<dl class="section note"><dt>Note</dt><dd>The outputs will be 2-stage shifted before being stored, i.e., out = ((out &gt;&gt; pre_rshift) *out_scale) &gt;&gt; post_rshift. </dd></dl>

</div>
</div>
<a id="gac66363c7f5934113644361412bcf3afc" name="gac66363c7f5934113644361412bcf3afc"></a>
<h2 class="memtitle"><span class="permalink"><a href="#gac66363c7f5934113644361412bcf3afc">&#9670;&#160;</a></span>hpm_nn_conv_HWC_s8_s8_s8_RGB_sym_fast()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">static int32_t hpm_nn_conv_HWC_s8_s8_s8_RGB_sym_fast </td>
          <td>(</td>
          <td class="paramtype">const q7_t *</td>          <td class="paramname"><span class="paramname"><em>in_tensor</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>in_tensor_dim</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const q7_t *</td>          <td class="paramname"><span class="paramname"><em>ker_weight</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>out_tensor_ch</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>ker_dim</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>pad</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>stride</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>pre_rshift</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>out_scale</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>post_rshift</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">q7_t *</td>          <td class="paramname"><span class="paramname"><em>out_tensor</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>out_tensor_dim</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">q15_t *</td>          <td class="paramname"><span class="paramname"><em>in_tmp_buf</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">q15_t *</td>          <td class="paramname"><span class="paramname"><em>wt_tmp_buf</em></span>&#160;)</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span><span class="mlabel">static</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p><code>#include &lt;<a class="el" href="hpm__math_8h.html">middleware/hpm_math/hpm_math.h</a>&gt;</code></p>

<p>This function performs fast convolution on RGB images for signed 8-bit integer inputs/outputs with symmetric quantization on the outputs. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor</td><td>pointer of the input tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor_dim</td><td>input tensor dimension </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">ker_weight</td><td>pointer of kernel weights </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_tensor_ch</td><td>number of output tensor channels </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">ker_dim</td><td>dimension of the filter kernel </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">pad</td><td>padding size </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">stride</td><td>convolution stride </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">pre_rshift</td><td>right shift amount for the output </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_scale</td><td>value of scaling for the output </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">post_rshift</td><td>right shift amount for the output </td></tr>
    <tr><td class="paramdir">[out]</td><td class="paramname">out_tensor</td><td>pointer of the output tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_tensor_dim</td><td>dimension of the output tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tmp_buf</td><td>temporary buffer for the input tensor. It is required when -mext-dsp or -mext-vector enabled and its size must be "2 * (3 *
                                 ker_dim * ker_dim + 1)". </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">wt_tmp_buf</td><td>temporary buffer for kernel weights. It is required when -mext-dsp or -mext-vector enabled and its size must be "out_tensor_ch *
                                 (3 * ker_dim * ker_dim + 1)". </td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>This function only returns 0.</dd></dl>
<dl class="section note"><dt>Note</dt><dd>The outputs will be 2-stage shifted before being stored, i.e., out = ((out &gt;&gt; pre_rshift) *out_scale) &gt;&gt; post_rshift. </dd></dl>

</div>
</div>
<a id="ga4289d8b8bf7de39fe2ec6716aeb1fb21" name="ga4289d8b8bf7de39fe2ec6716aeb1fb21"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ga4289d8b8bf7de39fe2ec6716aeb1fb21">&#9670;&#160;</a></span>hpm_nn_conv_HWC_s8_s8_s8_sft_bias()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">static int32_t hpm_nn_conv_HWC_s8_s8_s8_sft_bias </td>
          <td>(</td>
          <td class="paramtype">const q7_t *</td>          <td class="paramname"><span class="paramname"><em>in_tensor</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>in_tensor_dim</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>in_tensor_ch</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const q7_t *</td>          <td class="paramname"><span class="paramname"><em>ker_weight</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>out_tensor_ch</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>ker_dim</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>pad</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>stride</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const q7_t *</td>          <td class="paramname"><span class="paramname"><em>bias</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>bias_lshift</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>out_rshift</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">q7_t *</td>          <td class="paramname"><span class="paramname"><em>out_tensor</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>out_tensor_dim</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">q15_t *</td>          <td class="paramname"><span class="paramname"><em>in_tmp_buf</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">q7_t *</td>          <td class="paramname"><span class="paramname"><em>tmp_buf</em></span>&#160;)</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span><span class="mlabel">static</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p><code>#include &lt;<a class="el" href="hpm__math_8h.html">middleware/hpm_math/hpm_math.h</a>&gt;</code></p>

<p>This function performs signed 8-bit integer convolution with shift-based quantization on the outputs. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor</td><td>pointer of the input tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor_dim</td><td>dimension of the input tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor_ch</td><td>number of input tensor channels </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">ker_weight</td><td>pointer of kernel weights </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_tensor_ch</td><td>number of output tensor channels </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">ker_dim</td><td>dimension of the filter kernel </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">pad</td><td>padding size </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">stride</td><td>convolution stride </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">bias</td><td>pointer of the bias vector </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">bias_lshift</td><td>left shift amount for the bias </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_rshift</td><td>right shift amount for the output </td></tr>
    <tr><td class="paramdir">[out]</td><td class="paramname">out_tensor</td><td>pointer of the output tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_tensor_dim</td><td>dimension of the output tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tmp_buf</td><td>temporary buffer for input tensor. It is required when -mext-dsp or -mext-vector is enabled and its size must be equal to "2 *
                                 in_tensor_ch * ker_dim * ker_dim". </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">tmp_buf</td><td>dummy </td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>This function only returns 0.</dd></dl>
<p><b>Example:</b> </p><div class="fragment"><div class="line"><span class="comment">//Convolve a 28x28x1 input tensor with a 5x5 kernel and generate a 24x24x20</span></div>
<div class="line"><span class="comment">//output tensor. Let both dimensions padding be 0 and their stride be 1.</span></div>
<div class="line"> </div>
<div class="line"><span class="preprocessor">#define IN_DIM 28</span></div>
<div class="line"><span class="preprocessor">#define IN_CH 1</span></div>
<div class="line"><span class="preprocessor">#define KER_DIM 5</span></div>
<div class="line"><span class="preprocessor">#define PAD 0</span></div>
<div class="line"><span class="preprocessor">#define STRIDE 1</span></div>
<div class="line"><span class="preprocessor">#define BIAS_LSHIFT 6</span></div>
<div class="line"><span class="preprocessor">#define OUT_RSHIFT 10</span></div>
<div class="line"><span class="preprocessor">#define OUT_CH 20</span></div>
<div class="line"><span class="preprocessor">#define OUT_DIM 24</span></div>
<div class="line"> </div>
<div class="line">q7_t in_data[IN_CH * IN_DIM * IN_DIM] = {...};</div>
<div class="line">q7_t weight[IN_CH * KER_DIM * KER_DIM * OUT_CH] = {...};</div>
<div class="line">q7_t <a class="code hl_variable" href="group__nnfullyconnect.html#ga602e28fc157c370e73e4df5712f9df84">bias</a>[OUT_CH] = {...};</div>
<div class="line">q15_t <a class="code hl_variable" href="group__nnfullyconnect.html#ga4972f5e62722e743bc2e14d86e130148">in_tmp_buf</a>[2 * IN_CH * KER_DIM * KER_DIM] = {0};</div>
<div class="line">q7_t out_data[OUT_CH * OUT_DIM * OUT_DIM];</div>
<div class="line"> </div>
<div class="line">riscv_nn_conv_HWC_s8_s8_s8_sft_bias(in_data, IN_DIM, IN_CH, weight, OUT_CH,</div>
<div class="line">    KER_DIM, PAD, STRIDE, <a class="code hl_variable" href="group__nnfullyconnect.html#ga602e28fc157c370e73e4df5712f9df84">bias</a>, BIAS_LSHIFT, OUT_RSHIFT, out_data, OUT_DIM,</div>
<div class="line">    <a class="code hl_variable" href="group__nnfullyconnect.html#ga4972f5e62722e743bc2e14d86e130148">in_tmp_buf</a>, NULL);</div>
</div><!-- fragment --> 
</div>
</div>
<a id="gaa3bea4019638b22edc46a625f5cf7cce" name="gaa3bea4019638b22edc46a625f5cf7cce"></a>
<h2 class="memtitle"><span class="permalink"><a href="#gaa3bea4019638b22edc46a625f5cf7cce">&#9670;&#160;</a></span>hpm_nn_conv_HWC_s8_s8_s8_sft_bias_any()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">static void hpm_nn_conv_HWC_s8_s8_s8_sft_bias_any </td>
          <td>(</td>
          <td class="paramtype">const q7_t *</td>          <td class="paramname"><span class="paramname"><em>in_tensor</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>in_tensor_dim_x</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>in_tensor_dim_y</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>in_tensor_ch</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const q7_t *</td>          <td class="paramname"><span class="paramname"><em>ker_weight</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>out_tensor_ch</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>ker_dim_x</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>ker_dim_y</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>pad_x</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>pad_y</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>stride_x</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>stride_y</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const q7_t *</td>          <td class="paramname"><span class="paramname"><em>bias</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>bias_lshift</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>out_rshift</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">q7_t *</td>          <td class="paramname"><span class="paramname"><em>out_tensor</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>out_tensor_dim_x</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>out_tensor_dim_y</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">q15_t *</td>          <td class="paramname"><span class="paramname"><em>in_tmp_buf</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">q7_t *</td>          <td class="paramname"><span class="paramname"><em>tmp_buf</em></span>&#160;)</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span><span class="mlabel">static</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p><code>#include &lt;<a class="el" href="hpm__math_8h.html">middleware/hpm_math/hpm_math.h</a>&gt;</code></p>

<p>This function performs signed 8-bit integer convolution in any x and y dimensions with shift-based quantization on the outputs. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor</td><td>pointer of the input tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor_dim_x</td><td>x dimension of the input tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor_dim_y</td><td>y dimension of the input tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor_ch</td><td>number of input tensor channels </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">ker_weight</td><td>pointer of kernel weights </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_tensor_ch</td><td>number of output tensor channels </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">ker_dim_x</td><td>x dimension of the filter kernel </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">ker_dim_y</td><td>y dimension of the filter kernel </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">pad_x</td><td>padding size in the x dimension </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">pad_y</td><td>padding size in the y dimension </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">stride_x</td><td>convolution stride in the x dimension </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">stride_y</td><td>convolution stride in the y dimension </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">bias</td><td>pointer of the bias vector </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">bias_lshift</td><td>left shift amount for the bias </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_rshift</td><td>right shift amount for the output </td></tr>
    <tr><td class="paramdir">[out]</td><td class="paramname">out_tensor</td><td>pointer of the output tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_tensor_dim_x</td><td>x dimension of the output tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_tensor_dim_y</td><td>y dimension of the output tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tmp_buf</td><td>temporary buffer for the input tensor. It is required when -mext-dsp or -mext-vector is enabled and its size must be equal to "2 * in_tensor_ch *
                                     ker_dim_x * ker_dim_y". </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">tmp_buf</td><td>dummy</td></tr>
  </table>
  </dd>
</dl>
<p><b>Example:</b> </p><div class="fragment"><div class="line"><span class="comment">//Convolve a 160x120x3 input tensor with a 3x5 kernel and generate a 80x59x5</span></div>
<div class="line"><span class="comment">//output tensor. Let both dimensions padding be 1 and their stride be 2.</span></div>
<div class="line"> </div>
<div class="line"><span class="preprocessor">#define IN_X 160</span></div>
<div class="line"><span class="preprocessor">#define IN_Y 120</span></div>
<div class="line"><span class="preprocessor">#define IN_CH 3</span></div>
<div class="line"><span class="preprocessor">#define OUT_CH 5</span></div>
<div class="line"><span class="preprocessor">#define KER_DIM_X 3</span></div>
<div class="line"><span class="preprocessor">#define KER_DIM_Y 5</span></div>
<div class="line"><span class="preprocessor">#define PAD_X 1</span></div>
<div class="line"><span class="preprocessor">#define PAD_Y 1</span></div>
<div class="line"><span class="preprocessor">#define STRIDE_X 2</span></div>
<div class="line"><span class="preprocessor">#define STRIDE_Y 2</span></div>
<div class="line"><span class="preprocessor">#define BIAS_LSHIFT 6</span></div>
<div class="line"><span class="preprocessor">#define OUT_RSHIFT 9</span></div>
<div class="line"><span class="preprocessor">#define OUT_X 40</span></div>
<div class="line"><span class="preprocessor">#define OUT_Y 30</span></div>
<div class="line"> </div>
<div class="line">q7_t in_data[IN_CH * IN_X * IN_Y] = {...};</div>
<div class="line">q7_t weight[IN_CH * KER_DIM_X * KER_DIM_Y * OUT_CH] = {...};</div>
<div class="line">q7_t <a class="code hl_variable" href="group__nnfullyconnect.html#ga602e28fc157c370e73e4df5712f9df84">bias</a>[OUT_CH] = {...};</div>
<div class="line">q15_t <a class="code hl_variable" href="group__nnfullyconnect.html#ga4972f5e62722e743bc2e14d86e130148">in_tmp_buf</a>[2 * IN_CH * KER_DIM_X * KER_DIM_Y] = {0};</div>
<div class="line">q7_t out_data[OUT_CH * OUT_X * OUT_Y];</div>
<div class="line"> </div>
<div class="line">riscv_nn_conv_HWC_s8_s8_s8_sft_bias_any(in_data, IN_X, IN_Y , IN_CH, weight,</div>
<div class="line">    OUT_CH, KER_DIM_X, KER_DIM_Y, PAD_X, PAD_Y, STRIDE_X, STRIDE_Y, <a class="code hl_variable" href="group__nnfullyconnect.html#ga602e28fc157c370e73e4df5712f9df84">bias</a>,</div>
<div class="line">    BIAS_LSHIFT, OUT_RSHIFT, out_data, OUT_X, OUT_Y, <a class="code hl_variable" href="group__nnfullyconnect.html#ga4972f5e62722e743bc2e14d86e130148">in_tmp_buf</a>, NULL);</div>
</div><!-- fragment --> 
</div>
</div>
<a id="gad9c7a0bfeedea12c13702a7b85f6045b" name="gad9c7a0bfeedea12c13702a7b85f6045b"></a>
<h2 class="memtitle"><span class="permalink"><a href="#gad9c7a0bfeedea12c13702a7b85f6045b">&#9670;&#160;</a></span>hpm_nn_conv_HWC_s8_s8_s8_sft_bias_fast()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">static int32_t hpm_nn_conv_HWC_s8_s8_s8_sft_bias_fast </td>
          <td>(</td>
          <td class="paramtype">const q7_t *</td>          <td class="paramname"><span class="paramname"><em>in_tensor</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>in_tensor_dim</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>in_tensor_ch</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const q7_t *</td>          <td class="paramname"><span class="paramname"><em>ker_weight</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>out_tensor_ch</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>ker_dim</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>pad</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>stride</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const q7_t *</td>          <td class="paramname"><span class="paramname"><em>bias</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>bias_lshift</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>out_rshift</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">q7_t *</td>          <td class="paramname"><span class="paramname"><em>out_tensor</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>out_tensor_dim</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">q15_t *</td>          <td class="paramname"><span class="paramname"><em>in_tmp_buf</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">q7_t *</td>          <td class="paramname"><span class="paramname"><em>tmp_buf</em></span>&#160;)</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span><span class="mlabel">static</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p><code>#include &lt;<a class="el" href="hpm__math_8h.html">middleware/hpm_math/hpm_math.h</a>&gt;</code></p>

<p>This function performs fast signed 8-bit integer convolution with shift-based quantization on the outputs. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor</td><td>pointer of the input tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor_dim</td><td>dimension of the input tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor_ch</td><td>number of input tensor channels </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">ker_weight</td><td>pointer of kernel weights </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_tensor_ch</td><td>number of output tensor channels </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">ker_dim</td><td>dimension of the filter kernel </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">pad</td><td>padding size </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">stride</td><td>convolution stride </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">bias</td><td>pointer of the bias vector </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">bias_lshift</td><td>left shift amount for the bias </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_rshift</td><td>right shift amount for the output </td></tr>
    <tr><td class="paramdir">[out]</td><td class="paramname">out_tensor</td><td>pointer of the output tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_tensor_dim</td><td>dimension of the output tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tmp_buf</td><td>temporary buffer for the input tensor. It is required when -mext-dsp or -mext-vector enabled and its size must be equal to "2 *
                                 in_tensor_ch * ker_dim * ker_dim". </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">tmp_buf</td><td>dummy </td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>This function returns 0 on success; otherwise, it returns -1 if its inputs do not meet the constraints that in_tensor_ch is a multiple of 4 and out_tensor_ch is a multiple of 2.</dd></dl>
<p><b>Example:</b> </p><div class="fragment"><div class="line"><span class="comment">//Convolve a 12x12x20 input tensor with a 5x5 kernel and generate a 8x8x50</span></div>
<div class="line"><span class="comment">//output tensor. Let both dimensions padding be 0 and their stride be 1.</span></div>
<div class="line"> </div>
<div class="line"><span class="preprocessor">#define IN_DIM 12</span></div>
<div class="line"><span class="preprocessor">#define IN_CH 20</span></div>
<div class="line"><span class="preprocessor">#define KER_DIM 5</span></div>
<div class="line"><span class="preprocessor">#define PAD 0</span></div>
<div class="line"><span class="preprocessor">#define STRIDE 1</span></div>
<div class="line"><span class="preprocessor">#define BIAS_LSHIFT 6</span></div>
<div class="line"><span class="preprocessor">#define OUT_RSHIFT 10</span></div>
<div class="line"><span class="preprocessor">#define OUT_CH 50</span></div>
<div class="line"><span class="preprocessor">#define OUT_DIM 8</span></div>
<div class="line"> </div>
<div class="line">q7_t in_data[IN_CH * IN_DIM * IN_DIM] = {...};</div>
<div class="line">q7_t weight[IN_CH * KER_DIM * KER_DIM * OUT_CH] = {...};</div>
<div class="line">q7_t <a class="code hl_variable" href="group__nnfullyconnect.html#ga602e28fc157c370e73e4df5712f9df84">bias</a>[OUT_CH] = {...};</div>
<div class="line">q15_t <a class="code hl_variable" href="group__nnfullyconnect.html#ga4972f5e62722e743bc2e14d86e130148">in_tmp_buf</a>[2 * IN_CH * KER_DIM * KER_DIM] = {0};</div>
<div class="line">q7_t out_data[OUT_CH * OUT_DIM * OUT_DIM];</div>
<div class="line"> </div>
<div class="line">riscv_nn_conv_HWC_s8_s8_s8_sft_bias_fast(in_data, IN_DIM, IN_CH, weight,</div>
<div class="line">    OUT_CH, KER_DIM, PAD, STRIDE, <a class="code hl_variable" href="group__nnfullyconnect.html#ga602e28fc157c370e73e4df5712f9df84">bias</a>, BIAS_LSHIFT, OUT_RSHIFT, out_data,</div>
<div class="line">    OUT_DIM, <a class="code hl_variable" href="group__nnfullyconnect.html#ga4972f5e62722e743bc2e14d86e130148">in_tmp_buf</a>, NULL);</div>
</div><!-- fragment --> 
</div>
</div>
<a id="ga6ebc094b7ca8a8eb46c249c165dc0990" name="ga6ebc094b7ca8a8eb46c249c165dc0990"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ga6ebc094b7ca8a8eb46c249c165dc0990">&#9670;&#160;</a></span>hpm_nn_conv_HWC_s8_s8_s8_sft_bias_fast_any()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">static int32_t hpm_nn_conv_HWC_s8_s8_s8_sft_bias_fast_any </td>
          <td>(</td>
          <td class="paramtype">const q7_t *</td>          <td class="paramname"><span class="paramname"><em>in_tensor</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>in_tensor_dim_x</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>in_tensor_dim_y</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>in_tensor_ch</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const q7_t *</td>          <td class="paramname"><span class="paramname"><em>ker_weight</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>out_tensor_ch</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>ker_dim_x</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>ker_dim_y</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>pad_x</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>pad_y</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>stride_x</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>stride_y</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const q7_t *</td>          <td class="paramname"><span class="paramname"><em>bias</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>bias_lshift</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>out_rshift</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">q7_t *</td>          <td class="paramname"><span class="paramname"><em>out_tensor</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>out_tensor_dim_x</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>out_tensor_dim_y</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">q15_t *</td>          <td class="paramname"><span class="paramname"><em>in_tmp_buf</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">q7_t *</td>          <td class="paramname"><span class="paramname"><em>tmp_buf</em></span>&#160;)</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span><span class="mlabel">static</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p><code>#include &lt;<a class="el" href="hpm__math_8h.html">middleware/hpm_math/hpm_math.h</a>&gt;</code></p>

<p>This function performs fast signed 8-bit integer convolution in any x and y dimensions with shift-based quantization on the outputs. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor</td><td>pointer of the input tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor_dim_x</td><td>x dimension of the input tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor_dim_y</td><td>y dimension of the input tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor_ch</td><td>number of input tensor channels </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">ker_weight</td><td>pointer of kernel weights </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_tensor_ch</td><td>number of output tensor channels </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">ker_dim_x</td><td>x dimension of the filter kernel </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">ker_dim_y</td><td>y dimension of the filter kernel </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">pad_x</td><td>padding size in the x dimension </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">pad_y</td><td>padding size in the y dimension </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">stride_x</td><td>convolution stride in the x dimension </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">stride_y</td><td>convolution stride in the y dimension </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">bias</td><td>pointer of the bias vector </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">bias_lshift</td><td>left shift amount for the bias </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_rshift</td><td>right shift amount for the output </td></tr>
    <tr><td class="paramdir">[out]</td><td class="paramname">out_tensor</td><td>pointer of the output tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_tensor_dim_x</td><td>x dimension of the output tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_tensor_dim_y</td><td>y dimension of the output tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tmp_buf</td><td>temporary buffer for the input tensor. It is required when -mext-dsp or -mext-vector enabled and its size must be equal to "2 * in_tensor_ch * ker_dim_x
                                     * ker_dim_y". </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">tmp_buf</td><td>dummy </td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>This function returns 0 on success; otherwise, it returns -1 if its inputs do not meet the constraints that in_tensor_ch is a multiple of 4 and out_tensor_ch is a multiple of 2.</dd></dl>
<p><b>Example:</b> </p><div class="fragment"><div class="line"><span class="comment">//Convolve a 160x120x20 input tensor with a 3x5 kernel and generate a</span></div>
<div class="line"><span class="comment">//80x59x8 output tensor. Let both dimensions padding be 1 and their stride</span></div>
<div class="line"><span class="comment">//be 2.</span></div>
<div class="line"> </div>
<div class="line"><span class="preprocessor">#define IN_X 160</span></div>
<div class="line"><span class="preprocessor">#define IN_Y 120</span></div>
<div class="line"><span class="preprocessor">#define IN_CH 20</span></div>
<div class="line"><span class="preprocessor">#define OUT_CH 8</span></div>
<div class="line"><span class="preprocessor">#define KER_DIM_X 3</span></div>
<div class="line"><span class="preprocessor">#define KER_DIM_Y 5</span></div>
<div class="line"><span class="preprocessor">#define PAD_X 1</span></div>
<div class="line"><span class="preprocessor">#define PAD_Y 1</span></div>
<div class="line"><span class="preprocessor">#define STRIDE_X 2</span></div>
<div class="line"><span class="preprocessor">#define STRIDE_Y 2</span></div>
<div class="line"><span class="preprocessor">#define BIAS_LSHIFT 6</span></div>
<div class="line"><span class="preprocessor">#define OUT_RSHIFT 9</span></div>
<div class="line"><span class="preprocessor">#define OUT_X 80</span></div>
<div class="line"><span class="preprocessor">#define OUT_Y 59</span></div>
<div class="line"> </div>
<div class="line">q7_t in_data[IN_CH * IN_X * IN_Y] = {...};</div>
<div class="line">q7_t weight[IN_CH * KER_DIM_X * KER_DIM_Y * OUT_CH] = {...};</div>
<div class="line">q7_t <a class="code hl_variable" href="group__nnfullyconnect.html#ga602e28fc157c370e73e4df5712f9df84">bias</a>[OUT_CH] = {...};</div>
<div class="line">q15_t <a class="code hl_variable" href="group__nnfullyconnect.html#ga4972f5e62722e743bc2e14d86e130148">in_tmp_buf</a>[2 * IN_CH * KER_DIM_X * KER_DIM_Y] = {0};</div>
<div class="line">q7_t out_data[OUT_CH * OUT_Y * OUT_X];</div>
<div class="line"> </div>
<div class="line">riscv_nn_conv_HWC_s8_s8_s8_sft_bias_fast_any(in_data, IN_W, IN_Y , IN_CH,</div>
<div class="line">    weight, OUT_CH, KER_DIM_X, KER_DIM_Y, PAD_X, PAD_Y, STRIDE_X, STRIDE_Y,</div>
<div class="line">    <a class="code hl_variable" href="group__nnfullyconnect.html#ga602e28fc157c370e73e4df5712f9df84">bias</a>, BIAS_LSHIFT, OUT_RSHIFT, out_data, OUT_X, OUT_Y, <a class="code hl_variable" href="group__nnfullyconnect.html#ga4972f5e62722e743bc2e14d86e130148">in_tmp_buf</a>,</div>
<div class="line">    NULL);</div>
</div><!-- fragment --> 
</div>
</div>
<a id="ga0bc1ef1d72db702cc49be0016a4180f8" name="ga0bc1ef1d72db702cc49be0016a4180f8"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ga0bc1ef1d72db702cc49be0016a4180f8">&#9670;&#160;</a></span>hpm_nn_conv_HWC_s8_s8_s8_sym_bias_fast()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">static int32_t hpm_nn_conv_HWC_s8_s8_s8_sym_bias_fast </td>
          <td>(</td>
          <td class="paramtype">const q7_t *</td>          <td class="paramname"><span class="paramname"><em>in_tensor</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>in_tensor_dim</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>in_tensor_ch</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const q7_t *</td>          <td class="paramname"><span class="paramname"><em>ker_weight</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>out_tensor_ch</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>ker_dim</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>pad</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>stride</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const q31_t *</td>          <td class="paramname"><span class="paramname"><em>bias</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>pre_rshift</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>out_scale</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>post_rshift</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">q7_t *</td>          <td class="paramname"><span class="paramname"><em>out_tensor</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>out_tensor_dim</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">q15_t *</td>          <td class="paramname"><span class="paramname"><em>in_tmp_buf</em></span>&#160;)</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span><span class="mlabel">static</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p><code>#include &lt;<a class="el" href="hpm__math_8h.html">middleware/hpm_math/hpm_math.h</a>&gt;</code></p>

<p>This function performs fast convolution for signed 8-bit integer inputs/outputs with bias inputs and symmetric quantization on the outputs. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor</td><td>pointer of the input vector </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor_dim</td><td>dimension of the input tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor_ch</td><td>number of input tensor channels </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">ker_weight</td><td>pointer of kernel weights </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_tensor_ch</td><td>number of output tensor channels </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">ker_dim</td><td>dimension of the filter kernel </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">pad</td><td>padding size </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">stride</td><td>convolution stride </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">bias</td><td>pointer of the bias vector </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">pre_rshift</td><td>right shift amount for the output </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_scale</td><td>value of scaling for the output </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">post_rshift</td><td>right shift amount for the output </td></tr>
    <tr><td class="paramdir">[out]</td><td class="paramname">out_tensor</td><td>pointer of the output tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_tensor_dim</td><td>dimension of the output tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tmp_buf</td><td>temporary buffer for the input tensor. It is required when -mext-dsp or -mext-vector enabled and its size must be equal to "2 *
                                 in_tensor_ch * ker_dim * ker_dim". </td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>This function returns 0 on success; otherwise, it returns -1 if its inputs do not meet the constraints that in_tensor_ch is a multiple of 4 and out_tensor_ch is a multiple of 2.</dd></dl>
<dl class="section note"><dt>Note</dt><dd>The outputs will be 2-stage shifted before being stored, i.e., out = ((out &gt;&gt; pre_rshift) *out_scale) &gt;&gt; post_rshift. </dd></dl>

</div>
</div>
<a id="gaa733b3587ec4a987004946f46fdf4d8e" name="gaa733b3587ec4a987004946f46fdf4d8e"></a>
<h2 class="memtitle"><span class="permalink"><a href="#gaa733b3587ec4a987004946f46fdf4d8e">&#9670;&#160;</a></span>hpm_nn_conv_HWC_s8_s8_s8_sym_bias_fast_any()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">static int32_t hpm_nn_conv_HWC_s8_s8_s8_sym_bias_fast_any </td>
          <td>(</td>
          <td class="paramtype">const q7_t *</td>          <td class="paramname"><span class="paramname"><em>in_tensor</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>in_tensor_dim_x</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>in_tensor_dim_y</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>in_tensor_ch</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const q7_t *</td>          <td class="paramname"><span class="paramname"><em>ker_weight</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>out_tensor_ch</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>ker_dim_x</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>ker_dim_y</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>pad_x</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>pad_y</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>stride_x</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>stride_y</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const q31_t *</td>          <td class="paramname"><span class="paramname"><em>bias</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>pre_rshift</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>out_scale</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>post_rshift</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">q7_t *</td>          <td class="paramname"><span class="paramname"><em>out_tensor</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>out_tensor_dim_x</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>out_tensor_dim_y</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">q15_t *</td>          <td class="paramname"><span class="paramname"><em>in_tmp_buf</em></span>&#160;)</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span><span class="mlabel">static</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p><code>#include &lt;<a class="el" href="hpm__math_8h.html">middleware/hpm_math/hpm_math.h</a>&gt;</code></p>

<p>This function performs fast convolution for signed 8-bit integer inputs/outputs in any x and y dimensions with bias inputs and symmetric quantization on the outputs. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor</td><td>pointer of the input vector </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor_dim_x</td><td>x dimension of the input tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor_dim_y</td><td>y dimension of the input tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor_ch</td><td>number of input tensor channels </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">ker_weight</td><td>pointer of kernel weights </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_tensor_ch</td><td>number of output tensor channels </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">ker_dim_x</td><td>x dimension of the filter kernel </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">ker_dim_y</td><td>y dimension of the filter kernel </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">pad_x</td><td>padding size in the x dimension </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">pad_y</td><td>padding size in the y dimension </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">stride_x</td><td>convolution stride in the x dimension </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">stride_y</td><td>convolution stride in the y dimension </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">bias</td><td>pointer of the bias vector </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">pre_rshift</td><td>right shift amount for the output </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_scale</td><td>value of scaling for the output </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">post_rshift</td><td>right shift amount for the output </td></tr>
    <tr><td class="paramdir">[out]</td><td class="paramname">out_tensor</td><td>pointer of the output tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_tensor_dim_x</td><td>x dimension of the output tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_tensor_dim_y</td><td>y dimension of the output tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tmp_buf</td><td>temporary buffer for the input tensor. It is required when -mext-dsp or -mext-vector enabled and its size must be equal to "2 * in_tensor_ch * ker_dim_x
                                     * ker_dim_y". </td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>This function returns 0 on success; otherwise, it returns -1 if its inputs do not meet the constraints that in_tensor_ch is a multiple of 4 and out_tensor_ch is a multiple of 2.</dd></dl>
<dl class="section note"><dt>Note</dt><dd>The outputs will be 2-stage shifted before being stored, i.e., out = ((out &gt;&gt; pre_rshift) *out_scale) &gt;&gt; post_rshift. </dd></dl>

</div>
</div>
<a id="gaf85f4310b5b177044f48ea61614aaf10" name="gaf85f4310b5b177044f48ea61614aaf10"></a>
<h2 class="memtitle"><span class="permalink"><a href="#gaf85f4310b5b177044f48ea61614aaf10">&#9670;&#160;</a></span>hpm_nn_conv_HWC_s8_s8_s8_sym_fast()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">static int32_t hpm_nn_conv_HWC_s8_s8_s8_sym_fast </td>
          <td>(</td>
          <td class="paramtype">const q7_t *</td>          <td class="paramname"><span class="paramname"><em>in_tensor</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>in_tensor_dim</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>in_tensor_ch</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const q7_t *</td>          <td class="paramname"><span class="paramname"><em>ker_weight</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>out_tensor_ch</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>ker_dim</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>pad</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>stride</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>pre_rshift</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>out_scale</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>post_rshift</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">q7_t *</td>          <td class="paramname"><span class="paramname"><em>out_tensor</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>out_tensor_dim</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">q15_t *</td>          <td class="paramname"><span class="paramname"><em>in_tmp_buf</em></span>&#160;)</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span><span class="mlabel">static</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p><code>#include &lt;<a class="el" href="hpm__math_8h.html">middleware/hpm_math/hpm_math.h</a>&gt;</code></p>

<p>This function performs fast convolution for signed 8-bit integer inputs/outputs with symmetric quantization on the outputs. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor</td><td>pointer of the input vector </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor_dim</td><td>dimension of the input tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor_ch</td><td>number of input tensor channels </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">ker_weight</td><td>pointer of kernel weights </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_tensor_ch</td><td>number of output tensor channels </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">ker_dim</td><td>dimension of the filter kernel </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">pad</td><td>padding size </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">stride</td><td>convolution stride </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">pre_rshift</td><td>right shift amount for the output </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_scale</td><td>value of scaling for the output </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">post_rshift</td><td>right shift amount for the output </td></tr>
    <tr><td class="paramdir">[out]</td><td class="paramname">out_tensor</td><td>pointer of the output tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_tensor_dim</td><td>dimension of the output tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tmp_buf</td><td>temporary buffer for the input tensor. It is required when -mext-dsp or -mext-vector enabled and its size must be equal to "2 *
                                 in_tensor_ch * ker_dim * ker_dim". </td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>This function returns 0 on success; otherwise, it returns -1 if its inputs do not meet the constraints that in_tensor_ch is a multiple of 4 and out_tensor_ch is a multiple of 2.</dd></dl>
<dl class="section note"><dt>Note</dt><dd>The outputs will be 2-stage shifted before being stored, i.e., out = ((out &gt;&gt; pre_rshift) *out_scale) &gt;&gt; post_rshift. </dd></dl>

</div>
</div>
<a id="gaf210756844a35322033afcc20325eae5" name="gaf210756844a35322033afcc20325eae5"></a>
<h2 class="memtitle"><span class="permalink"><a href="#gaf210756844a35322033afcc20325eae5">&#9670;&#160;</a></span>hpm_nn_conv_HWC_s8_s8_s8_sym_fast_any()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">static int32_t hpm_nn_conv_HWC_s8_s8_s8_sym_fast_any </td>
          <td>(</td>
          <td class="paramtype">const q7_t *</td>          <td class="paramname"><span class="paramname"><em>in_tensor</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>in_tensor_dim_x</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>in_tensor_dim_y</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>in_tensor_ch</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const q7_t *</td>          <td class="paramname"><span class="paramname"><em>ker_weight</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>out_tensor_ch</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>ker_dim_x</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>ker_dim_y</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>pad_x</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>pad_y</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>stride_x</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>stride_y</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>pre_rshift</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>out_scale</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>post_rshift</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">q7_t *</td>          <td class="paramname"><span class="paramname"><em>out_tensor</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>out_tensor_dim_x</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>out_tensor_dim_y</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">q15_t *</td>          <td class="paramname"><span class="paramname"><em>in_tmp_buf</em></span>&#160;)</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span><span class="mlabel">static</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p><code>#include &lt;<a class="el" href="hpm__math_8h.html">middleware/hpm_math/hpm_math.h</a>&gt;</code></p>

<p>This function performs fast convolution for signed 8-bit integer inputs/outputs in any x and y dimensions with symmetric quantization on the outputs. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor</td><td>pointer of the input vector </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor_dim_x</td><td>x dimension of the input tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor_dim_y</td><td>y dimension of the input tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor_ch</td><td>number of input tensor channels </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">ker_weight</td><td>pointer of kernel weights </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_tensor_ch</td><td>number of output tensor channels </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">ker_dim_x</td><td>x dimension of the filter kernel </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">ker_dim_y</td><td>y dimension of the filter kernel </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">pad_x</td><td>padding size in the x dimension </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">pad_y</td><td>padding size in the y dimension </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">stride_x</td><td>convolution stride in the x dimension </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">stride_y</td><td>convolution stride in the y dimension </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">pre_rshift</td><td>right shift amount for the output </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_scale</td><td>value of scaling for the output </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">post_rshift</td><td>right shift amount for the output </td></tr>
    <tr><td class="paramdir">[out]</td><td class="paramname">out_tensor</td><td>pointer of the output tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_tensor_dim_x</td><td>x dimension of the output tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_tensor_dim_y</td><td>y dimension of the output tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tmp_buf</td><td>temporary buffer for the input tensor. It is required when -mext-dsp or -mext-vector enabled and its size must be equal to "2 * in_tensor_ch * ker_dim_x
                                     * ker_dim_y". </td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>This function returns 0 on success; otherwise, it returns -1 if its inputs do not meet the constraints that in_tensor_ch is a multiple of 4 and out_tensor_ch is a multiple of 2.</dd></dl>
<dl class="section note"><dt>Note</dt><dd>The outputs will be 2-stage shifted before being stored, i.e., out = ((out &gt;&gt; pre_rshift) *out_scale) &gt;&gt; post_rshift. </dd></dl>

</div>
</div>
<a id="ga3fbca4e04cca9289834c84a10a913a88" name="ga3fbca4e04cca9289834c84a10a913a88"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ga3fbca4e04cca9289834c84a10a913a88">&#9670;&#160;</a></span>hpm_nn_conv_HWC_u8_s16_s8_RGB_sym_bias_fast()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">static int32_t hpm_nn_conv_HWC_u8_s16_s8_RGB_sym_bias_fast </td>
          <td>(</td>
          <td class="paramtype">const u8_t *</td>          <td class="paramname"><span class="paramname"><em>in_tensor</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>in_tensor_dim</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const q7_t *</td>          <td class="paramname"><span class="paramname"><em>ker_weight</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>out_tensor_ch</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>ker_dim</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>pad</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>stride</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const q31_t *</td>          <td class="paramname"><span class="paramname"><em>bias</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>pre_rshift</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>out_scale</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>post_rshift</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">q15_t *</td>          <td class="paramname"><span class="paramname"><em>out_tensor</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>out_tensor_dim</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">q15_t *</td>          <td class="paramname"><span class="paramname"><em>in_tmp_buf</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">q15_t *</td>          <td class="paramname"><span class="paramname"><em>wt_tmp_buf</em></span>&#160;)</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span><span class="mlabel">static</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p><code>#include &lt;<a class="el" href="hpm__math_8h.html">middleware/hpm_math/hpm_math.h</a>&gt;</code></p>

<p>This function performs fast convolution on RGB images for unsigned 8-bit integer inputs and signed 16-bit integer outputs with bias inputs and symmetric quantization on the outputs. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor</td><td>pointer of the input tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor_dim</td><td>input tensor dimension </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">ker_weight</td><td>pointer of kernel weights </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_tensor_ch</td><td>number of output tensor channels </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">ker_dim</td><td>dimension of the filter kernel </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">pad</td><td>padding size </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">stride</td><td>convolution stride </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">bias</td><td>pointer of the bias vector </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">pre_rshift</td><td>right shift amount for the output </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_scale</td><td>value of scaling for the output </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">post_rshift</td><td>right shift amount for the output </td></tr>
    <tr><td class="paramdir">[out]</td><td class="paramname">out_tensor</td><td>pointer of the output tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_tensor_dim</td><td>dimension of the output tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tmp_buf</td><td>temporary buffer for the input tensor. It is required when -mext-dsp or -mext-vector enabled and its size must be "2 * (3 *
                                 ker_dim * ker_dim + 1)". </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">wt_tmp_buf</td><td>temporary buffer for kernel weights. It is required when -mext-dsp or -mext-vector enabled and its size must be "out_tensor_ch *
                                 (3 * ker_dim * ker_dim + 1)". </td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>This function only returns 0.</dd></dl>
<dl class="section note"><dt>Note</dt><dd>The outputs will be 2-stage shifted before being stored, i.e., out = ((out &gt;&gt; pre_rshift) *out_scale) &gt;&gt; post_rshift. </dd></dl>

</div>
</div>
<a id="ga30719ccfc86c77e8b4fde37011f8d543" name="ga30719ccfc86c77e8b4fde37011f8d543"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ga30719ccfc86c77e8b4fde37011f8d543">&#9670;&#160;</a></span>hpm_nn_conv_HWC_u8_s16_s8_RGB_sym_fast()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">static int32_t hpm_nn_conv_HWC_u8_s16_s8_RGB_sym_fast </td>
          <td>(</td>
          <td class="paramtype">const u8_t *</td>          <td class="paramname"><span class="paramname"><em>in_tensor</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>in_tensor_dim</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const q7_t *</td>          <td class="paramname"><span class="paramname"><em>ker_weight</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>out_tensor_ch</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>ker_dim</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>pad</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>stride</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>pre_rshift</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>out_scale</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>post_rshift</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">q15_t *</td>          <td class="paramname"><span class="paramname"><em>out_tensor</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>out_tensor_dim</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">q15_t *</td>          <td class="paramname"><span class="paramname"><em>in_tmp_buf</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">q15_t *</td>          <td class="paramname"><span class="paramname"><em>wt_tmp_buf</em></span>&#160;)</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span><span class="mlabel">static</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p><code>#include &lt;<a class="el" href="hpm__math_8h.html">middleware/hpm_math/hpm_math.h</a>&gt;</code></p>

<p>This function performs fast convolution on RGB images for unsigned 8-bit integer inputs and signed 16-bit integer outputs with symmetric quantization on the outputs. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor</td><td>pointer of the input tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor_dim</td><td>input tensor dimension </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">ker_weight</td><td>pointer of kernel weights </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_tensor_ch</td><td>number of output tensor channels </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">ker_dim</td><td>dimension of the filter kernel </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">pad</td><td>padding size </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">stride</td><td>convolution stride </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">pre_rshift</td><td>right shift amount for the output </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_scale</td><td>value of scaling for the output </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">post_rshift</td><td>right shift amount for the output </td></tr>
    <tr><td class="paramdir">[out]</td><td class="paramname">out_tensor</td><td>pointer of the output tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_tensor_dim</td><td>dimension of the output tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tmp_buf</td><td>temporary buffer for the input tensor. It is required when -mext-dsp or -mext-vector enabled and its size must be "2 * (3 *
                                 ker_dim * ker_dim + 1)". </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">wt_tmp_buf</td><td>temporary buffer for kernel weights. It is required when -mext-dsp or -mext-vector enabled and its size must be "out_tensor_ch *
                                 (3 * ker_dim * ker_dim + 1)". </td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>This function only returns 0.</dd></dl>
<dl class="section note"><dt>Note</dt><dd>The outputs will be 2-stage shifted before being stored, i.e., out = ((out &gt;&gt; pre_rshift) *out_scale) &gt;&gt; post_rshift. </dd></dl>

</div>
</div>
<a id="ga14a05c18351cdbb2158cf1978e508f8c" name="ga14a05c18351cdbb2158cf1978e508f8c"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ga14a05c18351cdbb2158cf1978e508f8c">&#9670;&#160;</a></span>hpm_nn_conv_HWC_u8_s16_s8_sym_bias_fast()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">static int32_t hpm_nn_conv_HWC_u8_s16_s8_sym_bias_fast </td>
          <td>(</td>
          <td class="paramtype">const u8_t *</td>          <td class="paramname"><span class="paramname"><em>in_tensor</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>in_tensor_dim</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>in_tensor_ch</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const q7_t *</td>          <td class="paramname"><span class="paramname"><em>ker_weight</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>out_tensor_ch</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>ker_dim</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>pad</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>stride</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const q31_t *</td>          <td class="paramname"><span class="paramname"><em>bias</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>pre_rshift</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>out_scale</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>post_rshift</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">q15_t *</td>          <td class="paramname"><span class="paramname"><em>out_tensor</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>out_tensor_dim</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">q15_t *</td>          <td class="paramname"><span class="paramname"><em>in_tmp_buf</em></span>&#160;)</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span><span class="mlabel">static</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p><code>#include &lt;<a class="el" href="hpm__math_8h.html">middleware/hpm_math/hpm_math.h</a>&gt;</code></p>

<p>This function performs fast convolution for unsigned 8-bit integer inputs and signed 16-bit integer outputs with bias inputs and symmetric quantization on the outputs. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor</td><td>pointer of the input vector </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor_dim</td><td>dimension of the input tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor_ch</td><td>number of input tensor channels </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">ker_weight</td><td>pointer of kernel weights </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_tensor_ch</td><td>number of output tensor channels </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">ker_dim</td><td>dimension of the filter kernel </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">pad</td><td>padding size </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">stride</td><td>convolution stride </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">bias</td><td>pointer of the bias vector </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">pre_rshift</td><td>right shift amount for the output </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_scale</td><td>value of scaling for the output </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">post_rshift</td><td>right shift amount for the output </td></tr>
    <tr><td class="paramdir">[out]</td><td class="paramname">out_tensor</td><td>pointer of the output tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_tensor_dim</td><td>dimension of the output tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tmp_buf</td><td>temporary buffer for the input tensor. It is required when -mext-dsp or -mext-vector enabled and its size must be equal to "2 *
                                 in_tensor_ch * ker_dim * ker_dim". </td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>This function returns 0 on success; otherwise, it returns -1 if its inputs do not meet the constraints that in_tensor_ch is a multiple of 4 and out_tensor_ch is a multiple of 2.</dd></dl>
<dl class="section note"><dt>Note</dt><dd>The outputs will be 2-stage shifted before being stored, i.e., out = ((out &gt;&gt; pre_rshift) *out_scale) &gt;&gt; post_rshift. </dd></dl>

</div>
</div>
<a id="ga1ba10db375981d7dfba5902aea8de0ff" name="ga1ba10db375981d7dfba5902aea8de0ff"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ga1ba10db375981d7dfba5902aea8de0ff">&#9670;&#160;</a></span>hpm_nn_conv_HWC_u8_s16_s8_sym_bias_fast_any()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">static int32_t hpm_nn_conv_HWC_u8_s16_s8_sym_bias_fast_any </td>
          <td>(</td>
          <td class="paramtype">const u8_t *</td>          <td class="paramname"><span class="paramname"><em>in_tensor</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>in_tensor_dim_x</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>in_tensor_dim_y</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>in_tensor_ch</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const q7_t *</td>          <td class="paramname"><span class="paramname"><em>ker_weight</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>out_tensor_ch</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>ker_dim_x</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>ker_dim_y</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>pad_x</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>pad_y</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>stride_x</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>stride_y</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const q31_t *</td>          <td class="paramname"><span class="paramname"><em>bias</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>pre_rshift</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>out_scale</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>post_rshift</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">q15_t *</td>          <td class="paramname"><span class="paramname"><em>out_tensor</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>out_tensor_dim_x</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>out_tensor_dim_y</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">q15_t *</td>          <td class="paramname"><span class="paramname"><em>in_tmp_buf</em></span>&#160;)</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span><span class="mlabel">static</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p><code>#include &lt;<a class="el" href="hpm__math_8h.html">middleware/hpm_math/hpm_math.h</a>&gt;</code></p>

<p>This function performs fast convolution for unsigned 8-bit integer inputs and signed 16-bit integer outputs in any x and y dimensions with bias inputs and symmetric quantization on the outputs. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor</td><td>pointer of the input vector </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor_dim_x</td><td>x dimension of the input tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor_dim_y</td><td>y dimension of the input tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor_ch</td><td>number of input tensor channels </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">ker_weight</td><td>pointer of kernel weights </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_tensor_ch</td><td>number of output tensor channels </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">ker_dim_x</td><td>x dimension of the filter kernel </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">ker_dim_y</td><td>y dimension of the filter kernel </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">pad_x</td><td>padding size in the x dimension </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">pad_y</td><td>padding size in the y dimension </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">stride_x</td><td>convolution stride in the x dimension </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">stride_y</td><td>convolution stride in the y dimension </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">bias</td><td>pointer of the bias vector </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">pre_rshift</td><td>right shift amount for the output </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_scale</td><td>value of scaling for the output </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">post_rshift</td><td>right shift amount for the output </td></tr>
    <tr><td class="paramdir">[out]</td><td class="paramname">out_tensor</td><td>pointer of the output tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_tensor_dim_x</td><td>x dimension of the output tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_tensor_dim_y</td><td>y dimension of the output tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tmp_buf</td><td>temporary buffer for the input tensor. It is required when -mext-dsp or -mext-vector enabled and its size must be equal to "2 * in_tensor_ch * ker_dim_x
                                     * ker_dim_y". </td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>This function returns 0 on success; otherwise, it returns -1 if its inputs do not meet the constraints that in_tensor_ch is a multiple of 4 and out_tensor_ch is a multiple of 2.</dd></dl>
<dl class="section note"><dt>Note</dt><dd>The outputs will be 2-stage shifted before being stored, i.e., out = ((out &gt;&gt; pre_rshift) *out_scale) &gt;&gt; post_rshift. </dd></dl>

</div>
</div>
<a id="ga6ca86332aeecf3be577bfb87f554d178" name="ga6ca86332aeecf3be577bfb87f554d178"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ga6ca86332aeecf3be577bfb87f554d178">&#9670;&#160;</a></span>hpm_nn_conv_HWC_u8_s16_s8_sym_fast()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">static int32_t hpm_nn_conv_HWC_u8_s16_s8_sym_fast </td>
          <td>(</td>
          <td class="paramtype">const u8_t *</td>          <td class="paramname"><span class="paramname"><em>in_tensor</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>in_tensor_dim</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>in_tensor_ch</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const q7_t *</td>          <td class="paramname"><span class="paramname"><em>ker_weight</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>out_tensor_ch</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>ker_dim</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>pad</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>stride</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>pre_rshift</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>out_scale</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>post_rshift</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">q15_t *</td>          <td class="paramname"><span class="paramname"><em>out_tensor</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>out_tensor_dim</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">q15_t *</td>          <td class="paramname"><span class="paramname"><em>in_tmp_buf</em></span>&#160;)</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span><span class="mlabel">static</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p><code>#include &lt;<a class="el" href="hpm__math_8h.html">middleware/hpm_math/hpm_math.h</a>&gt;</code></p>

<p>This function performs fast convolution for unsigned 8-bit integer inputs and signed 16-bit integer outputs with symmetric quantization on the outputs. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor</td><td>pointer of the input vector </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor_dim</td><td>dimension of the input tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor_ch</td><td>number of input tensor channels </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">ker_weight</td><td>pointer of kernel weights </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_tensor_ch</td><td>number of output tensor channels </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">ker_dim</td><td>dimension of the filter kernel </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">pad</td><td>padding size </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">stride</td><td>convolution stride </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">pre_rshift</td><td>right shift amount for the output </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_scale</td><td>value of scaling for the output </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">post_rshift</td><td>right shift amount for the output </td></tr>
    <tr><td class="paramdir">[out]</td><td class="paramname">out_tensor</td><td>pointer of the output tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_tensor_dim</td><td>dimension of the output tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tmp_buf</td><td>temporary buffer for the input tensor. It is required when -mext-dsp or -mext-vector enabled and its size must be equal to "2 *
                                 in_tensor_ch * ker_dim * ker_dim". </td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>This function returns 0 on success; otherwise, it returns -1 if its inputs do not meet the constraints that in_tensor_ch is a multiple of 4 and out_tensor_ch is a multiple of 2.</dd></dl>
<dl class="section note"><dt>Note</dt><dd>The outputs will be 2-stage shifted before being stored, i.e., out = ((out &gt;&gt; pre_rshift) *out_scale) &gt;&gt; post_rshift. </dd></dl>

</div>
</div>
<a id="ga7bb79b1cd25ff4e15ddfff5ac9336d3f" name="ga7bb79b1cd25ff4e15ddfff5ac9336d3f"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ga7bb79b1cd25ff4e15ddfff5ac9336d3f">&#9670;&#160;</a></span>hpm_nn_conv_HWC_u8_s16_s8_sym_fast_any()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">static int32_t hpm_nn_conv_HWC_u8_s16_s8_sym_fast_any </td>
          <td>(</td>
          <td class="paramtype">const u8_t *</td>          <td class="paramname"><span class="paramname"><em>in_tensor</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>in_tensor_dim_x</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>in_tensor_dim_y</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>in_tensor_ch</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const q7_t *</td>          <td class="paramname"><span class="paramname"><em>ker_weight</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>out_tensor_ch</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>ker_dim_x</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>ker_dim_y</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>pad_x</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>pad_y</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>stride_x</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>stride_y</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>pre_rshift</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>out_scale</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>post_rshift</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">q15_t *</td>          <td class="paramname"><span class="paramname"><em>out_tensor</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>out_tensor_dim_x</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>out_tensor_dim_y</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">q15_t *</td>          <td class="paramname"><span class="paramname"><em>in_tmp_buf</em></span>&#160;)</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span><span class="mlabel">static</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p><code>#include &lt;<a class="el" href="hpm__math_8h.html">middleware/hpm_math/hpm_math.h</a>&gt;</code></p>

<p>This function performs fast convolution for unsigned 8-bit integer inputs and signed 16-bit integer outputs in any x and y dimensions with symmetric quantization on the outputs. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor</td><td>pointer of the input vector </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor_dim_x</td><td>x dimension of the input tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor_dim_y</td><td>y dimension of the input tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor_ch</td><td>number of input tensor channels </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">ker_weight</td><td>pointer of kernel weights </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_tensor_ch</td><td>number of output tensor channels </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">ker_dim_x</td><td>x dimension of the filter kernel </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">ker_dim_y</td><td>y dimension of the filter kernel </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">pad_x</td><td>padding size in the x dimension </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">pad_y</td><td>padding size in the y dimension </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">stride_x</td><td>convolution stride in the x dimension </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">stride_y</td><td>convolution stride in the y dimension </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">pre_rshift</td><td>right shift amount for the output </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_scale</td><td>value of scaling for the output </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">post_rshift</td><td>right shift amount for the output </td></tr>
    <tr><td class="paramdir">[out]</td><td class="paramname">out_tensor</td><td>pointer of the output tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_tensor_dim_x</td><td>x dimension of the output tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_tensor_dim_y</td><td>y dimension of the output tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tmp_buf</td><td>temporary buffer for the input tensor. It is required when -mext-dsp or -mext-vector enabled and its size must be equal to "2 * in_tensor_ch * ker_dim_x
                                     * ker_dim_y". </td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>This function returns 0 on success; otherwise, it returns -1 if its inputs do not meet the constraints that in_tensor_ch is a multiple of 4 and out_tensor_ch is a multiple of 2.</dd></dl>
<dl class="section note"><dt>Note</dt><dd>The outputs will be 2-stage shifted before being stored, i.e., out = ((out &gt;&gt; pre_rshift) *out_scale) &gt;&gt; post_rshift. </dd></dl>

</div>
</div>
<a id="ga02b99a74afdae934fc45f491a59d2214" name="ga02b99a74afdae934fc45f491a59d2214"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ga02b99a74afdae934fc45f491a59d2214">&#9670;&#160;</a></span>hpm_nn_conv_HWC_u8_s8_s8_RGB_sym_bias_fast()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">static int32_t hpm_nn_conv_HWC_u8_s8_s8_RGB_sym_bias_fast </td>
          <td>(</td>
          <td class="paramtype">const u8_t *</td>          <td class="paramname"><span class="paramname"><em>in_tensor</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>in_tensor_dim</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const q7_t *</td>          <td class="paramname"><span class="paramname"><em>ker_weight</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>out_tensor_ch</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>ker_dim</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>pad</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>stride</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const q31_t *</td>          <td class="paramname"><span class="paramname"><em>bias</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>pre_rshift</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>out_scale</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>post_rshift</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">q7_t *</td>          <td class="paramname"><span class="paramname"><em>out_tensor</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>out_tensor_dim</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">q15_t *</td>          <td class="paramname"><span class="paramname"><em>in_tmp_buf</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">q15_t *</td>          <td class="paramname"><span class="paramname"><em>wt_tmp_buf</em></span>&#160;)</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span><span class="mlabel">static</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p><code>#include &lt;<a class="el" href="hpm__math_8h.html">middleware/hpm_math/hpm_math.h</a>&gt;</code></p>

<p>This function performs fast convolution on RGB images for signed 8-bit integer inputs/outputs with bias inputs and symmetric quantization on the outputs. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor</td><td>pointer of the input tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor_dim</td><td>input tensor dimension </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">ker_weight</td><td>pointer of kernel weights </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_tensor_ch</td><td>number of output tensor channels </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">ker_dim</td><td>dimension of the filter kernel </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">pad</td><td>padding size </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">stride</td><td>convolution stride </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">bias</td><td>pointer of the bias vector </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">pre_rshift</td><td>right shift amount for the output </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_scale</td><td>value of scaling for the output </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">post_rshift</td><td>right shift amount for the output </td></tr>
    <tr><td class="paramdir">[out]</td><td class="paramname">out_tensor</td><td>pointer of the output tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_tensor_dim</td><td>dimension of the output tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tmp_buf</td><td>temporary buffer for the input tensor. It is required when -mext-dsp or -mext-vector enabled and its size must be "2 * (3 *
                                 ker_dim * ker_dim + 1)". </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">wt_tmp_buf</td><td>temporary buffer for kernel weights. It is required when -mext-dsp or -mext-vector enabled and its size must be "out_tensor_ch *
                                 (3 * ker_dim * ker_dim + 1)". </td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>This function only returns 0.</dd></dl>
<dl class="section note"><dt>Note</dt><dd>The outputs will be 2-stage shifted before being stored, i.e., out = ((out &gt;&gt; pre_rshift) *out_scale) &gt;&gt; post_rshift. </dd></dl>

</div>
</div>
<a id="ga2f5d213d0023ff26d9ce168bfefa2a40" name="ga2f5d213d0023ff26d9ce168bfefa2a40"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ga2f5d213d0023ff26d9ce168bfefa2a40">&#9670;&#160;</a></span>hpm_nn_conv_HWC_u8_s8_s8_RGB_sym_fast()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">static int32_t hpm_nn_conv_HWC_u8_s8_s8_RGB_sym_fast </td>
          <td>(</td>
          <td class="paramtype">const u8_t *</td>          <td class="paramname"><span class="paramname"><em>in_tensor</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>in_tensor_dim</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const q7_t *</td>          <td class="paramname"><span class="paramname"><em>ker_weight</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>out_tensor_ch</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>ker_dim</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>pad</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>stride</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>pre_rshift</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>out_scale</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>post_rshift</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">q7_t *</td>          <td class="paramname"><span class="paramname"><em>out_tensor</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>out_tensor_dim</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">q15_t *</td>          <td class="paramname"><span class="paramname"><em>in_tmp_buf</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">q15_t *</td>          <td class="paramname"><span class="paramname"><em>wt_tmp_buf</em></span>&#160;)</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span><span class="mlabel">static</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p><code>#include &lt;<a class="el" href="hpm__math_8h.html">middleware/hpm_math/hpm_math.h</a>&gt;</code></p>

<p>This function performs fast convolution on RGB images for unsigned 8-bit integer inputs and signed 8-bit integer outputs with symmetric quantization on the outputs. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor</td><td>pointer of the input tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor_dim</td><td>input tensor dimension </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">ker_weight</td><td>pointer of kernel weights </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_tensor_ch</td><td>number of output tensor channels </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">ker_dim</td><td>dimension of the filter kernel </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">pad</td><td>padding size </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">stride</td><td>convolution stride </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">pre_rshift</td><td>right shift amount for the output </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_scale</td><td>value of scaling for the output </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">post_rshift</td><td>right shift amount for the output </td></tr>
    <tr><td class="paramdir">[out]</td><td class="paramname">out_tensor</td><td>pointer of the output tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_tensor_dim</td><td>dimension of the output tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tmp_buf</td><td>temporary buffer for the input tensor. It is required when -mext-dsp or -mext-vector enabled and its size must be "2 * (3 *
                                 ker_dim * ker_dim + 1)". </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">wt_tmp_buf</td><td>temporary buffer for kernel weights. It is required when -mext-dsp or -mext-vector enabled and its size must be "out_tensor_ch *
                                 (3 * ker_dim * ker_dim + 1)". </td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>This function only returns 0.</dd></dl>
<dl class="section note"><dt>Note</dt><dd>The outputs will be 2-stage shifted before being stored, i.e., out = ((out &gt;&gt; pre_rshift) *out_scale) &gt;&gt; post_rshift. </dd></dl>

</div>
</div>
<a id="ga7cd15bdefc9684fc8c6dc5740bd973e6" name="ga7cd15bdefc9684fc8c6dc5740bd973e6"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ga7cd15bdefc9684fc8c6dc5740bd973e6">&#9670;&#160;</a></span>hpm_nn_conv_HWC_u8_s8_s8_sym_bias_fast()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">static int32_t hpm_nn_conv_HWC_u8_s8_s8_sym_bias_fast </td>
          <td>(</td>
          <td class="paramtype">const u8_t *</td>          <td class="paramname"><span class="paramname"><em>in_tensor</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>in_tensor_dim</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>in_tensor_ch</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const q7_t *</td>          <td class="paramname"><span class="paramname"><em>ker_weight</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>out_tensor_ch</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>ker_dim</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>pad</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>stride</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const q31_t *</td>          <td class="paramname"><span class="paramname"><em>bias</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>pre_rshift</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>out_scale</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>post_rshift</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">q7_t *</td>          <td class="paramname"><span class="paramname"><em>out_tensor</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>out_tensor_dim</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">q15_t *</td>          <td class="paramname"><span class="paramname"><em>in_tmp_buf</em></span>&#160;)</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span><span class="mlabel">static</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p><code>#include &lt;<a class="el" href="hpm__math_8h.html">middleware/hpm_math/hpm_math.h</a>&gt;</code></p>

<p>This function performs fast convolution for unsigned 8-bit integer inputs and signed 8-bit integer outputs with bias inputs and symmetric quantization on the outputs. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor</td><td>pointer of the input vector </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor_dim</td><td>dimension of the input tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor_ch</td><td>number of input tensor channels </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">ker_weight</td><td>pointer of kernel weights </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_tensor_ch</td><td>number of output tensor channels </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">ker_dim</td><td>dimension of the filter kernel </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">pad</td><td>padding size </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">stride</td><td>convolution stride </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">bias</td><td>pointer of the bias vector </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">pre_rshift</td><td>right shift amount for the output </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_scale</td><td>value of scaling for the output </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">post_rshift</td><td>right shift amount for the output </td></tr>
    <tr><td class="paramdir">[out]</td><td class="paramname">out_tensor</td><td>pointer of the output tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_tensor_dim</td><td>dimension of the output tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tmp_buf</td><td>temporary buffer for the input tensor. It is required when -mext-dsp or -mext-vector enabled and its size must be equal to "2 *
                                 in_tensor_ch * ker_dim * ker_dim". </td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>This function returns 0 on success; otherwise, it returns -1 if its inputs do not meet the constraints that in_tensor_ch is a multiple of 4 and out_tensor_ch is a multiple of 2.</dd></dl>
<dl class="section note"><dt>Note</dt><dd>The outputs will be 2-stage shifted before being stored, i.e., out = ((out &gt;&gt; pre_rshift) *out_scale) &gt;&gt; post_rshift. </dd></dl>

</div>
</div>
<a id="gae65c6f8353b1d3eb0ad4f6bbdb89c4cc" name="gae65c6f8353b1d3eb0ad4f6bbdb89c4cc"></a>
<h2 class="memtitle"><span class="permalink"><a href="#gae65c6f8353b1d3eb0ad4f6bbdb89c4cc">&#9670;&#160;</a></span>hpm_nn_conv_HWC_u8_s8_s8_sym_bias_fast_any()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">static int32_t hpm_nn_conv_HWC_u8_s8_s8_sym_bias_fast_any </td>
          <td>(</td>
          <td class="paramtype">const u8_t *</td>          <td class="paramname"><span class="paramname"><em>in_tensor</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>in_tensor_dim_x</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>in_tensor_dim_y</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>in_tensor_ch</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const q7_t *</td>          <td class="paramname"><span class="paramname"><em>ker_weight</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>out_tensor_ch</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>ker_dim_x</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>ker_dim_y</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>pad_x</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>pad_y</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>stride_x</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>stride_y</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const q31_t *</td>          <td class="paramname"><span class="paramname"><em>bias</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>pre_rshift</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>out_scale</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>post_rshift</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">q7_t *</td>          <td class="paramname"><span class="paramname"><em>out_tensor</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>out_tensor_dim_x</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>out_tensor_dim_y</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">q15_t *</td>          <td class="paramname"><span class="paramname"><em>in_tmp_buf</em></span>&#160;)</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span><span class="mlabel">static</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p><code>#include &lt;<a class="el" href="hpm__math_8h.html">middleware/hpm_math/hpm_math.h</a>&gt;</code></p>

<p>This function performs fast convolution for unsigned 8-bit integer inputs and signed 8-bit integer outputs in any x and y dimensions with bias inputs and symmetric quantization on the outputs. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor</td><td>pointer of the input vector </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor_dim_x</td><td>x dimension of the input tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor_dim_y</td><td>y dimension of the input tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor_ch</td><td>number of input tensor channels </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">ker_weight</td><td>pointer of kernel weights </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_tensor_ch</td><td>number of output tensor channels </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">ker_dim_x</td><td>x dimension of the filter kernel </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">ker_dim_y</td><td>y dimension of the filter kernel </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">pad_x</td><td>padding size in the x dimension </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">pad_y</td><td>padding size in the y dimension </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">stride_x</td><td>convolution stride in the x dimension </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">stride_y</td><td>convolution stride in the y dimension </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">bias</td><td>pointer of the bias vector </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">pre_rshift</td><td>right shift amount for the output </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_scale</td><td>value of scaling for the output </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">post_rshift</td><td>right shift amount for the output </td></tr>
    <tr><td class="paramdir">[out]</td><td class="paramname">out_tensor</td><td>pointer of the output tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_tensor_dim_x</td><td>x dimension of the output tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_tensor_dim_y</td><td>y dimension of the output tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tmp_buf</td><td>temporary buffer for the input tensor. It is required when -mext-dsp or -mext-vector enabled and its size must be equal to "2 * in_tensor_ch * ker_dim_x
                                     * ker_dim_y". </td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>This function returns 0 on success; otherwise, it returns -1 if its inputs do not meet the constraints that in_tensor_ch is a multiple of 4 and out_tensor_ch is a multiple of 2.</dd></dl>
<dl class="section note"><dt>Note</dt><dd>The outputs will be 2-stage shifted before being stored, i.e., out = ((out &gt;&gt; pre_rshift) *out_scale) &gt;&gt; post_rshift. </dd></dl>

</div>
</div>
<a id="ga681fd01c3db04f540acb48e080682acc" name="ga681fd01c3db04f540acb48e080682acc"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ga681fd01c3db04f540acb48e080682acc">&#9670;&#160;</a></span>hpm_nn_conv_HWC_u8_s8_s8_sym_fast()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">static int32_t hpm_nn_conv_HWC_u8_s8_s8_sym_fast </td>
          <td>(</td>
          <td class="paramtype">const u8_t *</td>          <td class="paramname"><span class="paramname"><em>in_tensor</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>in_tensor_dim</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>in_tensor_ch</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const q7_t *</td>          <td class="paramname"><span class="paramname"><em>ker_weight</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>out_tensor_ch</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>ker_dim</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>pad</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>stride</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>pre_rshift</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>out_scale</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>post_rshift</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">q7_t *</td>          <td class="paramname"><span class="paramname"><em>out_tensor</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>out_tensor_dim</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">q15_t *</td>          <td class="paramname"><span class="paramname"><em>in_tmp_buf</em></span>&#160;)</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span><span class="mlabel">static</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p><code>#include &lt;<a class="el" href="hpm__math_8h.html">middleware/hpm_math/hpm_math.h</a>&gt;</code></p>

<p>This function performs fast convolution for unsigned 8-bit integer inputs and signed 8-bit integer outputs with symmetric quantization on the outputs. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor</td><td>pointer of the input vector </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor_dim</td><td>dimension of the input tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor_ch</td><td>number of input tensor channels </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">ker_weight</td><td>pointer of kernel weights </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_tensor_ch</td><td>number of output tensor channels </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">ker_dim</td><td>dimension of the filter kernel </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">pad</td><td>padding size </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">stride</td><td>convolution stride </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">pre_rshift</td><td>right shift amount for the output </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_scale</td><td>value of scaling for the output </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">post_rshift</td><td>right shift amount for the output </td></tr>
    <tr><td class="paramdir">[out]</td><td class="paramname">out_tensor</td><td>pointer of the output tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_tensor_dim</td><td>dimension of the output tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tmp_buf</td><td>temporary buffer for the input tensor. It is required when -mext-dsp or -mext-vector enabled and its size must be equal to "2 *
                                 in_tensor_ch * ker_dim * ker_dim". </td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>This function returns 0 on success; otherwise, it returns -1 if its inputs do not meet the constraints that in_tensor_ch is a multiple of 4 and out_tensor_ch is a multiple of 2.</dd></dl>
<dl class="section note"><dt>Note</dt><dd>The outputs will be 2-stage shifted before being stored, i.e., out = ((out &gt;&gt; pre_rshift) *out_scale) &gt;&gt; post_rshift. </dd></dl>

</div>
</div>
<a id="gad463faadd1a58de1fabc5f05a396f025" name="gad463faadd1a58de1fabc5f05a396f025"></a>
<h2 class="memtitle"><span class="permalink"><a href="#gad463faadd1a58de1fabc5f05a396f025">&#9670;&#160;</a></span>hpm_nn_conv_HWC_u8_s8_s8_sym_fast_any()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">static int32_t hpm_nn_conv_HWC_u8_s8_s8_sym_fast_any </td>
          <td>(</td>
          <td class="paramtype">const u8_t *</td>          <td class="paramname"><span class="paramname"><em>in_tensor</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>in_tensor_dim_x</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>in_tensor_dim_y</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>in_tensor_ch</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const q7_t *</td>          <td class="paramname"><span class="paramname"><em>ker_weight</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>out_tensor_ch</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>ker_dim_x</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>ker_dim_y</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>pad_x</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>pad_y</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>stride_x</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>stride_y</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>pre_rshift</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>out_scale</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>post_rshift</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">q7_t *</td>          <td class="paramname"><span class="paramname"><em>out_tensor</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>out_tensor_dim_x</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>out_tensor_dim_y</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">q15_t *</td>          <td class="paramname"><span class="paramname"><em>in_tmp_buf</em></span>&#160;)</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span><span class="mlabel">static</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p><code>#include &lt;<a class="el" href="hpm__math_8h.html">middleware/hpm_math/hpm_math.h</a>&gt;</code></p>

<p>This function performs fast convolution for unsigned 8-bit integer inputs and signed 8-bit integer outputs in any x and y dimensions with symmetric quantization on the outputs. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor</td><td>pointer of the input vector </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor_dim_x</td><td>x dimension of the input tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor_dim_y</td><td>y dimension of the input tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor_ch</td><td>number of input tensor channels </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">ker_weight</td><td>pointer of kernel weights </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_tensor_ch</td><td>number of output tensor channels </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">ker_dim_x</td><td>x dimension of the filter kernel </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">ker_dim_y</td><td>y dimension of the filter kernel </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">pad_x</td><td>padding size in the x dimension </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">pad_y</td><td>padding size in the y dimension </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">stride_x</td><td>convolution stride in the x dimension </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">stride_y</td><td>convolution stride in the y dimension </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">pre_rshift</td><td>right shift amount for the output </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_scale</td><td>value of scaling for the output </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">post_rshift</td><td>right shift amount for the output </td></tr>
    <tr><td class="paramdir">[out]</td><td class="paramname">out_tensor</td><td>pointer of the output tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_tensor_dim_x</td><td>x dimension of the output tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_tensor_dim_y</td><td>y dimension of the output tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tmp_buf</td><td>temporary buffer for the input tensor. It is required when -mext-dsp or -mext-vector enabled and its size must be equal to "2 * in_tensor_ch * ker_dim_x
                                     * ker_dim_y". </td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>This function returns 0 on success; otherwise, it returns -1 if its inputs do not meet the constraints that in_tensor_ch is a multiple of 4 and out_tensor_ch is a multiple of 2.</dd></dl>
<dl class="section note"><dt>Note</dt><dd>The outputs will be 2-stage shifted before being stored, i.e., out = ((out &gt;&gt; pre_rshift) *out_scale) &gt;&gt; post_rshift. </dd></dl>

</div>
</div>
<a id="gae84e818d001cf7ea2c4331924f36e35e" name="gae84e818d001cf7ea2c4331924f36e35e"></a>
<h2 class="memtitle"><span class="permalink"><a href="#gae84e818d001cf7ea2c4331924f36e35e">&#9670;&#160;</a></span>hpm_nn_conv_HWC_u8_u8_s8_RGB_sym_bias_fast()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">static int32_t hpm_nn_conv_HWC_u8_u8_s8_RGB_sym_bias_fast </td>
          <td>(</td>
          <td class="paramtype">const u8_t *</td>          <td class="paramname"><span class="paramname"><em>in_tensor</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>in_tensor_dim</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const q7_t *</td>          <td class="paramname"><span class="paramname"><em>ker_weight</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>out_tensor_ch</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>ker_dim</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>pad</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>stride</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const q31_t *</td>          <td class="paramname"><span class="paramname"><em>bias</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>pre_rshift</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>out_scale</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>post_rshift</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">u8_t *</td>          <td class="paramname"><span class="paramname"><em>out_tensor</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>out_tensor_dim</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">q15_t *</td>          <td class="paramname"><span class="paramname"><em>in_tmp_buf</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">q15_t *</td>          <td class="paramname"><span class="paramname"><em>wt_tmp_buf</em></span>&#160;)</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span><span class="mlabel">static</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p><code>#include &lt;<a class="el" href="hpm__math_8h.html">middleware/hpm_math/hpm_math.h</a>&gt;</code></p>

<p>This function performs fast convolution on RGB images for unsigned 8-bit integer inputs/outputs with symmetric quantization on the outputs. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor</td><td>pointer of the input tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor_dim</td><td>input tensor dimension </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">ker_weight</td><td>pointer of kernel weights </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_tensor_ch</td><td>number of output tensor channels </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">ker_dim</td><td>dimension of the filter kernel </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">pad</td><td>padding size </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">stride</td><td>convolution stride </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">bias</td><td>pointer of the bias vector </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">pre_rshift</td><td>right shift amount for the output </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_scale</td><td>value of scaling for the output </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">post_rshift</td><td>right shift amount for the output </td></tr>
    <tr><td class="paramdir">[out]</td><td class="paramname">out_tensor</td><td>pointer of the output tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_tensor_dim</td><td>dimension of the output tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tmp_buf</td><td>temporary buffer for the input tensor. It is required when -mext-dsp or -mext-vector enabled and its size must be "2 * (3 *
                                 ker_dim * ker_dim + 1)". </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">wt_tmp_buf</td><td>temporary buffer for kernel weights. It is required when -mext-dsp or -mext-vector enabled and its size must be "out_tensor_ch *
                                 (3 * ker_dim * ker_dim + 1)". </td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>This function only returns 0.</dd></dl>
<dl class="section note"><dt>Note</dt><dd>The outputs will be 2-stage shifted before being stored, i.e., out = ((out &gt;&gt; pre_rshift) *out_scale) &gt;&gt; post_rshift. </dd></dl>

</div>
</div>
<a id="ga546898208090a68e33f99ced79470f5f" name="ga546898208090a68e33f99ced79470f5f"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ga546898208090a68e33f99ced79470f5f">&#9670;&#160;</a></span>hpm_nn_conv_HWC_u8_u8_s8_RGB_sym_fast()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">static int32_t hpm_nn_conv_HWC_u8_u8_s8_RGB_sym_fast </td>
          <td>(</td>
          <td class="paramtype">const u8_t *</td>          <td class="paramname"><span class="paramname"><em>in_tensor</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>in_tensor_dim</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const q7_t *</td>          <td class="paramname"><span class="paramname"><em>ker_weight</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>out_tensor_ch</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>ker_dim</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>pad</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>stride</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>pre_rshift</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>out_scale</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>post_rshift</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">u8_t *</td>          <td class="paramname"><span class="paramname"><em>out_tensor</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>out_tensor_dim</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">q15_t *</td>          <td class="paramname"><span class="paramname"><em>in_tmp_buf</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">q15_t *</td>          <td class="paramname"><span class="paramname"><em>wt_tmp_buf</em></span>&#160;)</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span><span class="mlabel">static</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p><code>#include &lt;<a class="el" href="hpm__math_8h.html">middleware/hpm_math/hpm_math.h</a>&gt;</code></p>

<p>This function performs fast convolution on RGB images for unsigned 8-bit integer inputs/outputs with symmetric quantization on the outputs. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor</td><td>pointer of the input tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor_dim</td><td>input tensor dimension </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">ker_weight</td><td>pointer of kernel weights </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_tensor_ch</td><td>number of output tensor channels </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">ker_dim</td><td>dimension of the filter kernel </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">pad</td><td>padding size </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">stride</td><td>convolution stride </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">pre_rshift</td><td>right shift amount for the output </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_scale</td><td>value of scaling for the output </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">post_rshift</td><td>right shift amount for the output </td></tr>
    <tr><td class="paramdir">[out]</td><td class="paramname">out_tensor</td><td>pointer of the output tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_tensor_dim</td><td>dimension of the output tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tmp_buf</td><td>temporary buffer for the input tensor. It is required when -mext-dsp or -mext-vector enabled and its size must be "2 * (3 *
                                 ker_dim * ker_dim + 1)". </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">wt_tmp_buf</td><td>temporary buffer for kernel weights. It is required when -mext-dsp or -mext-vector enabled and its size must be "out_tensor_ch *
                                 (3 * ker_dim * ker_dim + 1)". </td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>This function only returns 0.</dd></dl>
<dl class="section note"><dt>Note</dt><dd>The outputs will be 2-stage shifted before being stored, i.e., out = ((out &gt;&gt; pre_rshift) *out_scale) &gt;&gt; post_rshift. </dd></dl>

</div>
</div>
<a id="gab00822cf6d1b355344c6385a2555dab4" name="gab00822cf6d1b355344c6385a2555dab4"></a>
<h2 class="memtitle"><span class="permalink"><a href="#gab00822cf6d1b355344c6385a2555dab4">&#9670;&#160;</a></span>hpm_nn_conv_HWC_u8_u8_s8_sym_bias_fast()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">static int32_t hpm_nn_conv_HWC_u8_u8_s8_sym_bias_fast </td>
          <td>(</td>
          <td class="paramtype">const u8_t *</td>          <td class="paramname"><span class="paramname"><em>in_tensor</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>in_tensor_dim</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>in_tensor_ch</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const q7_t *</td>          <td class="paramname"><span class="paramname"><em>ker_weight</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>out_tensor_ch</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>ker_dim</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>pad</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>stride</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const q31_t *</td>          <td class="paramname"><span class="paramname"><em>bias</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>pre_rshift</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>out_scale</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>post_rshift</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">u8_t *</td>          <td class="paramname"><span class="paramname"><em>out_tensor</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>out_tensor_dim</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">q15_t *</td>          <td class="paramname"><span class="paramname"><em>in_tmp_buf</em></span>&#160;)</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span><span class="mlabel">static</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p><code>#include &lt;<a class="el" href="hpm__math_8h.html">middleware/hpm_math/hpm_math.h</a>&gt;</code></p>

<p>This function performs fast convolution for unsigned 8-bit integer inputs/outputs with bias inputs and symmetric quantization on the outputs. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor</td><td>pointer of the input vector </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor_dim</td><td>dimension of the input tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor_ch</td><td>number of input tensor channels </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">ker_weight</td><td>pointer of kernel weights </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_tensor_ch</td><td>number of output tensor channels </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">ker_dim</td><td>dimension of the filter kernel </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">pad</td><td>padding size </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">stride</td><td>convolution stride </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">bias</td><td>pointer of the bias vector </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">pre_rshift</td><td>right shift amount for the output </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_scale</td><td>value of scaling for the output </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">post_rshift</td><td>right shift amount for the output </td></tr>
    <tr><td class="paramdir">[out]</td><td class="paramname">out_tensor</td><td>pointer of the output tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_tensor_dim</td><td>dimension of the output tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tmp_buf</td><td>temporary buffer for the input tensor. It is required when -mext-dsp or -mext-vector enabled and its size must be equal to "2 *
                                 in_tensor_ch * ker_dim * ker_dim". </td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>This function returns 0 on success; otherwise, it returns -1 if its inputs do not meet the constraints that in_tensor_ch is a multiple of 4 and out_tensor_ch is a multiple of 2.</dd></dl>
<dl class="section note"><dt>Note</dt><dd>The outputs will be 2-stage shifted before being stored, i.e., out = ((out &gt;&gt; pre_rshift) *out_scale) &gt;&gt; post_rshift. </dd></dl>

</div>
</div>
<a id="gaa245691db40029df9384b7e50b79fde4" name="gaa245691db40029df9384b7e50b79fde4"></a>
<h2 class="memtitle"><span class="permalink"><a href="#gaa245691db40029df9384b7e50b79fde4">&#9670;&#160;</a></span>hpm_nn_conv_HWC_u8_u8_s8_sym_bias_fast_any()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">static int32_t hpm_nn_conv_HWC_u8_u8_s8_sym_bias_fast_any </td>
          <td>(</td>
          <td class="paramtype">const u8_t *</td>          <td class="paramname"><span class="paramname"><em>in_tensor</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>in_tensor_dim_x</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>in_tensor_dim_y</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>in_tensor_ch</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const q7_t *</td>          <td class="paramname"><span class="paramname"><em>ker_weight</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>out_tensor_ch</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>ker_dim_x</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>ker_dim_y</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>pad_x</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>pad_y</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>stride_x</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>stride_y</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const q31_t *</td>          <td class="paramname"><span class="paramname"><em>bias</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>pre_rshift</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>out_scale</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>post_rshift</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">u8_t *</td>          <td class="paramname"><span class="paramname"><em>out_tensor</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>out_tensor_dim_x</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>out_tensor_dim_y</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">q15_t *</td>          <td class="paramname"><span class="paramname"><em>in_tmp_buf</em></span>&#160;)</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span><span class="mlabel">static</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p><code>#include &lt;<a class="el" href="hpm__math_8h.html">middleware/hpm_math/hpm_math.h</a>&gt;</code></p>

<p>This function performs fast convolution for unsigned 8-bit integer inputs/outputs in any x and y dimensions with bias inputs and symmetric quantization on the outputs. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor</td><td>pointer of the input vector </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor_dim_x</td><td>x dimension of the input tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor_dim_y</td><td>y dimension of the input tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor_ch</td><td>number of input tensor channels </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">ker_weight</td><td>pointer of kernel weights </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_tensor_ch</td><td>number of output tensor channels </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">ker_dim_x</td><td>x dimension of the filter kernel </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">ker_dim_y</td><td>y dimension of the filter kernel </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">pad_x</td><td>padding size in the x dimension </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">pad_y</td><td>padding size in the y dimension </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">stride_x</td><td>convolution stride in the x dimension </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">stride_y</td><td>convolution stride in the y dimension </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">bias</td><td>pointer of the bias vector </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">pre_rshift</td><td>right shift amount for the output </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_scale</td><td>value of scaling for the output </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">post_rshift</td><td>right shift amount for the output </td></tr>
    <tr><td class="paramdir">[out]</td><td class="paramname">out_tensor</td><td>pointer of the output tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_tensor_dim_x</td><td>x dimension of the output tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_tensor_dim_y</td><td>y dimension of the output tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tmp_buf</td><td>temporary buffer for the input tensor. It is required when -mext-dsp or -mext-vector enabled and its size must be equal to "2 * in_tensor_ch * ker_dim_x
                                     * ker_dim_y". </td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>This function returns 0 on success; otherwise, it returns -1 if its inputs do not meet the constraints that in_tensor_ch is a multiple of 4 and out_tensor_ch is a multiple of 2.</dd></dl>
<dl class="section note"><dt>Note</dt><dd>The outputs will be 2-stage shifted before being stored, i.e., out = ((out &gt;&gt; pre_rshift) *out_scale) &gt;&gt; post_rshift. </dd></dl>

</div>
</div>
<a id="ga44f3d234a8ffe93b8cbc31e19ed49cc3" name="ga44f3d234a8ffe93b8cbc31e19ed49cc3"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ga44f3d234a8ffe93b8cbc31e19ed49cc3">&#9670;&#160;</a></span>hpm_nn_conv_HWC_u8_u8_s8_sym_fast()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">static int32_t hpm_nn_conv_HWC_u8_u8_s8_sym_fast </td>
          <td>(</td>
          <td class="paramtype">const u8_t *</td>          <td class="paramname"><span class="paramname"><em>in_tensor</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>in_tensor_dim</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>in_tensor_ch</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const q7_t *</td>          <td class="paramname"><span class="paramname"><em>ker_weight</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>out_tensor_ch</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>ker_dim</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>pad</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>stride</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>pre_rshift</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>out_scale</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>post_rshift</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">u8_t *</td>          <td class="paramname"><span class="paramname"><em>out_tensor</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>out_tensor_dim</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">q15_t *</td>          <td class="paramname"><span class="paramname"><em>in_tmp_buf</em></span>&#160;)</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span><span class="mlabel">static</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p><code>#include &lt;<a class="el" href="hpm__math_8h.html">middleware/hpm_math/hpm_math.h</a>&gt;</code></p>

<p>This function performs fast convolution for unsigned 8-bit integer inputs/outputs with symmetric quantization on the outputs. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor</td><td>pointer of the input vector </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor_dim</td><td>dimension of the input tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor_ch</td><td>number of input tensor channels </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">ker_weight</td><td>pointer of kernel weights </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_tensor_ch</td><td>number of output tensor channels </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">ker_dim</td><td>dimension of the filter kernel </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">pad</td><td>padding size </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">stride</td><td>convolution stride </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">pre_rshift</td><td>right shift amount for the output </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_scale</td><td>value of scaling for the output </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">post_rshift</td><td>right shift amount for the output </td></tr>
    <tr><td class="paramdir">[out]</td><td class="paramname">out_tensor</td><td>pointer of the output tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_tensor_dim</td><td>dimension of the output tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tmp_buf</td><td>temporary buffer for the input tensor. It is required when -mext-dsp or -mext-vector enabled and its size must be equal to "2 *
                                 in_tensor_ch * ker_dim * ker_dim". </td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>This function returns 0 on success; otherwise, it returns -1 if its inputs do not meet the constraints that in_tensor_ch is a multiple of 4 and out_tensor_ch is a multiple of 2.</dd></dl>
<dl class="section note"><dt>Note</dt><dd>The outputs will be 2-stage shifted before being stored, i.e., out = ((out &gt;&gt; pre_rshift) *out_scale) &gt;&gt; post_rshift. </dd></dl>

</div>
</div>
<a id="gad00d5ffdfffd45ad20e15c41da36a31b" name="gad00d5ffdfffd45ad20e15c41da36a31b"></a>
<h2 class="memtitle"><span class="permalink"><a href="#gad00d5ffdfffd45ad20e15c41da36a31b">&#9670;&#160;</a></span>hpm_nn_conv_HWC_u8_u8_s8_sym_fast_any()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">static int32_t hpm_nn_conv_HWC_u8_u8_s8_sym_fast_any </td>
          <td>(</td>
          <td class="paramtype">const u8_t *</td>          <td class="paramname"><span class="paramname"><em>in_tensor</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>in_tensor_dim_x</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>in_tensor_dim_y</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>in_tensor_ch</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const q7_t *</td>          <td class="paramname"><span class="paramname"><em>ker_weight</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>out_tensor_ch</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>ker_dim_x</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>ker_dim_y</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>pad_x</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>pad_y</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>stride_x</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>stride_y</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>pre_rshift</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>out_scale</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>post_rshift</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">u8_t *</td>          <td class="paramname"><span class="paramname"><em>out_tensor</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>out_tensor_dim_x</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t</td>          <td class="paramname"><span class="paramname"><em>out_tensor_dim_y</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">q15_t *</td>          <td class="paramname"><span class="paramname"><em>in_tmp_buf</em></span>&#160;)</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span><span class="mlabel">static</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p><code>#include &lt;<a class="el" href="hpm__math_8h.html">middleware/hpm_math/hpm_math.h</a>&gt;</code></p>

<p>This function performs fast convolution for unsigned 8-bit integer inputs/outputs in any x and y dimensions with symmetric quantization on the outputs. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor</td><td>pointer of the input vector </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor_dim_x</td><td>x dimension of the input tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor_dim_y</td><td>y dimension of the input tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tensor_ch</td><td>number of input tensor channels </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">ker_weight</td><td>pointer of kernel weights </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_tensor_ch</td><td>number of output tensor channels </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">ker_dim_x</td><td>x dimension of the filter kernel </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">ker_dim_y</td><td>y dimension of the filter kernel </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">pad_x</td><td>padding size in the x dimension </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">pad_y</td><td>padding size in the y dimension </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">stride_x</td><td>convolution stride in the x dimension </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">stride_y</td><td>convolution stride in the y dimension </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">pre_rshift</td><td>right shift amount for the output </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_scale</td><td>value of scaling for the output </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">post_rshift</td><td>right shift amount for the output </td></tr>
    <tr><td class="paramdir">[out]</td><td class="paramname">out_tensor</td><td>pointer of the output tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_tensor_dim_x</td><td>x dimension of the output tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_tensor_dim_y</td><td>y dimension of the output tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">in_tmp_buf</td><td>temporary buffer for the input tensor. It is required when -mext-dsp or -mext-vector enabled and its size must be equal to "2 * in_tensor_ch * ker_dim_x
                                     * ker_dim_y". </td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>This function returns 0 on success; otherwise, it returns -1 if its inputs do not meet the constraints that in_tensor_ch is a multiple of 4 and out_tensor_ch is a multiple of 2.</dd></dl>
<dl class="section note"><dt>Note</dt><dd>The outputs will be 2-stage shifted before being stored, i.e., out = ((out &gt;&gt; pre_rshift) *out_scale) &gt;&gt; post_rshift. </dd></dl>

</div>
</div>
</div><!-- contents -->
</div><!-- doc-content -->
<!-- start footer part -->
<div id="nav-path" class="navpath"><!-- id is needed for treeview function! -->
  <ul>
    <li class="footer">Generated on Mon Sep 30 2024 15:24:03 for HPM SDK by <a href="https://www.doxygen.org/index.html"><img class="footer" src="doxygen.svg" width="104" height="31" alt="doxygen"/></a> 1.12.0 </li>
  </ul>
</div>
</body>
</html>
